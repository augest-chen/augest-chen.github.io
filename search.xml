<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/06/03/cyjournal-11/"/>
      <url>/2020/06/03/cyjournal-11/</url>
      
        <content type="html"><![CDATA[<p>累死了，现在在考虑去买一个单独台式机做并行计算，我感觉即使mac很流畅，但是吃不住大型的计算。yinan最近压力似乎挺大的，也没敢去打扰她。就悄咪咪的一个人上课，一个人搞计算吧。庆幸的是，在孤单的时候总能有一群志同道合之人，也不失为人生的一种乐趣吧。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200603 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>清华｜数据科学</title>
      <link href="/2020/06/03/edx/"/>
      <url>/2020/06/03/edx/</url>
      
        <content type="html"><![CDATA[<h2 id="数据挖掘：理论与算法-Data-Mining-Theories-and-Algorithms-for-Tackling-Big-Data"><a href="#数据挖掘：理论与算法-Data-Mining-Theories-and-Algorithms-for-Tackling-Big-Data" class="headerlink" title="数据挖掘：理论与算法 | Data Mining: Theories and Algorithms for Tackling Big Data"></a>数据挖掘：理论与算法 | Data Mining: Theories and Algorithms for Tackling Big Data</h2><h3 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a><strong>第一部分</strong></h3><h3 id="走进数据"><a href="#走进数据" class="headerlink" title="走进数据"></a><strong>走进数据</strong></h3><p>这一部分基本是简单的介绍，我就稍微选几个我觉得是重点的吧。需要理解什么是data rich information poor。</p><p><strong>其次，一些教材推荐：</strong></p><p>1.数据挖掘：概念与技术</p><p>2.模式分类，3.beautiful data （这本书案例多，可以拓展思路）4.data mining：practical machine learning tools and techniques 5. introduction to data mining</p><p><strong>以及需要关注一些国际会议的论文：</strong></p><p>international conference on data mining</p><p>international conference on data engineering</p><p>international conference on machine learning</p><p>international joint conference on artificial intelligence</p><p>Pacific-asia conference on knowledge discovery and data mining</p><p>ACM SIGKDD conference on knowledge discovery and data mining</p><p>ieee transaction knowledge and data engineering</p><p>ieee transaction neural newtworks and learning systems</p><p>data mining and konwledge discovery</p><p>information sciences</p><p><strong>两个协会：</strong></p><p>ieee computiatioal intelligence society</p><p>ieee computer society</p><p><strong>几个华人学者的实验室官网，关注其进度：</strong></p><p>xindong wu</p><p>zhihua zhou</p><p>jiawei han</p><p>jian pei</p><p>qiang yang</p><p>chih-jen lin</p><p>philip s. yu</p><p>changshui zhang</p><p><strong>一些工具的推荐：</strong></p><p>1.检索类：</p><p>Wikipedia</p><p>google </p><p>google scholar</p><p>kddnuggest 专门的数据挖掘网站</p><p>2.工具类</p><p>matlab 的 app</p><p>machine learning repository 上的公开数据集</p><p>weka 这是一款开源的数据挖掘软件</p><p>数据挖掘的广义概念如下图：</p><p><img src="/images/datamining.png" alt="alt"></p><h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a><strong>数据</strong></h3><p>数据的定义（粗略的）：定量、定型化的属性值。数据是底层的一种表现形式，信息是高一层的。数据处理后的，才能叫做信息。数据不同类型，连续型的(continues)，二值型(binary)的。存储上，数据又可以分为逻辑下那型和物理层面的。物理上都是01的，但是逻辑上，可以是二维表等。在实际数据分析工作中，数据类型转换和数据自身的错误是面临的主要挑战之一。</p><p>big data ： gartner的定义：数据量大，速度快（产生速度），数据种类多（千奇百怪）/mckinsey：超过传统数据处理的能力的数据</p><p>三个特点：</p><p>1.结构化变为非结构化</p><p>2.batch变为数据流</p><p>3.数据变大了</p><p><img src="/images/bigdata.png" alt="alt"></p><p>大数据应用：</p><p>1.公共安全：预防犯罪</p><p>2.医疗健康：undertreat &amp; overtreat、 基因</p><p>3.城市规划：智慧城市</p><p>4.地理位置：定位、商店购物</p><p>5.情感分析：sentiment amalysis</p><p>6.社交网站：</p><p>7.点球成金；</p><h3 id="数据到知识"><a href="#数据到知识" class="headerlink" title="数据到知识"></a><strong>数据到知识</strong></h3><p>开放数据，难以获得，因此，产生了数据孤岛。有一种趋势就是去打破这些数据孤岛。也就是数据公开。公开数据有两个要求：1.技术公开(可公开，易获得)，2.法律公开（开放，公开）。</p><p>以下有可获得公开数据的来源：</p><p><img src="/images/opendataset.png" alt="alt"></p><p>此外，补充一个政府数据公开的网站：</p><p><a href="https://www.data.gov/" target="_blank" rel="noopener">美国政府公开数据网站</a></p><p>数据挖掘：从以前的统计分析，到现代的大型计算机引入的统计方式都是数据挖掘的一部分。<strong>数据挖掘应该是一个过程，一个自动化的过程，一个自动化提取有趣（interesting）、有用（useful）、隐藏（hidden）的模式（pattern），从海量的（massive）、不完整的（incomplete）、嘈杂（noisy）的数据中。</strong>并且，需要注意的是，并不是全自动的过程。数据挖掘，并不是，没有人的涉及的。数据挖掘（data mining），有一个近义词，知识发现（konwledge discovery）</p><p>数据挖掘的流程：</p><p><img src="/images/liuc.png" alt="alt"></p><p>业界的数据挖掘流程：</p><p><img src="/images/qiye.png" alt="alt"></p><p>其中ETL,又可以被叫做数据融合。ETL系统的作用主要是数据提起、数据转换、数据装载</p><p>可以把这些过程进行抽象，得到理论上的过程：</p><p><img src="/images/lilun.png" alt="alt"></p><h3 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a><strong>算法简介</strong></h3><h4 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a><strong>分类问题</strong></h4><p>定义：数据挖掘当中第一类问题就叫做Classification 分类问题，什么叫分类问题 你给我一批人过来，每个人有一些属性标签，身高体重年龄 反正这样的，一些属性 然后你要预测什么，比如他是好人还是坏人 我建一个模型能做这件事情 这就叫做分类。<strong>我为什么能够给他打标签，好人还是坏人 因为我以前已经见过，一批打过标签的人 我已经知道了</strong>，好人长什么样坏人长什么样，所以现在再来一个人 我就可以去，根据以前我学到的这些知识我就，来判断新来的这个人他到底是好，这就叫classification</p><p>典型的算法：决策树、KNN、神经网络、支持向量机</p><p>直观的来看：其实就是分界面：</p><p><img src="/images/classexample.png" alt="alt"></p><p>随着情况的复杂，有的时候一条线可能并不能完整的划分的很好，因此，也可以使用曲面、</p><p><img src="/images/classexample2.png" alt="alt"></p><p>本质上，这就是对于空间进行划分。不同的分类器的结果也是不一样的。重要的是：平滑的分类曲线更加重要！</p><p>下图的绿色的分类器，就是过拟合的现象，而黑色的，更加平滑，即使有一定的错误，但是更加的平稳。</p><p><img src="/images/fenleiqi.png" alt="alt"></p><p>在数据挖掘的时候，一定要注意划分测试集(test set)和训练集(traning set),流程如下：</p><p><img src="/images/liuchengtu.png" alt="alt"></p><p>混淆矩阵：注意准确率的计算方法</p><p><img src="/images/hunxiaojuzhen.png" alt="alt"></p><p>AUC的概念：首先，看到左上角的图片，红色的正态分布为男人的身高，蓝色的正态分布代表女人的身高。来选择一个合适的分类器，来通过身高划分男人和女人。如果这个分类器设置为：这个人身高超过10m，才算是男人，那么没有人会别分类为男人，因此，预测为男，实际为男的数量就是0，然后预测为女，实际为男的数量就是100%。得到第一组坐标，就是[0,100%]，同理，如果分类器设置为：这个人升高超过1m，就是男人。那么可以得到第二组坐标[100%,0]。由此，我们将其在中间的图上画出。</p><p><img src="/images/nanrennvrenwenti.png" alt="alt"></p><p>如果分类的调整是随机的（random process）,那么这两点的连线，就是随机的分类器的曲线。但是，我们希望的是分类器的曲线是上图的曲线的。</p><p><img src="/images/fenleiqi2.png" alt="alt"></p><p>但是不同的分类器，都有着不同的曲线，未来衡量他们的效果。求解曲线到x轴的面积，我们叫做auc，使用其作为衡量分类器效果的一个标准。AUC上限为1，随机的AUC为0.5。这一过程，也叫做ROC分析</p><p><strong>cost sensitive learning：</strong></p><p>实际过程中，不同错误的危害是不一样的。实际操作，记得考虑成本</p><p><strong>lift analysis：</strong></p><p>用了模型和不使用模型的差异就是提升度(lift)，这个可以说是另外一种分析的模型效果的方法。</p><p>简单例题：假设目标客户占人群的5%，现根据用户模型进行打分排序，取1000名潜在客户中排名前10%的客户，发现其中包含25名目标客户，问此模型在10%处的提升度是多少？</p><p>1000*5% = 50人</p><p>目标客户有50人</p><p>1000*10% = 100人</p><p>取得100人做预测</p><p>25/100 = 25%</p><p>模型的效率25%</p><p>25%/5% = 5</p><p>提升度为5</p><h4 id="聚类问题"><a href="#聚类问题" class="headerlink" title="聚类问题"></a><strong>聚类问题</strong></h4><h2 id="数据科学导论-Data-Science-A-New-Way-of-Thinking"><a href="#数据科学导论-Data-Science-A-New-Way-of-Thinking" class="headerlink" title="数据科学导论|Data Science: A New Way of Thinking"></a>数据科学导论|Data Science: A New Way of Thinking</h2><h3 id><a href="#" class="headerlink" title></a></h3>]]></content>
      
      
      <categories>
          
          <category> edx </category>
          
          <category> thu data science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> edx </tag>
            
            <tag> thu </tag>
            
            <tag> data science </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/06/02/cyjournal-10/"/>
      <url>/2020/06/02/cyjournal-10/</url>
      
        <content type="html"><![CDATA[<p>作为杭州人，61过儿童节，62过62节哈哈哈哈。不过呢，今天yinan似乎挺烦躁的。点个烧烤，给他安慰一下内心吧。不过到时候又要怪我，给他点夜宵，减不了肥了。哈哈哈，今天也没有什么大事，定个小目标，在利用接下来的两个月刷完coursera和edx的课程。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200602 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/06/01/cyjournal-9/"/>
      <url>/2020/06/01/cyjournal-9/</url>
      
        <content type="html"><![CDATA[<p>六一快乐，yinan。在学校的日子还是比较清闲的。感觉需要找点事情来做。明天就找yinan一起学习。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200601 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coursera 1st the global financial crisis</title>
      <link href="/2020/06/01/coursera-4/"/>
      <url>/2020/06/01/coursera-4/</url>
      
        <content type="html"><![CDATA[<p>A number of students have asked for the name of a textbook so that they might read more on the content covered in the course. There is no one textbook that covers the breadth of the course. Even when we teach the course at Yale, we use a compilation of various articles and texts. Below are some resources that will enable you to explore further the key themes addressed in the course. Also see the Suggested Readings posted with each weekly module.</p><p>Thank you for your continued participation in the Global Financial Crisis. We hope you enjoy the course!</p><p>Yale Coursera Team</p><p><strong>Recommended Additional Readings week 1</strong></p><p><strong>P1</strong></p><p>\1. Geithner, Timothy, Stress Test, Introduction + Chapters One and Two</p><p>\2. Bernanke, Ben, 2010, <a href="http://som.yale.edu/sites/default/files/files/Bernanke_Ben_Causes_of_the_Recent_Financial%26Economic_Crisis_9-2-10.pdf" target="_blank" rel="noopener">Testimony to the Financial Crisis Inquiry Commission.</a></p><p>\3. Gorton, Gary B. and Andrew Metrick, 2012, <a href="http://faculty.som.yale.edu/garygorton/documents/GettingUpToSpeed_Jan-11-2012.pdf" target="_blank" rel="noopener">Getting up to speed on the financial crisis: a one-weekend-reader’s guide</a>, <em>Journal of Economic Literature</em> 2012, 50:1, 128–150</p><p>\4. Schularick, Moritz and Alan M. Taylor 2012, <a href="http://www.aeaweb.org/articles?id=10.1257/aer.102.2.1029" target="_blank" rel="noopener">Credit booms gone bust: monetary policy, leverage cycles and financial crises, 1870-2008</a>, <em>American Economic Review</em> 102, 1029-1061.</p><p><strong>P2</strong></p><p>\1. Bernanke, Ben S.,., The Recent Financial Turmoil and its Economic and Policy Consequences. Speech at the Economic Club of New York, New York, New York. 2007.</p><p><em>— The former Chairman of the Federal Reserve discusses events occurring at the early stages of the crisis and the spillover from the subprime crisis to the financial system.</em></p><p>\2. Bernanke, Ben S., Testimony to the Financial Crisis Inquiry Commission, 2010.</p><p><em>— The former Chairman of the Federal Reserve discusses some of the elements that lead up to the crisis including increased leverage and the reliance on short-term funding by financial institutions. He also discusses some of the weaknesses in the regulatory system and the problem of too-big-to-fail financial institutions.</em></p><p>\3. Financial Crisis Inquiry Commission. The Financial Crisis Inquiry Report: Final Report of the National Commission on the Causes of the Financial and Economic Crisis in the United States, authorized ed. New York: Public Affairs, 2011.</p><p>— <em>The FCIC was established to examine the causes of the financial and economic crisis in the United States. The final report presents the commission’s findings and conclusions and also includes dissenting views. A Table of Contents makes it easy to locate particular topics. The FCIC website also has searchable original documents and testimony as well as various reports prepared by commission staff.</em></p><p>\4. Geithner, Timothy F., Stress Test. New York, Crown Publishing Group, 2014.</p><p><em>—Former President of the Federal Reserve Bank of New York and Secretary of the Treasury recounts the financial crisis from a first person perspective. The book presents unique insights as to the pressures, perceptions and timing under which decisions were made.</em></p><p>\5. Gorton, Gary B. and Andrew Metrick. Getting up to Speed on the Financial Crisis: A One-Weekend-Reader’s Guide, Journal of Economic Literature 2012, 50:1, 128-150. 2012.</p><p><em>—The authors discuss 16 selected documents, including academic papers and reports from regulatory and international agencies that provide a picture of the factors leading up to the financial crisis and the actions taken by governments in response. Articles discuss the global savings glut, panic in short-term debt, contagion and effects on the real economy.</em></p><p>\6. Sorkin, Andrew Ross. Too Big to Fail: The Inside Story of How Wall Street and Washington Fought to Save the Financial System—and Themselves. New York: Viking Press, 2009.</p><p><em>—The author presents a very readable and journalistic account of March-October 2008, the most critical period of the financial crisis, based on extensive interviews with key participants from industry and government.</em></p><p><em>7. Wessel, David. In Fed We Trust: Ben Bernanke’s War on The Great Panic. New York: Three Rivers P</em>ress, 2009.</p><p><em>—Focusing on the Federal Reserve’s unprecedented role, this book presents a highly-accessible analysis of the key players, critical decisions, underlying policy, and market turbulence that characterized the financial crisis.</em></p><p><strong>Recommended Additional Readings week 2</strong></p><p><strong>P1</strong></p><p>\1. Geithner, Timothy, Stress Test, Chapter Three</p><p>\2. Jobst, Andreas, 2008, <a href="http://http//www.imf.org/external/pubs/ft/fandd/2008/09/basics.htm" target="_blank" rel="noopener">Back to basics-what is securitization?</a> Finance &amp; Development 45, 48.</p><p>\3. Pozsar, Zoltan. 2011, <a href="http://https//www.imf.org/external/pubs/cat/longres.aspx?sk=25155.0" target="_blank" rel="noopener">Institutional Cash Pools and the Triffin Dilemma of the U.S. Banking System</a>, International Monetary Fund Working Paper 11/190.</p><p>\4. Bernanke, Ben S., Carol Bertaut, Laurie P. DeMarco, and Steven Kamin, 2011, <a href="http://https//www.federalreserve.gov/pubs/ifdp/2011/1014/ifdp1014.htm" target="_blank" rel="noopener">International capital flows and the return to safe assets in the United States, 2003-2007</a>, FRB International Finance Discussion Paper No. 1014.</p><p>\5. Gorton, Gary B. and Andrew Metrick, <a href="http://http//www.sciencedirect.com/science/article/pii/B978044453594800001X" target="_blank" rel="noopener">Securitization, 2013, Handbook of the Economics of Finance, Volume 2A</a>, George Constantinides, Milton Harris, and Rene Stulz eds., 1-70, Elsevier. (Just read the first three sections).</p><p><strong>Recommended Additional Readings week 3</strong></p><p><strong>P1</strong></p><p>\1. Bernanke, Ben S., <a href="https://www.federalreserve.gov/newsevents/speech/bernanke20070517a.htm" target="_blank" rel="noopener">The Subprime Mortgage Market</a>, Speech at the Federal Reserve Bank of Chicago’s 43rd Annual Conference on Bank Structure and Competition, Chicago, Illinois, May 17, 2007.</p><p>\2. Shiller, Robert J., 2007, <a href="http://www.kansascityfed.org/publicat/sympos/2007/PDF/Shiller_0415.pdf" target="_blank" rel="noopener">Understanding Recent Trends in House Prices and Homeownership</a>, in <em>Proceedings</em> of the symposium “Housing, Housing Finance, and Monetary Policy.” Kansas City: Federal Reserve Bank of Kansas City, pp.89-123.</p><p>\3. Mayer, Christopher, Karen Pence, and Shane M Sherlund, 2009, <a href="http://www.federalreserve.gov/pubs/feds/2008/200859/200859pap.pdf" target="_blank" rel="noopener">The Rise in Mortgage Defaults</a>, <em>The Journal of Economic Perspectives</em> 23, 27-50.</p><p>\4. Foote, Christopher L, Kristopher S Gerardi, and Paul S Willen, 2012, <a href="http://www.nber.org/papers/w18082" target="_blank" rel="noopener">Why did so many people make so many ex post bad decisions? The causes of the foreclosure crisis</a>, working paper, National Bureau of Economic Research.</p>]]></content>
      
      
      <categories>
          
          <category> coursera </category>
          
          <category> the global financial crisis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> coursera </tag>
            
            <tag> the global financial crisis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>云计算概论</title>
      <link href="/2020/05/31/azure/"/>
      <url>/2020/05/31/azure/</url>
      
        <content type="html"><![CDATA[<p>云计算会租用其他公司计算机上的存储空间或 CPU 周期等资源。 只需为所用的部分付费。 提供这些服务的公司称为云提供商。 某些提供商包括 Microsoft、Amazon 和 Google。</p><p>云提供商负责提供执行工作所需的物理硬件，并使其保持最新。 提供的计算服务往往因云提供商而异。 但是，它们通常包括：</p><ul><li><strong>计算能力</strong> - 例如，Linux 服务器或 Web 应用程序</li><li><strong>存储</strong> - 例如，文件和数据库</li><li><strong>网络</strong> - 例如，云提供商和公司之间的安全连接</li><li><strong>分析</strong>例如，可视化遥测和性能数据</li></ul><h2 id="云计算服务"><a href="#云计算服务" class="headerlink" title="云计算服务"></a>云计算服务</h2><p>云计算的目标是使企业开展业务更轻松、更高效，无论是小型初创企业还是大型企业。 每项业务都是独特的，有不同的需求。 为满足这些需求，云计算提供商提供广泛的服务。</p><p>需要对其提供的一些服务有基本了解。 我们简要讨论所有云服务提供商都提供的两种最常见服务：–<em>计算能力<em>和</em>存储</em>。</p><h3 id="计算能力"><a href="#计算能力" class="headerlink" title="计算能力"></a>计算能力</h3><p>发送一封电子邮件、在 Internet 上进行预订、在线付款、或甚至使用此 Microsoft Learn 模块时，你都在与处理每个请求并返回响应的基于云的服务器进行交互。 作为消费者，我们都依赖于组成 Internet 的各种云提供商提供的计算服务。</p><p>使用云计算生成解决方案时，可以根据自己的资源和需求选择工作的完成方式。 例如，如果希望对维护拥有更多控制权并承担更多责任，则可以创建虚拟机 (VM)。 VM 是仿真计算机，与你正在使用的台式机或笔记本电脑相似。 每个 VM 都包括操作系统和硬件，在用户看来就像运行 Windows 或 Linux 的物理计算机一样。 然后，你可以安装任何所需的软件来执行要在云中运行的任务。</p><p>不同之处在于，你无需购买任何硬件或安装操作系统。 云提供商在其中一个数据中心的物理服务器上运行虚拟机，通常与其他 VM 共享该服务器（独立且安全）。 借助云，你能够以比物理计算机更低的成本在数分钟内准备好 VM。</p><p>VM 不是唯一的计算选择，还有两个其他常用选项：容器和无服务器计算。</p><h4 id="什么是容器？"><a href="#什么是容器？" class="headerlink" title="什么是容器？"></a>什么是容器？</h4><p>容器为应用程序提供一致、独立的执行环境。 它们类似于 VM，但它们不需要来宾操作系统。 相反，应用程序及其所有依赖项都打包到“容器”中，然后使用标准运行时环境来执行应用。 这样，容器可以在数秒钟内启动，因为没有要启动和初始化的操作系统。 只需启动应用。</p><p>开放源代码项目 Docker 是用于管理容器的领先平台之一。 Docker 容器为应用程序部署提供了一种高效、轻量级的方法，因为通过它们可将应用程序的不同组件独立部署到不同的容器中。 多个容器可以在一台计算机上运行，并且容器可以在计算机之间移动。 由于容器的可移植性，可以非常轻松地将应用程序部署到多个环境（无论是在本地还是在云中），通常无需对应用程序进行任何更改。</p><h4 id="什么是无服务器计算？"><a href="#什么是无服务器计算？" class="headerlink" title="什么是无服务器计算？"></a>什么是无服务器计算？</h4><p>借助无服务器计算，无需创建、配置或维护服务器即可运行应用程序代码。 核心理念是将应用程序分为单独的函数，这些函数会在由某些操作触发时运行。 这是自动化任务的理想之选。例如，你可以构建无服务器进程，在客户进行在线购买后自动发送电子邮件确认。</p><p>无服务器模型与 VM 和容器的不同之处在于，你只需为每个函数在执行时使用的处理时间付费。 VM 和容器运行时，即使其上的应用程序处于空闲状态，也会收取相应的费用。 此体系结构并不适用于每个应用 - 但是当应用逻辑可以分离到独立的单元时，可以单独对其进行测试和更新，并在数微秒内启动它们，从而使这种方法成为部署的最快选择。</p><p>以下是比较我们介绍的三种计算方法的关系图。</p><p><img src="/images/2-vm-vs-container-vs-serverless.png" alt="显示虚拟机、容器和无服务器计算的比较的关系图"></p><h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><p>大多数设备和应用程序都会读取和/或写入数据。 下面是一些示例：</p><ul><li>在线购买电影票</li><li>查询在线商品的价格</li><li>拍摄照片</li><li>发送电子邮件</li><li>留语音邮件</li></ul><p>在以上所有案例中，不是读取数据（查询价格）就是写入数据（拍摄照片）。 在每种情况下，数据类型及其存储方式可能不同。</p><p>云提供商通常会提供可处理所有这些类型的数据的服务。 例如，如果要存储文本或影片剪辑，则可以使用磁盘上的文件。 如果有一组关系（例如地址簿），可以采取一种更结构化的方法，比如使用数据库。</p><p>使用基于云的数据存储的优点是可以缩放以满足需求。 如果发现需要更多空间来存储影片剪辑，则可以支付更多费用并增加可用空间。 在某些情况下，存储甚至可以自动进行扩展和缩放，因此你可以在任何给定的时间点为所需的内容付费。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>每项业务有不同的需求和要求。 云计算灵活且经济高效，不论是小型还是大型企业，均可由此受益。</p>]]></content>
      
      
      <categories>
          
          <category> Cloud computing </category>
          
          <category> Azure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Azure </tag>
            
            <tag> Cloud computing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/31/cyjournal-8/"/>
      <url>/2020/05/31/cyjournal-8/</url>
      
        <content type="html"><![CDATA[<p>五月的最后一天，生活还是平淡如常。一开始的时候有些厌恶，但是仔细想来，倒也不是一件坏事。无意间发现自己多了一些行为，一天之内居然好几次拿起手机，想法朋友圈，文字配图都被仔细的编辑好了，却又在的时候，退出了编辑，并且选择了不保留。</p><p>无意间翻到了伍佰的歌，好听nice。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200531 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coursera 4st data management and visualization</title>
      <link href="/2020/05/30/coursera-3/"/>
      <url>/2020/05/30/coursera-3/</url>
      
        <content type="html"><![CDATA[<p>This is my assignment.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Sun May 24 11:56:00 2020</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: chenjiahao</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">'dataset.csv'</span>)<span class="comment"># ge the garminder data i need</span></span><br><span class="line"></span><br><span class="line">print(data.shape[<span class="number">0</span>])<span class="comment"># number of observations(rows)</span></span><br><span class="line">print(data.shape[<span class="number">1</span>]) <span class="comment"># number of variables(columns)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.replace(data[<span class="string">'hivrate'</span>].get(<span class="number">0</span>), <span class="number">9999</span>) <span class="comment">#replace missing data</span></span><br><span class="line">    </span><br><span class="line">c1 = data[<span class="string">'country'</span>]</span><br><span class="line">c2 = data[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">c3 = data[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">c4 = data[<span class="string">'employrate'</span>]</span><br><span class="line">c5 = data[<span class="string">'hivrate'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Separate the data I need into series</span></span><br><span class="line"></span><br><span class="line">aw = [c1,c2,c3,c4,c5] <span class="comment"># Convert data to a list</span></span><br><span class="line">result = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] <span class="comment"># Form an empty list to store the results</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>): <span class="comment"># Generate a statistical table for each column</span></span><br><span class="line">    w = aw[ii] <span class="comment"># Gets the specified column</span></span><br><span class="line">    </span><br><span class="line">    df_show = pd.DataFrame(columns=[<span class="string">'frequency'</span>, <span class="string">'percent'</span>, <span class="string">'cumlativefrequency'</span>,<span class="string">'cumlativepercent'</span>])<span class="comment"># Create an empty dataframe</span></span><br><span class="line">    </span><br><span class="line">    fc1 = pd.value_counts(w)<span class="comment"># Statistical frequency</span></span><br><span class="line">    df_show.index.name = fc1.index.name<span class="comment"># Match coordinate index</span></span><br><span class="line">    df_show[<span class="string">'frequency'</span>] = fc1 <span class="comment"># Data matching</span></span><br><span class="line"></span><br><span class="line">    fc2 = pd.value_counts(w,normalize = <span class="literal">True</span>) <span class="comment">#frequency</span></span><br><span class="line">    df_show[<span class="string">'percent'</span>] = fc2 <span class="comment">#Data matching</span></span><br><span class="line"></span><br><span class="line">    v2 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    v1 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    </span><br><span class="line">    df_show= df_show.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,df_show.shape[<span class="number">0</span>]):<span class="comment"># Processing of accumulated data</span></span><br><span class="line"></span><br><span class="line">        v2 = v2 + df_show.iat[i,<span class="number">0</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">2</span>] = v2 <span class="comment">#Store data</span></span><br><span class="line"></span><br><span class="line">        df_show.iat[i,<span class="number">1</span>] = df_show.iat[i,<span class="number">1</span>]*<span class="number">100</span> <span class="comment">#Convert data</span></span><br><span class="line">        v1 = v1 + df_show.iat[i,<span class="number">1</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">3</span>] = v1 <span class="comment"># Store data</span></span><br><span class="line"></span><br><span class="line">    print(df_show) <span class="comment">#show data</span></span><br><span class="line">    result[ii] = df_show <span class="comment"># Store result</span></span><br><span class="line">    </span><br><span class="line">nums =[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">    vs1 = result[i]</span><br><span class="line">    nums[i<span class="number">-1</span>] = data.shape[<span class="number">0</span>] - vs1.iat[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">mark_index = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">4</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">3</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">2</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">1</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">new_datas = data.drop(index = mark_index, axis = <span class="number">0</span> )</span><br><span class="line"></span><br><span class="line">new_datas[<span class="string">'me'</span>] = <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,new_datas.shape[<span class="number">0</span>]):</span><br><span class="line">    new_datas.iat[i,<span class="number">5</span>] = float(new_datas.iat[i,<span class="number">3</span>]) - float(new_datas.iat[i,<span class="number">2</span>]) </span><br><span class="line"></span><br><span class="line">c1 = new_datas[<span class="string">'country'</span>]</span><br><span class="line">c2 = new_datas[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">c3 = new_datas[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">c4 = new_datas[<span class="string">'employrate'</span>]</span><br><span class="line">c5 = new_datas[<span class="string">'hivrate'</span>]</span><br><span class="line">c6 = new_datas[<span class="string">'me'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Separate the data I need into series</span></span><br><span class="line"></span><br><span class="line">aw = [c1,c2,c3,c4,c5,c6] <span class="comment"># Convert data to a list</span></span><br><span class="line">result = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] <span class="comment"># Form an empty list to store the results</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">6</span>): <span class="comment"># Generate a statistical table for each column</span></span><br><span class="line">    w = aw[ii] <span class="comment"># Gets the specified column</span></span><br><span class="line">    </span><br><span class="line">    df_show = pd.DataFrame(columns=[<span class="string">'frequency'</span>, <span class="string">'percent'</span>, <span class="string">'cumlativefrequency'</span>,<span class="string">'cumlativepercent'</span>])<span class="comment"># Create an empty dataframe</span></span><br><span class="line">    </span><br><span class="line">    fc1 = pd.value_counts(w)<span class="comment"># Statistical frequency</span></span><br><span class="line">    df_show.index.name = fc1.index.name<span class="comment"># Match coordinate index</span></span><br><span class="line">    df_show[<span class="string">'frequency'</span>] = fc1 <span class="comment"># Data matching</span></span><br><span class="line"></span><br><span class="line">    fc2 = pd.value_counts(w,normalize = <span class="literal">True</span>) <span class="comment">#frequency</span></span><br><span class="line">    df_show[<span class="string">'percent'</span>] = fc2 <span class="comment">#Data matching</span></span><br><span class="line"></span><br><span class="line">    v2 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    v1 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    </span><br><span class="line">    df_show= df_show.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,df_show.shape[<span class="number">0</span>]):<span class="comment"># Processing of accumulated data</span></span><br><span class="line"></span><br><span class="line">        v2 = v2 + df_show.iat[i,<span class="number">0</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">2</span>] = v2 <span class="comment">#Store data</span></span><br><span class="line"></span><br><span class="line">        df_show.iat[i,<span class="number">1</span>] = df_show.iat[i,<span class="number">1</span>]*<span class="number">100</span> <span class="comment">#Convert data</span></span><br><span class="line">        v1 = v1 + df_show.iat[i,<span class="number">1</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">3</span>] = v1 <span class="comment"># Store data</span></span><br><span class="line"></span><br><span class="line">    print(df_show) <span class="comment">#show data</span></span><br><span class="line">    result[ii] = df_show <span class="comment"># Store result</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_for_plt = result[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">x = data_for_plt.index</span><br><span class="line"></span><br><span class="line">y = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">xx = range(<span class="number">0</span>,len(data_for_plt.index)) </span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.bar(xx,y,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">"country"</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y1 = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">ax2 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.bar(xx,y1,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax2.yaxis.tick_right()</span><br><span class="line">ax2.set_xlabel(<span class="string">"country"</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">y2 = data_for_plt[<span class="string">'percent'</span>]</span><br><span class="line">ax3 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.bar(xx,y2,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax3.set_xlabel(<span class="string">"country"</span>)</span><br><span class="line">ax3.set_ylabel(<span class="string">"percent"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y3 = data_for_plt[<span class="string">'frequency'</span>]</span><br><span class="line">ax4 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.bar(xx,y3,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax4.set_xlabel(<span class="string">"country"</span>)</span><br><span class="line">ax4.yaxis.tick_right()</span><br><span class="line">ax4.set_ylabel(<span class="string">"frequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()  </span><br><span class="line">plt.savefig(<span class="string">"barChart_country.jpg"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_for_plt = result[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">x = data_for_plt.index</span><br><span class="line">y = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">xx = range(<span class="number">0</span>,len(data_for_plt.index)) </span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.bar(xx,y,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">"armedforcesrate"</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y1 = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">ax2 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.bar(xx,y1,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax2.yaxis.tick_right()</span><br><span class="line">ax2.set_xlabel(<span class="string">"armedforcesrate"</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">y2 = data_for_plt[<span class="string">'percent'</span>]</span><br><span class="line">ax3 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.bar(xx,y2,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax3.set_xlabel(<span class="string">"armedforcesrate"</span>)</span><br><span class="line">ax3.set_ylabel(<span class="string">"percent"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y3 = data_for_plt[<span class="string">'frequency'</span>]</span><br><span class="line">ax4 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.bar(xx,y3,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax4.set_xlabel(<span class="string">"armedforcesrate"</span>)</span><br><span class="line">ax4.yaxis.tick_right()</span><br><span class="line">ax4.set_ylabel(<span class="string">"frequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()  </span><br><span class="line">plt.savefig(<span class="string">"barChart_armedforcesrate.jpg"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_for_plt = result[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">x = data_for_plt.index</span><br><span class="line">y = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">xx = range(<span class="number">0</span>,len(data_for_plt.index)) </span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.bar(xx,y,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">"femaleemployrate"</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y1 = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">ax2 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.bar(xx,y1,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax2.yaxis.tick_right()</span><br><span class="line">ax2.set_xlabel(<span class="string">"femaleemployrate"</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">y2 = data_for_plt[<span class="string">'percent'</span>]</span><br><span class="line">ax3 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.bar(xx,y2,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax3.set_xlabel(<span class="string">"femaleemployrate"</span>)</span><br><span class="line">ax3.set_ylabel(<span class="string">"percent"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y3 = data_for_plt[<span class="string">'frequency'</span>]</span><br><span class="line">ax4 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.bar(xx,y3,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax4.set_xlabel(<span class="string">"femaleemployrate"</span>)</span><br><span class="line">ax4.yaxis.tick_right()</span><br><span class="line">ax4.set_ylabel(<span class="string">"frequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()  </span><br><span class="line">plt.savefig(<span class="string">"barChart_femaleemployrate.jpg"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_for_plt = result[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">x = data_for_plt.index</span><br><span class="line">y = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">xx = range(<span class="number">0</span>,len(data_for_plt.index)) </span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.bar(xx,y,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">"employrate"</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y1 = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">ax2 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.bar(xx,y1,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax2.yaxis.tick_right()</span><br><span class="line">ax2.set_xlabel(<span class="string">"employrate"</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">y2 = data_for_plt[<span class="string">'percent'</span>]</span><br><span class="line">ax3 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.bar(xx,y2,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax3.set_xlabel(<span class="string">"employrate"</span>)</span><br><span class="line">ax3.set_ylabel(<span class="string">"percent"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y3 = data_for_plt[<span class="string">'frequency'</span>]</span><br><span class="line">ax4 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.bar(xx,y3,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax4.set_xlabel(<span class="string">"employratee"</span>)</span><br><span class="line">ax4.yaxis.tick_right()</span><br><span class="line">ax4.set_ylabel(<span class="string">"frequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()  </span><br><span class="line">plt.savefig(<span class="string">"barChart_employrate.jpg"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_for_plt = result[<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">x = data_for_plt.index</span><br><span class="line">y = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">xx = range(<span class="number">0</span>,len(data_for_plt.index)) </span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.bar(xx,y,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">"hivrate"</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y1 = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">ax2 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.bar(xx,y1,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax2.yaxis.tick_right()</span><br><span class="line">ax2.set_xlabel(<span class="string">"hivrate"</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">y2 = data_for_plt[<span class="string">'percent'</span>]</span><br><span class="line">ax3 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.bar(xx,y2,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax3.set_xlabel(<span class="string">"hivrate"</span>)</span><br><span class="line">ax3.set_ylabel(<span class="string">"percent"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y3 = data_for_plt[<span class="string">'frequency'</span>]</span><br><span class="line">ax4 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.bar(xx,y3,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax4.set_xlabel(<span class="string">"hivrate"</span>)</span><br><span class="line">ax4.yaxis.tick_right()</span><br><span class="line">ax4.set_ylabel(<span class="string">"frequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()  </span><br><span class="line">plt.savefig(<span class="string">"barChart_hivrate.jpg"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_for_plt = result[<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">x = data_for_plt.index</span><br><span class="line">y = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">xx = range(<span class="number">0</span>,len(data_for_plt.index)) </span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.bar(xx,y,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">"me"</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y1 = data_for_plt[<span class="string">'cumlativefrequency'</span>]</span><br><span class="line">ax2 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.bar(xx,y1,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax2.yaxis.tick_right()</span><br><span class="line">ax2.set_xlabel(<span class="string">"me"</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">"cumlativefrequency"</span>)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">y2 = data_for_plt[<span class="string">'percent'</span>]</span><br><span class="line">ax3 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.bar(xx,y2,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax3.set_xlabel(<span class="string">"me"</span>)</span><br><span class="line">ax3.set_ylabel(<span class="string">"percent"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y3 = data_for_plt[<span class="string">'frequency'</span>]</span><br><span class="line">ax4 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.bar(xx,y3,<span class="number">0.4</span>,color=<span class="string">"green"</span>)</span><br><span class="line">ax4.set_xlabel(<span class="string">"me"</span>)</span><br><span class="line">ax4.yaxis.tick_right()</span><br><span class="line">ax4.set_ylabel(<span class="string">"frequency"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()  </span><br><span class="line">plt.savefig(<span class="string">"barChart_me.jpg"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">print(new_datas.describe(include=<span class="string">'all'</span>))</span><br><span class="line"></span><br><span class="line">dc = new_datas.drop(columns = <span class="string">"country"</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,dc.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">        dc.iat[i,ii] = float(dc.iat[i,ii])</span><br><span class="line"></span><br><span class="line">print(dc.describe(include=<span class="string">'all'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">c2 = dc[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">print(c2.mean())</span><br><span class="line">print(c2.std())</span><br><span class="line">print(c2.quantile(q=<span class="number">0.25</span>))</span><br><span class="line">print(c2.quantile(q=<span class="number">0.50</span>))</span><br><span class="line">print(c2.quantile(q=<span class="number">0.75</span>))</span><br><span class="line"></span><br><span class="line">c3 = dc[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">print(c3.mean())</span><br><span class="line">print(c3.std())</span><br><span class="line">print(c3.quantile(q=<span class="number">0.25</span>))</span><br><span class="line">print(c3.quantile(q=<span class="number">0.50</span>))</span><br><span class="line">print(c3.quantile(q=<span class="number">0.75</span>))</span><br><span class="line"></span><br><span class="line">c4 = dc[<span class="string">'employrate'</span>]</span><br><span class="line">print(c4.mean())</span><br><span class="line">print(c4.std())</span><br><span class="line">print(c4.quantile(q=<span class="number">0.25</span>))</span><br><span class="line">print(c4.quantile(q=<span class="number">0.50</span>))</span><br><span class="line">print(c4.quantile(q=<span class="number">0.75</span>))</span><br><span class="line"></span><br><span class="line">c5 = dc[<span class="string">'hivrate'</span>]</span><br><span class="line">print(c5.mean())</span><br><span class="line">print(c5.std())</span><br><span class="line">print(c5.quantile(q=<span class="number">0.25</span>))</span><br><span class="line">print(c5.quantile(q=<span class="number">0.50</span>))</span><br><span class="line">print(c5.quantile(q=<span class="number">0.75</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">c6 = dc[<span class="string">'me'</span>]</span><br><span class="line">print(c6.mean())</span><br><span class="line">print(c6.std())</span><br><span class="line">print(c6.quantile(q=<span class="number">0.25</span>))</span><br><span class="line">print(c6.quantile(q=<span class="number">0.50</span>))</span><br><span class="line">print(c6.quantile(q=<span class="number">0.75</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">y = new_datas[<span class="string">'hivrate'</span>]</span><br><span class="line">x1 = new_datas[<span class="string">'me'</span>]</span><br><span class="line">x2 = new_datas[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">x3 = new_datas[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">x4 = new_datas[<span class="string">'employrate'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.bar(x1,y,<span class="number">0.4</span>,color=<span class="string">"red"</span>)</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.xticks([])</span><br><span class="line">ax1.set_ylabel(<span class="string">"hivrate"</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">"me"</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">ax2.yaxis.tick_right()</span><br><span class="line">plt.bar(x2,y,<span class="number">0.4</span>,color=<span class="string">"red"</span>)</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.xticks([])</span><br><span class="line">ax2.set_ylabel(<span class="string">"hivrate"</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">"armedforcesrate"</span>)</span><br><span class="line"></span><br><span class="line">ax3 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.bar(x3,y,<span class="number">0.4</span>,color=<span class="string">"red"</span>)</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.xticks([])</span><br><span class="line">ax3.set_ylabel(<span class="string">"hivrate"</span>)</span><br><span class="line">ax3.set_xlabel(<span class="string">"femaleemployrate"</span>)</span><br><span class="line"></span><br><span class="line">ax4 = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">ax4.yaxis.tick_right()</span><br><span class="line">plt.bar(x4,y,<span class="number">0.4</span>,color=<span class="string">"red"</span>)</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.xticks([])</span><br><span class="line">ax4.set_ylabel(<span class="string">"hivrate"</span>)</span><br><span class="line">ax4.set_xlabel(<span class="string">"employrate"</span>)</span><br><span class="line"></span><br><span class="line">plt.show()  </span><br><span class="line">plt.savefig(<span class="string">"analysis.jpg"</span>)</span><br></pre></td></tr></table></figure><p><strong>console and analysis:</strong></p><p><img src="/images/show_program.png" alt="alt"></p><p>To be specific：</p><p>The following figure is a single variable graph of all data variables.</p><p><img src="/images/country.png" alt="alt"></p><p>For national variables, it is evenly distributed. The rest will not be described in detail.</p><p><img src="/images/arm.png" alt="alt"></p><p><img src="/images/emp.png" alt="alt"></p><p><img src="/images/fam.png" alt="alt"></p><p><img src="/images/hiv.png" alt="alt"></p><p><img src="/images/me.png" alt="alt"></p><p>The following is a graph with HIV rate as the response variable and the independent variable as the other.</p><p><img src="/images/ii.png" alt="alt"></p><p>It can be observed that female employment rate and overall employment rate are positively related to HIV rate. Male employment rate and HIV rate showed a middle high and low side characteristics, but not obvious. The military ratio and HIV rate are high on both sides and low in the middle.</p>]]></content>
      
      
      <categories>
          
          <category> coursera </category>
          
          <category> data management and visualization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> coursera </tag>
            
            <tag> data management and visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/30/cyjournal-7/"/>
      <url>/2020/05/30/cyjournal-7/</url>
      
        <content type="html"><![CDATA[<p><img src="/images/wsh.jpg" alt="alt"></p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200530 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/29/cyjournal-6/"/>
      <url>/2020/05/29/cyjournal-6/</url>
      
        <content type="html"><![CDATA[<p>快毕业了，才突然意识到，我去年给yinan预约了两个写真，还没有拍。真的吐了。这个啥时候才能拍噢。想想还是很激动的。学校的大盘鸡变得不好吃了，以前好好次的，诶，难受。yinan说，要我blog写长一点，那我尽力吧哈哈。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200529 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>奥地利经济学派小论</title>
      <link href="/2020/05/29/eco/"/>
      <url>/2020/05/29/eco/</url>
      
        <content type="html"><![CDATA[<p>和其他学科的历史一样，经济思想史展现为一种不同思想体系的混杂，而这些思想体系曾经分属于秉持各种观念的特定学派。这种把来自不同思想家的观念分类的方法关注特定群体的相似之处，却遮蔽了他们的差异。在十八世纪后半叶声名鹊起的法国重农学派代表了第一个现代经济思想学派。随之而来的是古典经济思想、马克思主义和社会主义。十九世纪末叶，在西欧出现了两个互相冲突的经济思想流派：德国历史学派和奥地利学派。德国历史学派试图通过研究经济史来求取经济真理。在1883年，他们的经验主义方法论成为了早期奥地利学派的靶子。奥地利学派坚持经济学知识源自理论分析而非历史研究。这场方法论论战，或者说对方法的争论，持续了逾二十年。</p><p>推荐一本书：《奥地利经济学入门》</p><p>托马斯泰勒的《奥地利经济学入门》以在1873年到1903年之间任维也纳大学政治经济学教授的卡尔·门格尔（Carl Menger）为开端，尝试阐释奥地利学派的核心观念。1871年，门格尔在他的《国民经济学原理》（德文书名：Grundsätze der Volkswirtschaftslehre，英文译名：Principles of Economics）一书中，提出了一种价值理论，解决了长期困扰那些伟大的古典经济学家的问题。这个理论就是基于边际效用原理的主观价值理论。[注：经济思想史如今已经将几乎在同时分别创立了主观价值理论的荣誉归功于门格尔、英国经济学家威廉·斯坦利·杰文斯（William Stanley Jevons）和法国经济学家列昂·瓦尔拉斯（Leon Walras）。参见马克·布劳格（Mark Blaug），《经济理论回顾》（Economic Theory in Retrospect）（Homewood: Richard D. Irwin, Inc., 1962）第272页~第273页。]它破除了一个经典概念，即事物的价值是一种内在于事物本身的客观衡量。现在，经济财货依据某一使用者期望从对其增量的使用中所得到的满足，而得到主观评价。在本书的后面部分，我们将更全面地讨论整个奥地利学派系统的基石——主观价值论。门格尔的两个伟大门徒弗里德里希·冯·维塞尔（Friedrich von Wieser）和欧根·冯·庞巴维克（Eugen von Böhm-Bawerk）继承了主观价值论，他们深化了它并廓清了其在成本、资本和利息理论领域的全部分支。具体如下：</p><p>维塞尔扩展了门格尔的归属（imputation）问题，解释了资源的价格或成本源自资源所生产出来的消费品的预期价格。这样便揭示了价值的形成乃是一个循环的过程，而门格尔理论所欠缺的成本概念也被补充进了主观价值论。维塞尔的“成本法则”或替代成本学说认为，生产一件产品的成本反映了其他制造商对生产所用资源的竞争出价。成本仅仅是为了将资源从其第二有利可图的用途上吸引过来而必须支付的报酬。</p><p>庞巴维克的伟大贡献是他的资本和利息理论。他强调了在经济过程中时间的重要性并将资本定义为已生产出来的生产要素。他的分析中的关键思想，是采用“迂回”的生产方式能提升人们的生产力。这种生产力的增长既体现在不考虑装备和工具时可生产财货数量的增加，也体现在仅考虑资本财货时的可生产财货上。采用非直接过程导致的等待时期为他对利息这一现象的解释提供了基础。他宣称，在其他条件一样的情况下，人们对现在财货的估值，高于他们对具有相似特点的未来财货的估值。这个假设包含了为售价和成本之间的利润而辩护的基础。这个利润归属于提供中间产品或资本财货所需资金的资本家们。他们的回报是他们的投资被使用的期间所支付的利息，而不是如马克思声称的对工人的剥削。于是主观价值论得以扩展，从而包含了时间偏好法则。虽然奥地利学派的资本理论在某种程度上被修正了，庞巴维克对利息和迂回或称非直接生产过程的实质解释仍然在今天的奥地利学派理论中占据着支配地位。</p><p>路德维希·冯·米塞斯（Ludwig von Mises）和弗里德里希·冯·哈耶克（Friedrich von Hayek）是现代奥地利学派理论家中的两大巨擘。米塞斯在二十世纪二十年代以其对社会主义的质疑而广受其他经济学家关注。他认为，由于缺少市场价格——对他而言这是为了合理配置资源所不可或缺的手段——社会主义在现代经济中完全不可能实现。米塞斯和哈耶克都对奥地利学派理论形成一个整体做出了突出贡献。他们解释了由不受控制的政府信用的扩张如何导致商业周期波动，从而为奥地利学派的框架增添了又一个重要的组成部分。哈耶克关注于“社会中的知识”问题和协调相互作用的市场参与者的行为的不可或缺的需求，为经济学研究提供了至关重要的洞见。本书将大致描述哈耶克、米塞斯，以及米塞斯的两位学生伊斯雷尔·柯兹纳（Israel Kirzner）和穆瑞·罗斯巴德（Murray Rothbard）的观点。这两位都对说明及阐述奥地利学派的分析做出了突出的贡献。</p><p>尽管奥地利学派不再以它对主观价值论的赞同而和其他学派相区别，在奥地利学派的经济分析方法中仍然有一些显著的固有特征使之区别于其他学派。其中一个特征是它严格的方法论立场。关于门格尔在1883年出版的一本书里发起的方法论论战已经列出了参考书。[注：现在已经被译成英文，书名为《经济学与政治学问题》（Problems of Economics and Sociology）(Urbana: University of Illinois Press, 1963).]奥地利学派的经济分析主要植根于理论的、演绎的推理基础之上；经验主义在奥地利学派的理论中只占次要的位置——因此，他们与德国历史学派展开了论战。源自社会环境的经济现象，被奥地利学派视为太过复杂与易变，以至于不被允许使用物理学家所用的实验分析方法。相应地，奥地利学派理论反对把数学作为经济分析工具的方法论立场。概念理解，而非数量关系，被视为经济科学唯一有意义的基础。奥地利学派之父门格尔把坚持和追随定性研究的取向贯穿在他的著作中，就像他的继承者们所做的那样。</p><p>奥地利学派理论中第二个重要的特征是它的方法论个人主义。奥地利学派坚信经济现象并非是对某些社会力量或诸如“社会”这样的具体实体的表达。相反，它们是个人参与经济活动的行动的结果。因此，除非通过分析其基本元素，即个人的行动，总的经济过程就不能得到理解。</p><p>奥地利学派将人性及人类的困境用作分析的材料。受到包括感性知识在内的限制的个人价值标准和人的行动被置于经济科学的中心位置。人类犯错的因素、未来的不确定性、不可避免的时间流逝必须得到应有的关注。这一分析方法穿透了一个发达市场经济表面上的复杂性，并通过考察本质性的市场因素提供了对经济过程的基本理解。一切围绕在经济、市场价格、商业盈亏、利率、通货膨胀以及经济衰退和萧条的神秘感都被驱散了。这些现象不是无法解释的，也不是没有原因的，就如接下来的章节所展示的那样。</p><p>这本书如其书名所意指的那样，呈现了奥地利学派基本理论的概貌。它的重点是自由市场或者说资本主义经济。为了对这里讨论的主题有更深入理解，无疑不能忽视奥地利学派经济学家们富有创造力的著作。必须参考原著，尤其是为了缜密地鉴别现在十分猖獗的政府干预市场过程所造成的严重后果。本书在每章节的结尾处都提供了推荐阅读书目以加深理解。</p><p>实际上，一个人在使用“奥地利学派经济学”一词的时候难免会有些不好意思，因为担心这意味着它可能不同于简明可靠的经济学。凯恩斯主义经济学的混乱，计量经济学的惑人造作，“专业”经济学家糟糕的预测记录，诸如完全竞争和完全垄断等不切实际的教科书模型，持续的通货膨胀和失业，以及经济利益普遍的政治化，已经造成了对所有经济理论确定无疑的不信任。然而，如果要进一步理解市场过程和伴随其运行的干预的效果，就不能忽视奥地利学派的分析。</p><p>关于奥地利学派的另外一些资料已经更新在了资源那篇文章里。</p>]]></content>
      
      
      <categories>
          
          <category> economy </category>
          
          <category> 20200529 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> economy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/28/cyjournal-5/"/>
      <url>/2020/05/28/cyjournal-5/</url>
      
        <content type="html"><![CDATA[<p>今天和小猪聊天聊很多，脾气暴躁的我，解锁新称号：暴躁小恐龙。哈哈哈，聊了很多，觉得yinan其实也挺脆弱的。我可能平时太苛刻了吧，对她。应该对她要好一点。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200528 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/27/cyjournal-4/"/>
      <url>/2020/05/27/cyjournal-4/</url>
      
        <content type="html"><![CDATA[<p>今日享受生活</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200527 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coursera 3st data management and visualization</title>
      <link href="/2020/05/27/coursera-2/"/>
      <url>/2020/05/27/coursera-2/</url>
      
        <content type="html"><![CDATA[<p>This is my assignment.</p><p><strong>code:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">'dataset.csv'</span>)<span class="comment"># ge the garminder data i need</span></span><br><span class="line"></span><br><span class="line">print(data.shape[<span class="number">0</span>])<span class="comment"># number of observations(rows)</span></span><br><span class="line">print(data.shape[<span class="number">1</span>]) <span class="comment"># number of variables(columns)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.replace(data[<span class="string">'hivrate'</span>].get(<span class="number">0</span>), <span class="number">9999</span>) <span class="comment">#replace missing data</span></span><br><span class="line">    </span><br><span class="line">c1 = data[<span class="string">'country'</span>]</span><br><span class="line">c2 = data[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">c3 = data[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">c4 = data[<span class="string">'employrate'</span>]</span><br><span class="line">c5 = data[<span class="string">'hivrate'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Separate the data I need into series</span></span><br><span class="line"></span><br><span class="line">aw = [c1,c2,c3,c4,c5] <span class="comment"># Convert data to a list</span></span><br><span class="line">result = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] <span class="comment"># Form an empty list to store the results</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>): <span class="comment"># Generate a statistical table for each column</span></span><br><span class="line">    w = aw[ii] <span class="comment"># Gets the specified column</span></span><br><span class="line">    </span><br><span class="line">    df_show = pd.DataFrame(columns=[<span class="string">'frequency'</span>, <span class="string">'percent'</span>, <span class="string">'cumlativefrequency'</span>,<span class="string">'cumlativepercent'</span>])<span class="comment"># Create an empty dataframe</span></span><br><span class="line">    </span><br><span class="line">    fc1 = pd.value_counts(w)<span class="comment"># Statistical frequency</span></span><br><span class="line">    df_show.index.name = fc1.index.name<span class="comment"># Match coordinate index</span></span><br><span class="line">    df_show[<span class="string">'frequency'</span>] = fc1 <span class="comment"># Data matching</span></span><br><span class="line"></span><br><span class="line">    fc2 = pd.value_counts(w,normalize = <span class="literal">True</span>) <span class="comment">#frequency</span></span><br><span class="line">    df_show[<span class="string">'percent'</span>] = fc2 <span class="comment">#Data matching</span></span><br><span class="line"></span><br><span class="line">    v2 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    v1 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    </span><br><span class="line">    df_show= df_show.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,df_show.shape[<span class="number">0</span>]):<span class="comment"># Processing of accumulated data</span></span><br><span class="line"></span><br><span class="line">        v2 = v2 + df_show.iat[i,<span class="number">0</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">2</span>] = v2 <span class="comment">#Store data</span></span><br><span class="line"></span><br><span class="line">        df_show.iat[i,<span class="number">1</span>] = df_show.iat[i,<span class="number">1</span>]*<span class="number">100</span> <span class="comment">#Convert data</span></span><br><span class="line">        v1 = v1 + df_show.iat[i,<span class="number">1</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">3</span>] = v1 <span class="comment"># Store data</span></span><br><span class="line"></span><br><span class="line">    print(df_show) <span class="comment">#show data</span></span><br><span class="line">    result[ii] = df_show <span class="comment"># Store result</span></span><br><span class="line">    </span><br><span class="line">nums =[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">    vs1 = result[i]</span><br><span class="line">    nums[i<span class="number">-1</span>] = data.shape[<span class="number">0</span>] - vs1.iat[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">mark_index = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">4</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">3</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">2</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">1</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">new_datas = data.drop(index = mark_index, axis = <span class="number">0</span> )</span><br><span class="line"></span><br><span class="line">new_datas[<span class="string">'me'</span>] = <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,new_datas.shape[<span class="number">0</span>]):</span><br><span class="line">    new_datas.iat[i,<span class="number">5</span>] = float(new_datas.iat[i,<span class="number">3</span>]) - float(new_datas.iat[i,<span class="number">2</span>]) </span><br><span class="line"></span><br><span class="line">c1 = new_datas[<span class="string">'country'</span>]</span><br><span class="line">c2 = new_datas[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">c3 = new_datas[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">c4 = new_datas[<span class="string">'employrate'</span>]</span><br><span class="line">c5 = new_datas[<span class="string">'hivrate'</span>]</span><br><span class="line">c6 = new_datas[<span class="string">'me'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Separate the data I need into series</span></span><br><span class="line"></span><br><span class="line">aw = [c1,c2,c3,c4,c5,c6] <span class="comment"># Convert data to a list</span></span><br><span class="line">result = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] <span class="comment"># Form an empty list to store the results</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">6</span>): <span class="comment"># Generate a statistical table for each column</span></span><br><span class="line">    w = aw[ii] <span class="comment"># Gets the specified column</span></span><br><span class="line">    </span><br><span class="line">    df_show = pd.DataFrame(columns=[<span class="string">'frequency'</span>, <span class="string">'percent'</span>, <span class="string">'cumlativefrequency'</span>,<span class="string">'cumlativepercent'</span>])<span class="comment"># Create an empty dataframe</span></span><br><span class="line">    </span><br><span class="line">    fc1 = pd.value_counts(w)<span class="comment"># Statistical frequency</span></span><br><span class="line">    df_show.index.name = fc1.index.name<span class="comment"># Match coordinate index</span></span><br><span class="line">    df_show[<span class="string">'frequency'</span>] = fc1 <span class="comment"># Data matching</span></span><br><span class="line"></span><br><span class="line">    fc2 = pd.value_counts(w,normalize = <span class="literal">True</span>) <span class="comment">#frequency</span></span><br><span class="line">    df_show[<span class="string">'percent'</span>] = fc2 <span class="comment">#Data matching</span></span><br><span class="line"></span><br><span class="line">    v2 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    v1 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    </span><br><span class="line">    df_show= df_show.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,df_show.shape[<span class="number">0</span>]):<span class="comment"># Processing of accumulated data</span></span><br><span class="line"></span><br><span class="line">        v2 = v2 + df_show.iat[i,<span class="number">0</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">2</span>] = v2 <span class="comment">#Store data</span></span><br><span class="line"></span><br><span class="line">        df_show.iat[i,<span class="number">1</span>] = df_show.iat[i,<span class="number">1</span>]*<span class="number">100</span> <span class="comment">#Convert data</span></span><br><span class="line">        v1 = v1 + df_show.iat[i,<span class="number">1</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">3</span>] = v1 <span class="comment"># Store data</span></span><br><span class="line"></span><br><span class="line">    print(df_show) <span class="comment">#show data</span></span><br><span class="line">    result[ii] = df_show <span class="comment"># Store result</span></span><br></pre></td></tr></table></figure><p><strong>console and analysis:</strong></p><p><img src="/images/con.png" alt="alt"></p><p>To be specific：</p><p>No missing data here. This data mainly shows all countries. It’s evenly distributed</p><p><img src="/images/res1.png" alt="alt"></p><p>The following shows the proportion of the military, which is the same in almost every country. So they are evenly distributed. (I mean the frequency of proportion)</p><p><img src="/images/res2.png" alt="alt"></p><p>Three countries have the same level of female employment (at 39.5%). It also has the highest frequency.</p><p><img src="/images/res3.png" alt="alt"></p><p>Three employment ratios (47.49%, 61.5%, 58.9%) have occurred three times. This means that employment rates are at this level in three countries.</p><p><img src="/images/res4.png" alt="alt"></p><p>For AIDS rates, 25 countries are at the same level (10%), that is, 10% is also the most frequent rate</p><p><img src="/images/res5.png" alt="alt"></p><p>I use the employment rate minus the female employment rate to get the male employment rate. This data can better help to analyze the impact and relationship between the work rates of different genders on the AIDS rate.Among them, the frequency of male employment rate of 7% is the most, which occurs in four countries.</p><p><img src="/images/res6.png" alt="alt"></p><p><strong>Additional notes:</strong></p><ol><li><p>The variable I selected has no classification variables, so I don’t need to subclassify the original data.</p></li><li><p>Second, the original data is a variable of numeric type, so the usual frequency statistics of the table reveal the relationship between the variables is not obvious. Because the numbers of each country are difficult to agree.</p></li><li><p>For the second submission, I have marked the missing data and explained it. Another blog to go to.</p><p>link:<a href="https://augest-chen.github.io/2020/05/24/coursera-1/#more" target="_blank" rel="noopener">https://augest-chen.github.io/2020/05/24/coursera-1/#more</a></p></li><li><p>For the missing data, I use 9999 instead, and then delete the data one by one. 9999 was chosen because this value could not be within the original data range.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> coursera </category>
          
          <category> data management and visualization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> coursera </tag>
            
            <tag> data management and visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/26/cyjournal-3/"/>
      <url>/2020/05/26/cyjournal-3/</url>
      
        <content type="html"><![CDATA[<p>有的时候，我也不敢相信我和yinan一天微信只发五个消息，也不见一面，即使都在学校。我们这个恋爱居然也就这么谈下去了。真是不可意思</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200526 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IBM WASTON STUDIO 使用指南</title>
      <link href="/2020/05/25/ibm/"/>
      <url>/2020/05/25/ibm/</url>
      
        <content type="html"><![CDATA[<p>IBM Watson 是认知计算系统的杰出代表，也是一个技术平台。认知计算代表一种全新的计算模式，它包含信息分析，自然语言处理和机器学习领域的大量技术创新，能够助力决策者从大量非结构化数据中揭示非凡的洞察。简单来说，Watson能够支持如下方面，包括但不限于：理解自然语言、大数据的理解和分析、动态分析各类假设和问题、精细的个性化分析能力、在相关数据的基础上优化问题解答、在短时间内提炼洞察、发现新的运行模式、在迭代中学习，探索优化的解决方案、云端开发平台，支持生态发展</p><p><strong>上述都是扯淡，到底什么功能用了才知道。</strong></p><p>ibm官方在官网的放了ibm waston studio，兴趣使然想用一下，但是发现guide比较少。干脆自己写一个好了。先放一张官网的截图。</p><p><img src="/images/ij.png" alt="alt"></p><p>初步探索了一下，一个项目（project）基本可以由notebook和spss modeler两个运行的方式，这么说特也许有点不准确，我指的是一个数据源（data asset）可以使用两种方式（不同的code）去进行研究。然后又一个connection的链接，如果本地有mysql这类的数据库，可以直接从数据库中提取数据。实际上waston本身的数据导入的方式也还是比较简单的。</p>]]></content>
      
      
      <categories>
          
          <category> technology </category>
          
          <category> IBM WASTON STUDIO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IBM WASTON STUDIO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>0.3.....3*3 = ？</title>
      <link href="/2020/05/25/tech-1/"/>
      <url>/2020/05/25/tech-1/</url>
      
        <content type="html"><![CDATA[<p>今天问yinan一个问题：0.3333……3333*3 = ？她告诉我是0.999……99。我差点晕倒。实际上精髓一点讲：这一个极限问题。换得通俗一点，她的数学水平应该是在高等数学以下的。因为本质上：lim0.99999999…=1。这就是说：1和0.9999…表示的是同一个数，只是表示方法的不同。证明如下：</p><p><img src="/images/th.png" alt="alt"></p><p>实际上，对于这个问题，扯点别的。对于这个问题有疑问的人，如果是大学以及以上的学生（接受过高等数学学习），我是觉得有些担忧的。具体如下：</p><p><img src="/images/thr.png" alt="alt"></p>]]></content>
      
      
      <categories>
          
          <category> math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> math </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/25/cyjournal-2/"/>
      <url>/2020/05/25/cyjournal-2/</url>
      
        <content type="html"><![CDATA[<p>最近居然开始矛盾起来，又想快点毕业，又想不毕业。严重怀疑是不是一些哲学的视频看多了，导致心思太活跃了点。想的有点多？？by the way，强烈推荐一下李宗盛的《我是真的爱你》，总感觉李宗盛的声音比别的版本要好听那么一点。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200525 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/24/cyjournal-1/"/>
      <url>/2020/05/24/cyjournal-1/</url>
      
        <content type="html"><![CDATA[<p>今天和yinan终于见面了啦，2020在学校的第一次见面，着实有点久噢。新操场的微风和视野，的确也有点让人沉迷。yinan说还在在读一次大学，我说那你考本校呀，她说，我想和你一起读。哈哈哈这一句话让我暗自有点小幸福哈哈哈</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200524 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coursera 2st data management and visualization</title>
      <link href="/2020/05/24/coursera-1/"/>
      <url>/2020/05/24/coursera-1/</url>
      
        <content type="html"><![CDATA[<p>This is my assignment.</p><p><strong>code:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">'dataset.csv'</span>)<span class="comment"># ge the garminder data i need</span></span><br><span class="line"></span><br><span class="line">print(data.shape[<span class="number">0</span>])<span class="comment"># number of observations(rows)</span></span><br><span class="line">print(data.shape[<span class="number">1</span>]) <span class="comment"># number of variables(columns)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">c1 = data[<span class="string">'country'</span>]</span><br><span class="line">c2 = data[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">c3 = data[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">c4 = data[<span class="string">'employrate'</span>]</span><br><span class="line">c5 = data[<span class="string">'hivrate'</span>]</span><br><span class="line"><span class="comment"># Separate the data I need into series</span></span><br><span class="line"></span><br><span class="line">aw = [c1,c2,c3,c4,c5] <span class="comment"># Convert data to a list</span></span><br><span class="line">result = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] <span class="comment"># Form an empty list to store the results</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>): <span class="comment"># Generate a statistical table for each column</span></span><br><span class="line">    w = aw[ii] <span class="comment"># Gets the specified column</span></span><br><span class="line">    </span><br><span class="line">    df_show = pd.DataFrame(columns=[<span class="string">'frequency'</span>, <span class="string">'percent'</span>, <span class="string">'cumlativefrequency'</span>,<span class="string">'cumlativepercent'</span>])<span class="comment"># Create an empty dataframe</span></span><br><span class="line"></span><br><span class="line">    fc1 = pd.value_counts(w)<span class="comment"># Statistical frequency</span></span><br><span class="line">    df_show.index.name = fc1.index.name<span class="comment"># Match coordinate index</span></span><br><span class="line">    df_show[<span class="string">'frequency'</span>] = fc1 <span class="comment"># Data matching</span></span><br><span class="line"></span><br><span class="line">    fc2 = pd.value_counts(w,normalize = <span class="literal">True</span>) <span class="comment">#frequency</span></span><br><span class="line">    df_show[<span class="string">'percent'</span>] = fc2 <span class="comment">#Data matching</span></span><br><span class="line"></span><br><span class="line">    v2 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    v1 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,df_show.shape[<span class="number">0</span>]):<span class="comment"># Processing of accumulated data</span></span><br><span class="line"></span><br><span class="line">        v2 = v2 + df_show[<span class="string">'frequency'</span>].get(i) <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">2</span>] = v2 <span class="comment">#Store data</span></span><br><span class="line"></span><br><span class="line">        df_show.iat[i,<span class="number">1</span>] = df_show[<span class="string">'percent'</span>].get(i)*<span class="number">100</span> <span class="comment">#Convert data</span></span><br><span class="line">        v1 = v1 + df_show[<span class="string">'percent'</span>].get(i) <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">3</span>] = v1 <span class="comment"># Store data</span></span><br><span class="line"></span><br><span class="line">    print(df_show) <span class="comment">#show data</span></span><br><span class="line">    result[ii] = df_show <span class="comment"># Store result</span></span><br></pre></td></tr></table></figure><p><strong>console and analysis:</strong></p><p><img src="/images/re.png" alt="alt"></p><p>To be specific：</p><p><img src="/images/a1.png" alt="alt"></p><p>No missing data here. This data mainly shows all countries. It’s evenly distributed</p><p><img src="/images/a2.png" alt="alt"></p><p>Data for 49 countries are missing, accounting for 23% of the total. This means that there are 49 (23%) countries that do not show their share of the military.</p><p><img src="/images/a3.png" alt="alt"></p><p>Data from 35 countries are missing, accounting for 16.43% of the total. This means that 35 (16.43%) countries did not show their female employment rate.</p><p><img src="/images/a4.png" alt="alt"></p><p>Data from 35 countries are missing, accounting for 16.43% of the total. This means that there are 35 (16.43%) countries that do not show their overall employment rate.</p><p><img src="/images/a6.png" alt="alt"></p><p>Data from 66 countries are missing, accounting for 30.98% of the total. This means that there are 35 (30.98%) countries that do not show their HIV rate<br>Considering that my data is not classified data, I don’t do too much analysis on frequency here.</p>]]></content>
      
      
      <categories>
          
          <category> coursera </category>
          
          <category> data management and visualization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> coursera </tag>
            
            <tag> data management and visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>负数开三次方根后出现复数问题</title>
      <link href="/2020/05/24/tech/"/>
      <url>/2020/05/24/tech/</url>
      
        <content type="html"><![CDATA[<p>今天在做数值分析的时候，遇到一个有意思的情况。当我在python3.7中使用pow函数，对一个负数计算三次方根后，发现结果带有复数。具体结果如下：</p><p><img src="/images/py.png" alt="alt"></p><p>实际上为了验证是否是源代码出错，我又在mathematica上面做了一遍计算，结果如下：</p><p><img src="/images/mma.png" alt="alt"></p><p>那么根据两个软件的结果对比，应不是程序源码的问题。本质上这是一个数学问题：</p><p>首先，$ (x)^3 = -8 $，这是一个一元三次方根，根据一元n次方程的在复数领域内有n个根（n为正整数）。且复数的n次方根，可以直接得到如下的求解公式：</p><p><img src="/images/ma.png" alt="alt"></p><p>看到这里，我相信大部分就明白了，按道理这个计算是有三个结果的，但是计算机程序默认是选择了一个主值。具体根据计算机程序而已，有的会取（-pi，pi]。当然，对于主值的选择，一般是根据幅角最小来选择的。</p><p>关于如何展示所有结果，用mathematica的话：</p><p>cube root of -8</p><p>她就展示所有的结果。</p>]]></content>
      
      
      <categories>
          
          <category> math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> math </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>房产税</title>
      <link href="/2020/05/24/fiance/"/>
      <url>/2020/05/24/fiance/</url>
      
        <content type="html"><![CDATA[<p>房产税是最近热议的一个话题，实际上在中国房产是一个很重要的经济支撑部分。房地产对于中国的经济影响，几乎可以类比股市对于美国的经济。房地产实际上有双重属性。一个是基本需求，社会福利性质，这是居民的刚需。另一个是在信用货币体系下，投资者和投机者一般会采用实物保值。房地产就吸引了大量的投机资本。在中国这种情况更加严重一些，因为国内没有房地产税，从而加剧了这种投机资本的进入。</p><p>这些投资或者投机能够保值么，倒也不见得。理由是房地产的价格也是和产业布局相互连接的。以美国的底特律为例子，美国汽车公司一破产，大量的工人失业，但是房产价格10、20多美元，但是你一买，就需要就缴纳大量的税额。那么既然无法实现保值，或者说保值风险较大，那么就应该对这类的资本进行限制，避免产生更大的风险。</p><p>这也就是个人对于未来中国2020-2025年的中国股市的指数有可以增长30%-50%的预期空间的来源。当资本不在进入房地产或者说从房地产转向其他领域的时候，其他领域的发展一定是能够得到发展。</p><p>再来讨论房产税的可行性，实际上中国地方政府的税收主要是来源于土地增值。如果推进房产税，财政收入会受到影响。同样的户口制度也会给房产税的推进带来冲击。这实际上是财政税收制度不合理导致的。</p><p>考虑中国的房地产泡沫问题，不妨采用类比美国市场上的垃圾债的问题。采用当年四大国有银行上市前，进行的坏账剥离，成立专门的资产管理公司进行管理，应该是可以较为妥善的处理的。</p><p>那么在进行坏账剥离的前提，就是首先需要对于全国的房地产进行统一登记（这一点极其有必要）。具体来说，城市的房地产需要登记所有权、购房资金来源、购房时间、所有人等都需要进行登记，不仅城市的需要登记，农村的也需要进行登记。在这过程中，也可以顺带明确负债买房的比例、打击一下反腐。在这个步骤之后，就根据房产的数量和质量可以确定房产税率了。</p><p>之后还需要确定的是，房产税征收之后的去向，个人认为，房产税的征收之后应该主要流向于公共服务等社会福利的提供。倒不是说税收收入不流向于社会福利的提供，而是个人认为这一税收应该形成类似专项税的效应。对于一些农民工等这类在社会劳动分工中提供了价值的，但是没有购房的群体。不应该征收房产税。反而应该利用房产税税收，来提供福利。</p><p>总结一下，我设想的房产税是，在全国财产管理信息统一登记之后，对于二套房以及以后的房地产进行征收的，并且用以补贴第一套房产的征收机制。</p>]]></content>
      
      
      <categories>
          
          <category> finance </category>
          
          <category> 20200524 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> economy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal 5</title>
      <link href="/2020/05/23/cyjournal/"/>
      <url>/2020/05/23/cyjournal/</url>
      
        <content type="html"><![CDATA[<p>明儿见要见到我的狗子了，有点小期待噢。今天无题。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200523 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实体经济发展的一些思考</title>
      <link href="/2020/05/22/finance/"/>
      <url>/2020/05/22/finance/</url>
      
        <content type="html"><![CDATA[<p>最近有如下思考：</p><p>首先，我个人观点是金融业击垮实体经济的的一个重要原因在于，市场上不同行业的利润率差异过大导致的。</p><p>当金融行业的利润率远高于市场上其他实体行业的利润率时，市场上的投资者也就不会将投资目标放到其他行业上去了。也就导致了其他行业的衰落。引申开来：国进民退，也是如此。</p><p>其次，作为解决的方案，应该是政府统计的各行业的行业平均利润率，对于利润率高的行业，进行征税，低的进行减税，从而实现资本要素有序流动。</p><p>目前，根据现有网上资料，除了纽约大学有美国的行业平均利润率数据以外，其他国家似乎都是没有这一数据的统计的。所以，个人认为可以进行统计，至于是否有必要进行公开，这个可以后续在进行商讨。但是毫无疑问，这一数据，是对于宏观调控起到很好的作用的。</p><p>另外，眉山剑客陈平的对于经济学的看法个人十分推荐，值得一看。</p>]]></content>
      
      
      <categories>
          
          <category> finance </category>
          
          <category> 20200522 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> economy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyJournal 4</title>
      <link href="/2020/05/22/lovestory-3/"/>
      <url>/2020/05/22/lovestory-3/</url>
      
        <content type="html"><![CDATA[<p>有些时候，也很奇怪。我和yinan可以一整天不说话，各自沉迷在自己的世界里。</p><p>果然，学习才是唯一的好伙伴。对我和yinan都是如此，哈哈。</p><p>话说起来，最近追星的风格都是：男的女性化，女的中性化嘛？？我有一些难以理解，不过既然yinan喜欢，那也应该尊重她嘛。毕竟每个人都有自己的爱好。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200522 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coursera 1st data management and visualization</title>
      <link href="/2020/05/21/coursera/"/>
      <url>/2020/05/21/coursera/</url>
      
        <content type="html"><![CDATA[<p>After learning the first week of coursera data management and visualization courses, I will provide the first week of related assignments in this blog.</p><p><strong>First week assignnment:</strong></p><p><strong>STEP 1</strong>: Choose a data set</p><p>I chose <strong>GapMinder Codebook</strong> as the data set because I am interested in factors that affect the ratio of AIDS patients in a country.</p><p><strong>STEP 2</strong>: Identify a specific topic of interest</p><p>To be precise, I want to explore the correlation between the employment rate and a country ’s AIDS rate.<br>Specifically, I chose the three variables of <strong>female employment rate, employment rate and armed forces rate</strong> to measure and represent the employment rate of a country. Here I regard the number of troops in disguised form as an employment. The <strong>HIV rate</strong> is represented by HIVrate.</p><p>The reasons why I chose the above variables are as follows: </p><ol><li>AIDS is spread by blood. Therefore, I want to highlight the relationship between the employment rate of different genders and the AIDS rate by comparing the employment rate with that of women. </li><li>Entering the military service is usually not counted in the employed population, so the number of troops should also be considered</li></ol><p><strong>STEP 3:</strong> Prepare a codebook of your own (i.e., print individual pages or copy screen and paste into a new document) from the larger codebook that includes the questions/items/variables that measure your selected topics.)</p><p>According to step 2, I selected the following variables on the codebook, and did a simple treatment of the data set.</p><p><img src="/images/v1.png" alt="alt"></p><p><img src="/images/v2.png" alt="alt"></p><p>According to the codebook, it can be clearly seen that the data source of the armed force rate is work development indicators, and the interpretation of the calculation method of this ratio is armed forces personnel. The specific content is listed on the picture, so I won’t go into details here.</p><p>At the end of this step, I gave my collated variable data set. details as follows:</p><p><img src="/images/v3.png" alt="alt"></p><p><strong>STEP 4</strong>: Identify another specific topic of interest</p><p>The second topic, I want to explore the relationship between the employment rate of different genders and the ratio of AIDS by comparing the employment rate with the employment rate of women.</p><p><strong>STEP 5:</strong> Add questions/items/variables documenting this second topic to your personal codebook.</p><p>The selection of variables and the first topic have not changed, so I wo n’t repeat them here.</p><p><strong>STEP 6:</strong>  literature review</p><p>I focus on studying the following article:</p><p>Under normal circumstances, most people will be confused about my choice of employment rate rather than GDP as a variable, and the correlation between research and AIDS rate. But another author ’s research indicates that Education and employment may therefore become the short-run policy targets in combatting HIV / AIDS prevalence rate among the active population and achieving economic growth. Our results equally suggest that GDP growth by itself may not be an HIV / AIDS reduction driver. Therefore, it seems more reasonable to choose the employment rate.</p><p>The author (Channing Arndt) used the CGE method to study the interaction between the AIDS pandemic and unemployment. In the model, the wages of unskilled and semi-skilled workers are fixed relative to the producer price index. As a result, the level of employment by activity is an equilibrium variable. And to get the conclusion, although it is expected that the pandemic will cause the growth rate of the supply of unskilled and semi-skilled labor to be close to zero, the analysis shows that the AIDS pandemic will also reduce the demand for labor and put the unemployment rate on our “AIDS” basis and fiction Compared with the “No AIDS” scenario, there is basically no change. The pandemic suppressed labor demand through three effects.<br>In fact, this shows that the AIDS rate and the employment rate are highly correlated. However, there are still few research results on the ratio of AIDS to different genders.</p><p>[1] BACHMANN M O, BOOYSEN F L. Health and economic impact of HIV/AIDS on South African households: a cohort study [J]. BMC Public Health, 2003, 3(1): 14.</p><p>[2] AFAWUBO K, MATHEY S. Employment and education effects on HIV/AIDS prevalence rate and economic growth: empirical investigation in ECOWAS [J]. Applied economics letters, 2014, 21(11): 755-9.</p><p><strong>STEP 7:</strong> Based on your literature review, develop a hypothesis about what you believe the association might be between these topics. </p><p>Therefore, based on this, I propose the following topics:<br>Is the employment rate related to the AIDS rate？<br>My assumption is<br>The higher the employment rate, the lower the AIDS rate. They show a negative correlation.<br>The higher the female employment rate, the lower the AIDS rate. They show a negative correlation.<br>The higher the military employment rate, the lower the AIDS rate. They show a negative correlation.</p>]]></content>
      
      
      <categories>
          
          <category> coursera </category>
          
          <category> data management and visualization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> coursera </tag>
            
            <tag> data management and visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyJournal 3</title>
      <link href="/2020/05/21/lovestory-2/"/>
      <url>/2020/05/21/lovestory-2/</url>
      
        <content type="html"><![CDATA[<p>今日，啥都没有，注册了几门coursera，看看学习学习。其他的时间在啃MIT的Mathematics for Computer Science的，资料已经上传在resource的那篇文章里。</p><p>说起来似乎有些奇怪，昨日520还是如漆似胶，今天521就是交流几乎为0。当然了天天520那也是甜到发齁了。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200521 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据存放格式与运算速度</title>
      <link href="/2020/05/21/technology-1/"/>
      <url>/2020/05/21/technology-1/</url>
      
        <content type="html"><![CDATA[<p>考虑如下问题，需要在软件中输入一个3*3的矩阵，用以后续的计算，你会采用什么方式体现。</p><p>实际上可能大部分人想到的是：</p><p><img src="/images/juzhen.PNG" alt="alt"></p><p>但是，我们知道一些计算软件的列运算是行运算快很多的，典型的是matlab。</p><p>那么将第一列视为矩阵的行索引，第二列视为列索引，就可以得到以下的结果：</p><p><img src="/images/juzhen2.PNG" alt="alt"></p><p>看起来似乎没有太大的变化，但是当遇到一个规模比较大的矩阵的时候，这样子的做法，其实是可以提高运算速度的。</p><p>此外，倘若延伸到三维数据，或者高维度的数据：</p><p>在第一种方法中，已经较难表示了。</p><p>但是在第二种方法中，只需要增加一列作为新的维度的索引，即可。</p><p>python等基本思路是一样的，第二种方法，基本上都可以在大规模或者高维度的数据处理上，取得较好的计算效率。</p>]]></content>
      
      
      <categories>
          
          <category> technology </category>
          
          <category> data structure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K-means在Matlab的应用</title>
      <link href="/2020/05/21/technology/"/>
      <url>/2020/05/21/technology/</url>
      
        <content type="html"><![CDATA[<p>K-means算法是一种简单的聚类算法。算法的目的是使各个样本与所在类均值的误差平方和达到最小</p><p><strong>步骤：</strong></p><p>1.初始化数据。输入表达矩阵作为对象集X，输入指定聚类类数N，并在X中随机选取N个对象作为初始聚类中心。设定迭代中止条件。<br>2.进行迭代。根据相似度准则将数据对象分配到最接近的聚类中心，从而形成一类。初始化隶属度矩阵。<br>3.更新聚类中心。</p><p><strong>K-means面临的问题：</strong></p><p>1.收敛问题</p><p>2.类别数量需要预先给定</p><p><strong>解决方法:</strong></p><p>首先设类别数为1，然后逐步提高类别数，在每一个类别数都用上述方法，一般情况下，总方差会很快下降，直到到达一个拐点；这意味着再增加一个聚类中心不会显著减少方差，保存此时的聚类数。</p><p><strong>Matlab code:</strong></p><p>首先，这里个人使用的包是: Statistics and Machine Learning Toolbox</p><p><img src="/images/Matlab.PNG" alt="alt"></p><p>这个包是官方制作的bug也许少一些，稳定一些。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[Idx,C,sumD,D]=Kmeans(X,K)</span><br><span class="line"><span class="comment">%X: N*P的数据矩阵，N为数据个数，P为单个数据维度</span></span><br><span class="line"><span class="comment">%K: 预先给定类数，为整数</span></span><br><span class="line"><span class="comment">%idx: 聚类结果</span></span><br><span class="line"><span class="comment">%C: 聚类中心位置</span></span><br><span class="line"><span class="comment">%sumD: 类间所有点与该类质心点距离之和</span></span><br><span class="line"><span class="comment">%D: 每个点与所有质心的距离</span></span><br><span class="line">[Idx,C,sumD,D]=Kmeans(X,K,<span class="string">'Param1'</span>,Val1,<span class="string">'Param2'</span>,Val2,…)</span><br><span class="line"><span class="comment">%其中，'Param1'，'Param2'这是参数的意思</span></span><br><span class="line"><span class="comment">%其中val1，val2这是参数数值</span></span><br><span class="line"><span class="comment">%主要的有配置参数：有 ‘Distance’(距离测度),‘Start’（初始质心位置选择方法),‘Replicates’（聚类重复次数）  整数</span></span><br><span class="line"><span class="comment">%‘Distance’数值有：‘sqEuclidean’ 欧式距离（默认时，采用此距离方式）,‘cityblock’ 绝度误差和，又称：L1‘cosine’,针对向量‘correlation’  针对有时序关系的值,‘Hamming’ 只针对二进制数据</span></span><br><span class="line"><span class="comment">%‘Start’数值有：‘sample’ 从X中随机选取K个质心点,‘uniform’ 根据X的分布范围均匀的随机生成K个质心,‘cluster’ 初始聚类阶段随机选择10%的X的子样本（此方法初始使用’sample’方法),matrix 提供一K*P的矩阵，作为初始质心位置集合</span></span><br><span class="line"><span class="comment">%‘Replicates’数值有：整数即可。</span></span><br></pre></td></tr></table></figure><p><strong>案例</strong></p><p>这种方法比较简单，就暂时不放案例了。</p>]]></content>
      
      
      <categories>
          
          <category> technology </category>
          
          <category> matlab kmeans </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matlab </tag>
            
            <tag> Kmeans </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>culture</title>
      <link href="/2020/05/20/culture/"/>
      <url>/2020/05/20/culture/</url>
      
        <content type="html"><![CDATA[<p>基本上欧洲的整个发展历史都是和宗教有关系的。但是中西方的文化差异，有的时候我们并不是能很好的理解这种文化，典型是，看电影的时候，不太看得明白一些大史观的电影。我自己对欧洲的历史还算是比较感兴趣，又看了不少的电影，干脆就打算在这里简单介绍一下圣经中的一些背景文化，有了这些背景文化，至少在观看大部分的电影，应该没啥问题了。当然内容肯定还是比较多的，会分好几期写。</p><p>圣经的第一部分的基本可以这么理解，亚当和夏娃生活在伊甸园中，然后偷吃了善恶果被驱逐出了伊甸园。从此，人类呢，自生自灭了。</p><p>数代之后呢，上帝觉得人类太过于堕落了。因此呢，挑选了一个好人，名字叫做诺亚，让他建造一所大船。就在诺亚造好大船，就带着各种动物7对上船了。（记住这个数字）。一上船，就是12天的大雨，之后呢，诺亚放出了各鸽子，只见鸽子飞回来捡了树枝回来。诺亚就知道水位退下去了。</p><p>大部分人看到这里都知道了这就是诺亚方舟的故事，但是好莱坞的电影《诺亚方舟 创世之旅》就是由以这个故事为基础的。</p><p>同样的，灾难片《2012》其中最后地球是被海水淹没大部分地区的灾难设定也就是源自于此。</p><p>更有意思的是，上面提到鸽子，因为鸽子带着树枝回来，诺亚才知道洪水退去了。因此鸽子在西方背景中被视为和平的象征，那就是和平鸽最早的起源。到这里也就不难猜，这个树枝是什么？当然是橄榄树树枝。</p><p>这一期就到这里吧，下一期讲摩西。</p>]]></content>
      
      
      <categories>
          
          <category> culture </category>
          
          <category> culture20200520 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> culture </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyJournal 2</title>
      <link href="/2020/05/20/lovestory-1/"/>
      <url>/2020/05/20/lovestory-1/</url>
      
        <content type="html"><![CDATA[<p>记录感情生活的第二天，今天2020.05.20，和yinan一起出去享受生活啦。</p><p>虽然yinan在前一天，叮咛了几百遍，让我别迟到，然后自己今天迟到了。让我一个人傻乎乎的在地铁站等她。有点生气的噢！</p><p>中午，去了食不食货，这家店还是挺不错的。尤其是这个是冰镇小龙虾，似乎是放了青红酒吧，也许是啤酒，觉得味道还可以，虾的个头也比较大。满足～</p><p><img src="/images/shibushihuo.JPG" alt="alt"></p><p>可惜了龙骨感觉就一般了，我以为是烘箱烘的肉，结果却是腌制的，味道也一般吧。皮皮虾的个头倒是甚合我心。捞汁毛豆味道也比较有特色，具体形容起来就是，辣椒油混合了醋，再加点糖？感觉挺喜欢的这个口味的。</p><p>下午就去撸猫啦，yinan还忽悠我我，说是去鬼屋哈哈哈。以为我胆小吗？？</p><p><img src="/images/maoshe1.JPG" alt="alt"></p><p><img src="/images/maoshe2.JPG" alt="alt"></p><p>可惜，下午可能去的时候猫舍，猫猫们似乎都在晒太阳睡觉。不过还是挺可爱的。</p><p>最后是花鸟市场啦，展示一下下午的收获。</p><p>买给yinan的花儿</p><p><img src="/images/hua1.JPG" alt="alt"></p><p>我的最爱郁金香</p><p><img src="/images/hua2.jpg" alt="alt"></p><p>超大束的进口满天星</p><p><img src="/images/hua3.jpg" alt="alt"></p><p>写到最后突然意识到，今天大概是在一起三年了。</p><p>也算得上是一人两花三年了</p><p><img src="/images/end.JPG" alt="alt"></p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200520 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyJournal 1</title>
      <link href="/2020/05/19/lovestory/"/>
      <url>/2020/05/19/lovestory/</url>
      
        <content type="html"><![CDATA[<p>尝试记录一下自己的感情生活，也算是记录自己的生活吧。这是第一篇关于自己的情感生活的blog。实际上知道我的人都知道，我不怎么喜欢将一些情感生活记录下来。但是还是想突破的尝试一下。现在是2020.5.19.19:00，大部分情侣还是和往常一样在准备着如何过5.20。我和yinan也不例外。</p><p>实际上，今天我委婉的向她表达了，我觉得一年中不需要过这么多的纪念日，她的对与纪念日的要求可以说是很细致了，从早到晚都安排的满满的，每一次都能给我很多的惊喜。也不知明天她给我的惊喜是什么？</p><p>但是，为什么我还是今天委婉的表达了，可以不需要过这么多纪念日呢，其实准确的说，我是觉得绝大多数的纪念日可以通过出去吃个饭，去买点喜欢的，来庆祝。而，只有少部分的生日、纪念日等需要相对隆重的仪式感。我只是觉得每个小日子都过的很有仪式感，会显得很累。但是我想说明的是，过的有仪式感和过的累，并不是划等号的。更加准确的说，我觉得仪式感可以换更加多样化的方式获得，而不是单一化的过节日来获得。（我知道yinan是一个非常看重仪式感的人）。</p><p>她今天可能不是很能理解我的言语，似乎有些生气了。希望她能理解吧。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200519 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>financial engineering 2</title>
      <link href="/2020/05/19/financial-engineering-1/"/>
      <url>/2020/05/19/financial-engineering-1/</url>
      
        <content type="html"><![CDATA[<p><strong>算法交易和T0交易的区别</strong></p><p>在其他地方看一个博主的回答个人觉得比较符合实际（2020.5.19日以前的情况），在引用完全文后，还有个人的一些见解。</p><p>T0和算法交易从模型层面上来讲，区别并不是很大。都是基于股票横截面和时序数据做短周期预测，只是由于T0需要承担手续费，而算法交易则需要每天把交易需求全部做完，需要更多的交易信号以保证这一点，所以从信号强度来讲T0的信号强度会比算法交易大很多，同时信号个数会比算法交易少很多。不过算法比T0复杂的地方在于挂撤单和交易进度的控制，很多时候如果持续没有合适的信号或者时间比较紧张，挂单又不能成交，只能去敲一些对手价，这个时候就会产生亏损，如何控制交易进度并减少敲对价产生的损失，这又是另外一个问题了。</p><p>回到这个问题，那个方向更有前途。从目前业内状况看来，在任何一家alpha靠谱且管理规模大于2个亿的私募，算法交易都是比T0有前途的多的方向，整个方向的利润空间，生存压力都不是程序化T0所能想象的。这一点可能跟外界了解的区别甚大，这其中缘由，恐怕是18年各个券商私募的一轮造神运动中把T0吹上了天，而外界往往又不了解算法交易的利润空间所致，毕竟各位大佬们出去吹牛，可以吹我们程序化T0年化30%，可是没法吹算法交易年化30%，因为这理论上就不可能。</p><p>从截止本文的现实来看，算法交易至少在以下几个方面是远胜于T0的</p><p><strong>一、利润空间</strong></p><p>以一家靠谱且规模较小的私募为例，假设其总的股票持仓为2亿，每天的换手率25%，一个靠谱的算法交易员，其单边收益应该在万三到万六之间，这里取万4，双边就是万八，那么每天的底仓收益率大概是万二左右，年化是5%，大概对应业绩是1000万。5%在T0行业是什么概念呢，17年人工T0比较厉害的团队7%左右，程序化能做到3-4%就不错了。18年比较厉害的人工交易员团队能做到3-5%，程序化3%都有困难，19年除开上半年比较疯狂的几个月，下半年人工都做不到每天万一，程序化收益能做到年化1.5%已经不算差，也就是说，除了大牛市小牛市，程序化T0对底仓收益的贡献都是远低于算法交易的；</p><p><strong>二、资金容量</strong></p><p>前面说到算法交易信号强度要求低，触发次数多，而且有很多单纯的挂单成交，而T0由于要计算手续费，必然会要求比较强的信号，因此触发次数少很多，这就会带来另外一个问题，资金容量。比如一个T0的信号，可能要求强到有千3左右的费后预期收益才会去做，因为考虑到手续费和冲击成本，抢单难度，低于这个预期收益的信号实盘中可能会亏钱，而算法交易则不同，由于不需要手续费，可以做比较弱的信号，而此时的抢单难度不高，信号比较多，一次冲击成本也不会太大，因此可能预期有一个千二左右费前收益的信号就会做，考虑到千1.4左右的手续费，实际上这两个信号的强度差距千2.4，这样带来的信号个数可能是5-10倍的差距，相应的资金容量也会有类似的差距，也就是，同样一套模型，在T0上可能是3-5亿资金容量，在算法交易上就会有15-50亿的资金容量，这两者的差距显然是没有任何办法可以弥补的；</p><p><strong>三、竞争压力</strong></p><p>第一、目前国内程序化T0从产生到现在，一直面对一个强大的竞争对手，人工T0。目前业内前几名的私募，比如九坤幻方，都是有成规模的人工T0团队的，也就意味着这些公司的程序化T0在这么几年的发展中，依然比不过人工交易员，也不见业内有其他团队跳出来声称自己比人工T0强，目前市场上几家接程序化T0券的公司靠的是比人工交易员低一大截的提成，以及部分公司无力组建人工交易员团队，同时给出的提成又无法满足独立运营人工交易员团队的需求；第二，从2018年以来，很多期货高频团队受外资竞争影响，原有业务盈利下降非常厉害，甚至到了生存不下去的地步，因此逐步转型股票T0。实际上，这个市场的资金容量和利润空间都是极其有限的，但是由于私募行业整体上的封闭性和18年以来各大券商私募的错误宣传，导致这些人认为程序化T0是一个人傻钱多的行业，实际上到目前为止依然有期货高频团队排队入场，后果是这些人并没有开辟出新的方法来赚钱，反而是在原有的策略上大家相互抢钱，这也解释了为何19下半年在行情并没有明显比17年差的情况下，T0收益下降这么多。  </p><p>作者：匿名用户<br>链接：<a href="https://www.zhihu.com/question/354264347/answer/883277309" target="_blank" rel="noopener">https://www.zhihu.com/question/354264347/answer/883277309</a><br>来源：知乎</p><p><strong>个人见解</strong></p><p>首先，程序化交易无论是从掩盖交易量，还是提升利润空间都是可行的。资金量大的基金，更加希望能够借助程序化交易掩盖自身下单行为造成的市场影响，小规模的基因，则更加提升利润空间。</p><p>但是程序化交易的市场空间更大，T0的交易空间相对较小。在随着外资的引入，市场体系不断趋向于成熟，市场能出现适合做T0的机会注定是越来越少的。从长远看，这应该是符合有效市场理论的（这就不做过多展开了）。</p><p>其次，那么来讨论一下市场越来越成熟，难道程序化交易不受到影响么，受到！但是，问题是日内的T0，基本上要千5的利润空间才会去做，但是，程序化即使千1的利润空间也能去做。</p><p>不妨考虑，一个股票，已知今天收盘前需要平仓，T0由于摩擦、交易成本等，需要千5的利润空间才会去做，因为我要卖出，买入，再卖出，但是程序交易，我只需要千1的空间，因为我只要找机会卖出即可。</p><p>那么随着市场的完善和成熟，高利润点，注定是先受到影响的。所以成熟市场，程序化交易受到的影响比T0要小。</p><p>最后，凡是能做T0的时间点，程序化交易也可以做。但是能做程序化的，T0不一定能做。具体参考上面的例子。</p><p>如果你有任何的见解，请与我联系：<strong><a href="mailto:qianniao0825@icloud.com">qianniao0825@icloud.com</a></strong></p>]]></content>
      
      
      <categories>
          
          <category> financial engineering </category>
          
          <category> T0 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> financial engineering </tag>
            
            <tag> T0 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>financial engineering</title>
      <link href="/2020/05/18/financial-engineering/"/>
      <url>/2020/05/18/financial-engineering/</url>
      
        <content type="html"><![CDATA[<p><strong>This is my first financial engineering-themed blog. Here I want to record a summary of my undergraduate thesis. The specific content can be obtained in the download link below.</strong></p><p>Financial risk is a concept that financial markets cannot ignore. After the 2008 financial crisis, research in this field reached its peak. In recent years, with the trend of trade protectionism and globalization, the market attaches great importance to financial risks. Therefore, it is necessary to carry out risk assessment of financial markets. The stock market is a barometer of the economy, so this paper chooses to make a risk assessment for the index of the stock market. First of all, the index (CSI 300) of the reciprocal income, as a label. Then, 523 sets of factors were extracted and designed, and after the factor effectiveness analysis, the distribution pattern was selected after the collinear processing. The 294 factors obtained were normalized and finally predicted by the LSTM model. At the same time, the prediction results are optimized, and the results after optimization are compared with the prediction results of undeleted, the prediction results of non-log labels, and the prediction results of multi-nonlinear regression, and the evaluation functions designed by themselves are used for analysis.  </p><p>The conclusion shows that in the financial market, logarithm label is more suitable for prediction than non-log label, the optimized LSTM prediction performance is better than multi-nonlinear regression, the evaluation function of design has a good evaluation of the forecast demand, and the necessity of collinear processing of factor data is demonstrated. The treatment of normalized, in this paper is more suitable for the prediction model.  </p><p>You can contact me via the following email: <a href="mailto:qianniao0825@icloud.com">qianniao0825@icloud.com</a></p><p><strong>Full text link</strong> <a href="/download/benke.pdf">download</a></p>]]></content>
      
      
      <categories>
          
          <category> financial engineering </category>
          
          <category> financial risk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> financial engineering </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>“Resources”</title>
      <link href="/2020/05/18/%E2%80%9CResources%E2%80%9D/"/>
      <url>/2020/05/18/%E2%80%9CResources%E2%80%9D/</url>
      
        <content type="html"><![CDATA[<p>Here, I will list some books on using and learning (some of them are written by myself). Hope it helps you.   </p><p><strong>Important:</strong> All books listed here are for learning use only. If you feel that some copyrights have been infringed, please contact me. You can contact me via the following email: <a href="mailto:qianniao0825@icloud.com">qianniao0825@icloud.com</a></p><p><strong>1.  SAS guide 9.4</strong> <a href="/download/SAS9.4.pdf">download</a></p><p><strong>2. Mathematics for Computer Science（MIT2015）</strong><a href="/download/Mcs.pdf">download</a></p>]]></content>
      
      
      <categories>
          
          <category> free download </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Resources </tag>
            
            <tag> download </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tagscloud</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>about me</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[<p>Hello, this is augest-chen.<br>I am a researcher engaged in quantitative finance and modern statistics.<br>You can contact me via the following email: <a href="mailto:qianniao0825@icloud.com">qianniao0825@icloud.com</a><br>You are welcome to exchange any content with me about financial markets and modern statistics.<br>I also use some software: Python, Matlab, R, Mathematica, SAS. I will also write some summaries of my personal experience, which will be put in the blog, I hope these summaries will play a role for you.</p>]]></content>
      
    </entry>
    
    
  
</search>
