<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/27/cyjournal-4/"/>
      <url>/2020/05/27/cyjournal-4/</url>
      
        <content type="html"><![CDATA[<p>今日享受生活</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200527 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coursera 3st data management and visualization</title>
      <link href="/2020/05/27/coursera-2/"/>
      <url>/2020/05/27/coursera-2/</url>
      
        <content type="html"><![CDATA[<p>This is my assignment.</p><p><strong>code:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">'dataset.csv'</span>)<span class="comment"># ge the garminder data i need</span></span><br><span class="line"></span><br><span class="line">print(data.shape[<span class="number">0</span>])<span class="comment"># number of observations(rows)</span></span><br><span class="line">print(data.shape[<span class="number">1</span>]) <span class="comment"># number of variables(columns)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.replace(data[<span class="string">'hivrate'</span>].get(<span class="number">0</span>), <span class="number">9999</span>) <span class="comment">#replace missing data</span></span><br><span class="line">    </span><br><span class="line">c1 = data[<span class="string">'country'</span>]</span><br><span class="line">c2 = data[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">c3 = data[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">c4 = data[<span class="string">'employrate'</span>]</span><br><span class="line">c5 = data[<span class="string">'hivrate'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Separate the data I need into series</span></span><br><span class="line"></span><br><span class="line">aw = [c1,c2,c3,c4,c5] <span class="comment"># Convert data to a list</span></span><br><span class="line">result = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] <span class="comment"># Form an empty list to store the results</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>): <span class="comment"># Generate a statistical table for each column</span></span><br><span class="line">    w = aw[ii] <span class="comment"># Gets the specified column</span></span><br><span class="line">    </span><br><span class="line">    df_show = pd.DataFrame(columns=[<span class="string">'frequency'</span>, <span class="string">'percent'</span>, <span class="string">'cumlativefrequency'</span>,<span class="string">'cumlativepercent'</span>])<span class="comment"># Create an empty dataframe</span></span><br><span class="line">    </span><br><span class="line">    fc1 = pd.value_counts(w)<span class="comment"># Statistical frequency</span></span><br><span class="line">    df_show.index.name = fc1.index.name<span class="comment"># Match coordinate index</span></span><br><span class="line">    df_show[<span class="string">'frequency'</span>] = fc1 <span class="comment"># Data matching</span></span><br><span class="line"></span><br><span class="line">    fc2 = pd.value_counts(w,normalize = <span class="literal">True</span>) <span class="comment">#frequency</span></span><br><span class="line">    df_show[<span class="string">'percent'</span>] = fc2 <span class="comment">#Data matching</span></span><br><span class="line"></span><br><span class="line">    v2 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    v1 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    </span><br><span class="line">    df_show= df_show.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,df_show.shape[<span class="number">0</span>]):<span class="comment"># Processing of accumulated data</span></span><br><span class="line"></span><br><span class="line">        v2 = v2 + df_show.iat[i,<span class="number">0</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">2</span>] = v2 <span class="comment">#Store data</span></span><br><span class="line"></span><br><span class="line">        df_show.iat[i,<span class="number">1</span>] = df_show.iat[i,<span class="number">1</span>]*<span class="number">100</span> <span class="comment">#Convert data</span></span><br><span class="line">        v1 = v1 + df_show.iat[i,<span class="number">1</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">3</span>] = v1 <span class="comment"># Store data</span></span><br><span class="line"></span><br><span class="line">    print(df_show) <span class="comment">#show data</span></span><br><span class="line">    result[ii] = df_show <span class="comment"># Store result</span></span><br><span class="line">    </span><br><span class="line">nums =[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">    vs1 = result[i]</span><br><span class="line">    nums[i<span class="number">-1</span>] = data.shape[<span class="number">0</span>] - vs1.iat[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">mark_index = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">4</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">3</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">2</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> data.iat[i,<span class="number">1</span>] == int(<span class="number">9999</span>):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> mark_index:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mark_index.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    </span><br><span class="line">new_datas = data.drop(index = mark_index, axis = <span class="number">0</span> )</span><br><span class="line"></span><br><span class="line">new_datas[<span class="string">'me'</span>] = <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,new_datas.shape[<span class="number">0</span>]):</span><br><span class="line">    new_datas.iat[i,<span class="number">5</span>] = float(new_datas.iat[i,<span class="number">3</span>]) - float(new_datas.iat[i,<span class="number">2</span>]) </span><br><span class="line"></span><br><span class="line">c1 = new_datas[<span class="string">'country'</span>]</span><br><span class="line">c2 = new_datas[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">c3 = new_datas[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">c4 = new_datas[<span class="string">'employrate'</span>]</span><br><span class="line">c5 = new_datas[<span class="string">'hivrate'</span>]</span><br><span class="line">c6 = new_datas[<span class="string">'me'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Separate the data I need into series</span></span><br><span class="line"></span><br><span class="line">aw = [c1,c2,c3,c4,c5,c6] <span class="comment"># Convert data to a list</span></span><br><span class="line">result = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] <span class="comment"># Form an empty list to store the results</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">6</span>): <span class="comment"># Generate a statistical table for each column</span></span><br><span class="line">    w = aw[ii] <span class="comment"># Gets the specified column</span></span><br><span class="line">    </span><br><span class="line">    df_show = pd.DataFrame(columns=[<span class="string">'frequency'</span>, <span class="string">'percent'</span>, <span class="string">'cumlativefrequency'</span>,<span class="string">'cumlativepercent'</span>])<span class="comment"># Create an empty dataframe</span></span><br><span class="line">    </span><br><span class="line">    fc1 = pd.value_counts(w)<span class="comment"># Statistical frequency</span></span><br><span class="line">    df_show.index.name = fc1.index.name<span class="comment"># Match coordinate index</span></span><br><span class="line">    df_show[<span class="string">'frequency'</span>] = fc1 <span class="comment"># Data matching</span></span><br><span class="line"></span><br><span class="line">    fc2 = pd.value_counts(w,normalize = <span class="literal">True</span>) <span class="comment">#frequency</span></span><br><span class="line">    df_show[<span class="string">'percent'</span>] = fc2 <span class="comment">#Data matching</span></span><br><span class="line"></span><br><span class="line">    v2 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    v1 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    </span><br><span class="line">    df_show= df_show.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,df_show.shape[<span class="number">0</span>]):<span class="comment"># Processing of accumulated data</span></span><br><span class="line"></span><br><span class="line">        v2 = v2 + df_show.iat[i,<span class="number">0</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">2</span>] = v2 <span class="comment">#Store data</span></span><br><span class="line"></span><br><span class="line">        df_show.iat[i,<span class="number">1</span>] = df_show.iat[i,<span class="number">1</span>]*<span class="number">100</span> <span class="comment">#Convert data</span></span><br><span class="line">        v1 = v1 + df_show.iat[i,<span class="number">1</span>] <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">3</span>] = v1 <span class="comment"># Store data</span></span><br><span class="line"></span><br><span class="line">    print(df_show) <span class="comment">#show data</span></span><br><span class="line">    result[ii] = df_show <span class="comment"># Store result</span></span><br></pre></td></tr></table></figure><p><strong>console and analysis:</strong></p><p><img src="/images/con.png" alt="alt"></p><p>To be specific：</p><p>No missing data here. This data mainly shows all countries. It’s evenly distributed</p><p><img src="/images/res1.png" alt="alt"></p><p>The following shows the proportion of the military, which is the same in almost every country. So they are evenly distributed. (I mean the frequency of proportion)</p><p><img src="/images/res2.png" alt="alt"></p><p>Three countries have the same level of female employment (at 39.5%). It also has the highest frequency.</p><p><img src="/images/res3.png" alt="alt"></p><p>Three employment ratios (47.49%, 61.5%, 58.9%) have occurred three times. This means that employment rates are at this level in three countries.</p><p><img src="/images/res4.png" alt="alt"></p><p>For AIDS rates, 25 countries are at the same level (10%), that is, 10% is also the most frequent rate</p><p><img src="/images/res5.png" alt="alt"></p><p>I use the employment rate minus the female employment rate to get the male employment rate. This data can better help to analyze the impact and relationship between the work rates of different genders on the AIDS rate.Among them, the frequency of male employment rate of 7% is the most, which occurs in four countries.</p><p><img src="/images/res6.png" alt="alt"></p><p><strong>Additional notes:</strong></p><ol><li><p>The variable I selected has no classification variables, so I don’t need to subclassify the original data.</p></li><li><p>Second, the original data is a variable of numeric type, so the usual frequency statistics of the table reveal the relationship between the variables is not obvious. Because the numbers of each country are difficult to agree.</p></li><li><p>For the second submission, I have marked the missing data and explained it. Another blog to go to.</p><p>link:<a href="https://augest-chen.github.io/2020/05/24/coursera-1/#more" target="_blank" rel="noopener">https://augest-chen.github.io/2020/05/24/coursera-1/#more</a></p></li><li><p>For the missing data, I use 9999 instead, and then delete the data one by one. 9999 was chosen because this value could not be within the original data range.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> coursera </category>
          
          <category> data management and visualization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> coursera </tag>
            
            <tag> data management and visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/26/cyjournal-3/"/>
      <url>/2020/05/26/cyjournal-3/</url>
      
        <content type="html"><![CDATA[<p>有的时候，我也不敢相信我和yinan一天微信只发五个消息，也不见一面，即使都在学校。我们这个恋爱居然也就这么谈下去了。真是不可意思</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200526 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IBM WASTON STUDIO 使用指南</title>
      <link href="/2020/05/25/ibm/"/>
      <url>/2020/05/25/ibm/</url>
      
        <content type="html"><![CDATA[<p>IBM Watson 是认知计算系统的杰出代表，也是一个技术平台。认知计算代表一种全新的计算模式，它包含信息分析，自然语言处理和机器学习领域的大量技术创新，能够助力决策者从大量非结构化数据中揭示非凡的洞察。简单来说，Watson能够支持如下方面，包括但不限于：理解自然语言、大数据的理解和分析、动态分析各类假设和问题、精细的个性化分析能力、在相关数据的基础上优化问题解答、在短时间内提炼洞察、发现新的运行模式、在迭代中学习，探索优化的解决方案、云端开发平台，支持生态发展</p><p><strong>上述都是扯淡，到底什么功能用了才知道。</strong></p><p>ibm官方在官网的放了ibm waston studio，兴趣使然想用一下，但是发现guide比较少。干脆自己写一个好了。先放一张官网的截图。</p><p><img src="/images/ij.png" alt="alt"></p><p>初步探索了一下，一个项目（project）基本可以由notebook和spss modeler两个运行的方式，这么说特也许有点不准确，我指的是一个数据源（data asset）可以使用两种方式（不同的code）去进行研究。然后又一个connection的链接，如果本地有mysql这类的数据库，可以直接从数据库中提取数据。实际上waston本身的数据导入的方式也还是比较简单的。</p>]]></content>
      
      
      <categories>
          
          <category> technology </category>
          
          <category> IBM WASTON STUDIO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IBM WASTON STUDIO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tech</title>
      <link href="/2020/05/25/tech-1/"/>
      <url>/2020/05/25/tech-1/</url>
      
        <content type="html"><![CDATA[<p>今天问yinan一个问题：0.3333……3333*3 = ？她告诉我是0.999……99。我差点晕倒。实际上精髓一点讲：这一个极限问题。换得通俗一点，她的数学水平应该是在高等数学以下的。因为本质上：lim0.99999999…=1。这就是说：1和0.9999…表示的是同一个数，只是表示方法的不同。证明如下：</p><p><img src="/images/th.png" alt="alt"></p><p>实际上，对于这个问题，扯点别的。对于这个问题有疑问的人，如果是大学以及以上的学生（接受过高等数学学习），我是觉得有些担忧的。具体如下：</p><p><img src="/images/thr.png" alt="alt"></p>]]></content>
      
      
      <categories>
          
          <category> math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> math </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/25/cyjournal-2/"/>
      <url>/2020/05/25/cyjournal-2/</url>
      
        <content type="html"><![CDATA[<p>最近居然开始矛盾起来，又想快点毕业，又想不毕业。严重怀疑是不是一些哲学的视频看多了，导致心思太活跃了点。想的有点多？？by the way，强烈推荐一下李宗盛的《我是真的爱你》，总感觉李宗盛的声音比别的版本要好听那么一点。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200525 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal</title>
      <link href="/2020/05/24/cyjournal-1/"/>
      <url>/2020/05/24/cyjournal-1/</url>
      
        <content type="html"><![CDATA[<p>今天和yinan终于见面了啦，2020在学校的第一次见面，着实有点久噢。新操场的微风和视野，的确也有点让人沉迷。yinan说还在在读一次大学，我说那你考本校呀，她说，我想和你一起读。哈哈哈这一句话让我暗自有点小幸福哈哈哈</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200524 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coursera 2st data management and visualization</title>
      <link href="/2020/05/24/coursera-1/"/>
      <url>/2020/05/24/coursera-1/</url>
      
        <content type="html"><![CDATA[<p>This is my assignment.</p><p><strong>code:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">'dataset.csv'</span>)<span class="comment"># ge the garminder data i need</span></span><br><span class="line"></span><br><span class="line">print(data.shape[<span class="number">0</span>])<span class="comment"># number of observations(rows)</span></span><br><span class="line">print(data.shape[<span class="number">1</span>]) <span class="comment"># number of variables(columns)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">c1 = data[<span class="string">'country'</span>]</span><br><span class="line">c2 = data[<span class="string">'armedforcesrate'</span>]</span><br><span class="line">c3 = data[<span class="string">'femaleemployrate'</span>]</span><br><span class="line">c4 = data[<span class="string">'employrate'</span>]</span><br><span class="line">c5 = data[<span class="string">'hivrate'</span>]</span><br><span class="line"><span class="comment"># Separate the data I need into series</span></span><br><span class="line"></span><br><span class="line">aw = [c1,c2,c3,c4,c5] <span class="comment"># Convert data to a list</span></span><br><span class="line">result = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>] <span class="comment"># Form an empty list to store the results</span></span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>): <span class="comment"># Generate a statistical table for each column</span></span><br><span class="line">    w = aw[ii] <span class="comment"># Gets the specified column</span></span><br><span class="line">    </span><br><span class="line">    df_show = pd.DataFrame(columns=[<span class="string">'frequency'</span>, <span class="string">'percent'</span>, <span class="string">'cumlativefrequency'</span>,<span class="string">'cumlativepercent'</span>])<span class="comment"># Create an empty dataframe</span></span><br><span class="line"></span><br><span class="line">    fc1 = pd.value_counts(w)<span class="comment"># Statistical frequency</span></span><br><span class="line">    df_show.index.name = fc1.index.name<span class="comment"># Match coordinate index</span></span><br><span class="line">    df_show[<span class="string">'frequency'</span>] = fc1 <span class="comment"># Data matching</span></span><br><span class="line"></span><br><span class="line">    fc2 = pd.value_counts(w,normalize = <span class="literal">True</span>) <span class="comment">#frequency</span></span><br><span class="line">    df_show[<span class="string">'percent'</span>] = fc2 <span class="comment">#Data matching</span></span><br><span class="line"></span><br><span class="line">    v2 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line">    v1 =<span class="number">0</span>;<span class="comment"># Pre allocate memory, speed up</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,df_show.shape[<span class="number">0</span>]):<span class="comment"># Processing of accumulated data</span></span><br><span class="line"></span><br><span class="line">        v2 = v2 + df_show[<span class="string">'frequency'</span>].get(i) <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">2</span>] = v2 <span class="comment">#Store data</span></span><br><span class="line"></span><br><span class="line">        df_show.iat[i,<span class="number">1</span>] = df_show[<span class="string">'percent'</span>].get(i)*<span class="number">100</span> <span class="comment">#Convert data</span></span><br><span class="line">        v1 = v1 + df_show[<span class="string">'percent'</span>].get(i) <span class="comment">#Take out data and accumulate</span></span><br><span class="line">        df_show.iat[i,<span class="number">3</span>] = v1 <span class="comment"># Store data</span></span><br><span class="line"></span><br><span class="line">    print(df_show) <span class="comment">#show data</span></span><br><span class="line">    result[ii] = df_show <span class="comment"># Store result</span></span><br></pre></td></tr></table></figure><p><strong>console and analysis:</strong></p><p><img src="/images/re.png" alt="alt"></p><p>To be specific：</p><p><img src="/images/a1.png" alt="alt"></p><p>No missing data here. This data mainly shows all countries. It’s evenly distributed</p><p><img src="/images/a2.png" alt="alt"></p><p>Data for 49 countries are missing, accounting for 23% of the total. This means that there are 49 (23%) countries that do not show their share of the military.</p><p><img src="/images/a3.png" alt="alt"></p><p>Data from 35 countries are missing, accounting for 16.43% of the total. This means that 35 (16.43%) countries did not show their female employment rate.</p><p><img src="/images/a4.png" alt="alt"></p><p>Data from 35 countries are missing, accounting for 16.43% of the total. This means that there are 35 (16.43%) countries that do not show their overall employment rate.</p><p><img src="/images/a6.png" alt="alt"></p><p>Data from 66 countries are missing, accounting for 30.98% of the total. This means that there are 35 (30.98%) countries that do not show their HIV rate<br>Considering that my data is not classified data, I don’t do too much analysis on frequency here.</p>]]></content>
      
      
      <categories>
          
          <category> coursera </category>
          
          <category> data management and visualization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> coursera </tag>
            
            <tag> data management and visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>负数开三次方根后出现复数问题</title>
      <link href="/2020/05/24/tech/"/>
      <url>/2020/05/24/tech/</url>
      
        <content type="html"><![CDATA[<p>今天在做数值分析的时候，遇到一个有意思的情况。当我在python3.7中使用pow函数，对一个负数计算三次方根后，发现结果带有复数。具体结果如下：</p><p><img src="/images/py.png" alt="alt"></p><p>实际上为了验证是否是源代码出错，我又在mathematica上面做了一遍计算，结果如下：</p><p><img src="/images/mma.png" alt="alt"></p><p>那么根据两个软件的结果对比，应不是程序源码的问题。本质上这是一个数学问题：</p><p>首先，$ (x)^3 = -8 $，这是一个一元三次方根，根据一元n次方程的在复数领域内有n个根（n为正整数）。且复数的n次方根，可以直接得到如下的求解公式：</p><p><img src="/images/ma.png" alt="alt"></p><p>看到这里，我相信大部分就明白了，按道理这个计算是有三个结果的，但是计算机程序默认是选择了一个主值。具体根据计算机程序而已，有的会取（-pi，pi]。当然，对于主值的选择，一般是根据幅角最小来选择的。</p><p>关于如何展示所有结果，用mathematica的话：</p><p>cube root of -8</p><p>她就展示所有的结果。</p>]]></content>
      
      
      <categories>
          
          <category> math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> math </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>房产税</title>
      <link href="/2020/05/24/fiance/"/>
      <url>/2020/05/24/fiance/</url>
      
        <content type="html"><![CDATA[<p>房产税是最近热议的一个话题，实际上在中国房产是一个很重要的经济支撑部分。房地产对于中国的经济影响，几乎可以类比股市对于美国的经济。房地产实际上有双重属性。一个是基本需求，社会福利性质，这是居民的刚需。另一个是在信用货币体系下，投资者和投机者一般会采用实物保值。房地产就吸引了大量的投机资本。在中国这种情况更加严重一些，因为国内没有房地产税，从而加剧了这种投机资本的进入。</p><p>这些投资或者投机能够保值么，倒也不见得。理由是房地产的价格也是和产业布局相互连接的。以美国的底特律为例子，美国汽车公司一破产，大量的工人失业，但是房产价格10、20多美元，但是你一买，就需要就缴纳大量的税额。那么既然无法实现保值，或者说保值风险较大，那么就应该对这类的资本进行限制，避免产生更大的风险。</p><p>这也就是个人对于未来中国2020-2025年的中国股市的指数有可以增长30%-50%的预期空间的来源。当资本不在进入房地产或者说从房地产转向其他领域的时候，其他领域的发展一定是能够得到发展。</p><p>再来讨论房产税的可行性，实际上中国地方政府的税收主要是来源于土地增值。如果推进房产税，财政收入会受到影响。同样的户口制度也会给房产税的推进带来冲击。这实际上是财政税收制度不合理导致的。</p><p>考虑中国的房地产泡沫问题，不妨采用类比美国市场上的垃圾债的问题。采用当年四大国有银行上市前，进行的坏账剥离，成立专门的资产管理公司进行管理，应该是可以较为妥善的处理的。</p><p>那么在进行坏账剥离的前提，就是首先需要对于全国的房地产进行统一登记（这一点极其有必要）。具体来说，城市的房地产需要登记所有权、购房资金来源、购房时间、所有人等都需要进行登记，不仅城市的需要登记，农村的也需要进行登记。在这过程中，也可以顺带明确负债买房的比例、打击一下反腐。在这个步骤之后，就根据房产的数量和质量可以确定房产税率了。</p><p>之后还需要确定的是，房产税征收之后的去向，个人认为，房产税的征收之后应该主要流向于公共服务等社会福利的提供。倒不是说税收收入不流向于社会福利的提供，而是个人认为这一税收应该形成类似专项税的效应。对于一些农民工等这类在社会劳动分工中提供了价值的，但是没有购房的群体。不应该征收房产税。反而应该利用房产税税收，来提供福利。</p><p>总结一下，我设想的房产税是，在全国财产管理信息统一登记之后，对于二套房以及以后的房地产进行征收的，并且用以补贴第一套房产的征收机制。</p>]]></content>
      
      
      <categories>
          
          <category> finance </category>
          
          <category> 20200524 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> economy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyjournal 5</title>
      <link href="/2020/05/23/cyjournal/"/>
      <url>/2020/05/23/cyjournal/</url>
      
        <content type="html"><![CDATA[<p>明儿见要见到我的狗子了，有点小期待噢。今天无题。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200523 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实体经济发展的一些思考</title>
      <link href="/2020/05/22/finance/"/>
      <url>/2020/05/22/finance/</url>
      
        <content type="html"><![CDATA[<p>最近有如下思考：</p><p>首先，我个人观点是金融业击垮实体经济的的一个重要原因在于，市场上不同行业的利润率差异过大导致的。</p><p>当金融行业的利润率远高于市场上其他实体行业的利润率时，市场上的投资者也就不会将投资目标放到其他行业上去了。也就导致了其他行业的衰落。引申开来：国进民退，也是如此。</p><p>其次，作为解决的方案，应该是政府统计的各行业的行业平均利润率，对于利润率高的行业，进行征税，低的进行减税，从而实现资本要素有序流动。</p><p>目前，根据现有网上资料，除了纽约大学有美国的行业平均利润率数据以外，其他国家似乎都是没有这一数据的统计的。所以，个人认为可以进行统计，至于是否有必要进行公开，这个可以后续在进行商讨。但是毫无疑问，这一数据，是对于宏观调控起到很好的作用的。</p><p>另外，眉山剑客陈平的对于经济学的看法个人十分推荐，值得一看。</p>]]></content>
      
      
      <categories>
          
          <category> finance </category>
          
          <category> 20200522 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> economy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyJournal 4</title>
      <link href="/2020/05/22/lovestory-3/"/>
      <url>/2020/05/22/lovestory-3/</url>
      
        <content type="html"><![CDATA[<p>有些时候，也很奇怪。我和yinan可以一整天不说话，各自沉迷在自己的世界里。</p><p>果然，学习才是唯一的好伙伴。对我和yinan都是如此，哈哈。</p><p>话说起来，最近追星的风格都是：男的女性化，女的中性化嘛？？我有一些难以理解，不过既然yinan喜欢，那也应该尊重她嘛。毕竟每个人都有自己的爱好。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200522 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>coursera 1st data management and visualization</title>
      <link href="/2020/05/21/coursera/"/>
      <url>/2020/05/21/coursera/</url>
      
        <content type="html"><![CDATA[<p>After learning the first week of coursera data management and visualization courses, I will provide the first week of related assignments in this blog.</p><p><strong>First week assignnment:</strong></p><p><strong>STEP 1</strong>: Choose a data set</p><p>I chose <strong>GapMinder Codebook</strong> as the data set because I am interested in factors that affect the ratio of AIDS patients in a country.</p><p><strong>STEP 2</strong>: Identify a specific topic of interest</p><p>To be precise, I want to explore the correlation between the employment rate and a country ’s AIDS rate.<br>Specifically, I chose the three variables of <strong>female employment rate, employment rate and armed forces rate</strong> to measure and represent the employment rate of a country. Here I regard the number of troops in disguised form as an employment. The <strong>HIV rate</strong> is represented by HIVrate.</p><p>The reasons why I chose the above variables are as follows: </p><ol><li>AIDS is spread by blood. Therefore, I want to highlight the relationship between the employment rate of different genders and the AIDS rate by comparing the employment rate with that of women. </li><li>Entering the military service is usually not counted in the employed population, so the number of troops should also be considered</li></ol><p><strong>STEP 3:</strong> Prepare a codebook of your own (i.e., print individual pages or copy screen and paste into a new document) from the larger codebook that includes the questions/items/variables that measure your selected topics.)</p><p>According to step 2, I selected the following variables on the codebook, and did a simple treatment of the data set.</p><p><img src="/images/v1.png" alt="alt"></p><p><img src="/images/v2.png" alt="alt"></p><p>According to the codebook, it can be clearly seen that the data source of the armed force rate is work development indicators, and the interpretation of the calculation method of this ratio is armed forces personnel. The specific content is listed on the picture, so I won’t go into details here.</p><p>At the end of this step, I gave my collated variable data set. details as follows:</p><p><img src="/images/v3.png" alt="alt"></p><p><strong>STEP 4</strong>: Identify another specific topic of interest</p><p>The second topic, I want to explore the relationship between the employment rate of different genders and the ratio of AIDS by comparing the employment rate with the employment rate of women.</p><p><strong>STEP 5:</strong> Add questions/items/variables documenting this second topic to your personal codebook.</p><p>The selection of variables and the first topic have not changed, so I wo n’t repeat them here.</p><p><strong>STEP 6:</strong>  literature review</p><p>I focus on studying the following article:</p><p>Under normal circumstances, most people will be confused about my choice of employment rate rather than GDP as a variable, and the correlation between research and AIDS rate. But another author ’s research indicates that Education and employment may therefore become the short-run policy targets in combatting HIV / AIDS prevalence rate among the active population and achieving economic growth. Our results equally suggest that GDP growth by itself may not be an HIV / AIDS reduction driver. Therefore, it seems more reasonable to choose the employment rate.</p><p>The author (Channing Arndt) used the CGE method to study the interaction between the AIDS pandemic and unemployment. In the model, the wages of unskilled and semi-skilled workers are fixed relative to the producer price index. As a result, the level of employment by activity is an equilibrium variable. And to get the conclusion, although it is expected that the pandemic will cause the growth rate of the supply of unskilled and semi-skilled labor to be close to zero, the analysis shows that the AIDS pandemic will also reduce the demand for labor and put the unemployment rate on our “AIDS” basis and fiction Compared with the “No AIDS” scenario, there is basically no change. The pandemic suppressed labor demand through three effects.<br>In fact, this shows that the AIDS rate and the employment rate are highly correlated. However, there are still few research results on the ratio of AIDS to different genders.</p><p>[1] BACHMANN M O, BOOYSEN F L. Health and economic impact of HIV/AIDS on South African households: a cohort study [J]. BMC Public Health, 2003, 3(1): 14.</p><p>[2] AFAWUBO K, MATHEY S. Employment and education effects on HIV/AIDS prevalence rate and economic growth: empirical investigation in ECOWAS [J]. Applied economics letters, 2014, 21(11): 755-9.</p><p><strong>STEP 7:</strong> Based on your literature review, develop a hypothesis about what you believe the association might be between these topics. </p><p>Therefore, based on this, I propose the following topics:<br>Is the employment rate related to the AIDS rate？<br>My assumption is<br>The higher the employment rate, the lower the AIDS rate. They show a negative correlation.<br>The higher the female employment rate, the lower the AIDS rate. They show a negative correlation.<br>The higher the military employment rate, the lower the AIDS rate. They show a negative correlation.</p>]]></content>
      
      
      <categories>
          
          <category> coursera </category>
          
          <category> data management and visualization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> coursera </tag>
            
            <tag> data management and visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyJournal 3</title>
      <link href="/2020/05/21/lovestory-2/"/>
      <url>/2020/05/21/lovestory-2/</url>
      
        <content type="html"><![CDATA[<p>今日，啥都没有，注册了几门coursera，看看学习学习。其他的时间在啃MIT的Mathematics for Computer Science的，资料已经上传在resource的那篇文章里。</p><p>说起来似乎有些奇怪，昨日520还是如漆似胶，今天521就是交流几乎为0。当然了天天520那也是甜到发齁了。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200521 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据存放格式与运算速度</title>
      <link href="/2020/05/21/technology-1/"/>
      <url>/2020/05/21/technology-1/</url>
      
        <content type="html"><![CDATA[<p>考虑如下问题，需要在软件中输入一个3*3的矩阵，用以后续的计算，你会采用什么方式体现。</p><p>实际上可能大部分人想到的是：</p><p><img src="/images/juzhen.PNG" alt="alt"></p><p>但是，我们知道一些计算软件的列运算是行运算快很多的，典型的是matlab。</p><p>那么将第一列视为矩阵的行索引，第二列视为列索引，就可以得到以下的结果：</p><p><img src="/images/juzhen2.PNG" alt="alt"></p><p>看起来似乎没有太大的变化，但是当遇到一个规模比较大的矩阵的时候，这样子的做法，其实是可以提高运算速度的。</p><p>此外，倘若延伸到三维数据，或者高维度的数据：</p><p>在第一种方法中，已经较难表示了。</p><p>但是在第二种方法中，只需要增加一列作为新的维度的索引，即可。</p><p>python等基本思路是一样的，第二种方法，基本上都可以在大规模或者高维度的数据处理上，取得较好的计算效率。</p>]]></content>
      
      
      <categories>
          
          <category> technology </category>
          
          <category> data structure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> data structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K-means在Matlab的应用</title>
      <link href="/2020/05/21/technology/"/>
      <url>/2020/05/21/technology/</url>
      
        <content type="html"><![CDATA[<p>K-means算法是一种简单的聚类算法。算法的目的是使各个样本与所在类均值的误差平方和达到最小</p><p><strong>步骤：</strong></p><p>1.初始化数据。输入表达矩阵作为对象集X，输入指定聚类类数N，并在X中随机选取N个对象作为初始聚类中心。设定迭代中止条件。<br>2.进行迭代。根据相似度准则将数据对象分配到最接近的聚类中心，从而形成一类。初始化隶属度矩阵。<br>3.更新聚类中心。</p><p><strong>K-means面临的问题：</strong></p><p>1.收敛问题</p><p>2.类别数量需要预先给定</p><p><strong>解决方法:</strong></p><p>首先设类别数为1，然后逐步提高类别数，在每一个类别数都用上述方法，一般情况下，总方差会很快下降，直到到达一个拐点；这意味着再增加一个聚类中心不会显著减少方差，保存此时的聚类数。</p><p><strong>Matlab code:</strong></p><p>首先，这里个人使用的包是: Statistics and Machine Learning Toolbox</p><p><img src="/images/Matlab.PNG" alt="alt"></p><p>这个包是官方制作的bug也许少一些，稳定一些。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[Idx,C,sumD,D]=Kmeans(X,K)</span><br><span class="line"><span class="comment">%X: N*P的数据矩阵，N为数据个数，P为单个数据维度</span></span><br><span class="line"><span class="comment">%K: 预先给定类数，为整数</span></span><br><span class="line"><span class="comment">%idx: 聚类结果</span></span><br><span class="line"><span class="comment">%C: 聚类中心位置</span></span><br><span class="line"><span class="comment">%sumD: 类间所有点与该类质心点距离之和</span></span><br><span class="line"><span class="comment">%D: 每个点与所有质心的距离</span></span><br><span class="line">[Idx,C,sumD,D]=Kmeans(X,K,<span class="string">'Param1'</span>,Val1,<span class="string">'Param2'</span>,Val2,…)</span><br><span class="line"><span class="comment">%其中，'Param1'，'Param2'这是参数的意思</span></span><br><span class="line"><span class="comment">%其中val1，val2这是参数数值</span></span><br><span class="line"><span class="comment">%主要的有配置参数：有 ‘Distance’(距离测度),‘Start’（初始质心位置选择方法),‘Replicates’（聚类重复次数）  整数</span></span><br><span class="line"><span class="comment">%‘Distance’数值有：‘sqEuclidean’ 欧式距离（默认时，采用此距离方式）,‘cityblock’ 绝度误差和，又称：L1‘cosine’,针对向量‘correlation’  针对有时序关系的值,‘Hamming’ 只针对二进制数据</span></span><br><span class="line"><span class="comment">%‘Start’数值有：‘sample’ 从X中随机选取K个质心点,‘uniform’ 根据X的分布范围均匀的随机生成K个质心,‘cluster’ 初始聚类阶段随机选择10%的X的子样本（此方法初始使用’sample’方法),matrix 提供一K*P的矩阵，作为初始质心位置集合</span></span><br><span class="line"><span class="comment">%‘Replicates’数值有：整数即可。</span></span><br></pre></td></tr></table></figure><p><strong>案例</strong></p><p>这种方法比较简单，就暂时不放案例了。</p>]]></content>
      
      
      <categories>
          
          <category> technology </category>
          
          <category> matlab kmeans </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matlab </tag>
            
            <tag> Kmeans </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>culture</title>
      <link href="/2020/05/20/culture/"/>
      <url>/2020/05/20/culture/</url>
      
        <content type="html"><![CDATA[<p>基本上欧洲的整个发展历史都是和宗教有关系的。但是中西方的文化差异，有的时候我们并不是能很好的理解这种文化，典型是，看电影的时候，不太看得明白一些大史观的电影。我自己对欧洲的历史还算是比较感兴趣，又看了不少的电影，干脆就打算在这里简单介绍一下圣经中的一些背景文化，有了这些背景文化，至少在观看大部分的电影，应该没啥问题了。当然内容肯定还是比较多的，会分好几期写。</p><p>圣经的第一部分的基本可以这么理解，亚当和夏娃生活在伊甸园中，然后偷吃了善恶果被驱逐出了伊甸园。从此，人类呢，自生自灭了。</p><p>数代之后呢，上帝觉得人类太过于堕落了。因此呢，挑选了一个好人，名字叫做诺亚，让他建造一所大船。就在诺亚造好大船，就带着各种动物7对上船了。（记住这个数字）。一上船，就是12天的大雨，之后呢，诺亚放出了各鸽子，只见鸽子飞回来捡了树枝回来。诺亚就知道水位退下去了。</p><p>大部分人看到这里都知道了这就是诺亚方舟的故事，但是好莱坞的电影《诺亚方舟 创世之旅》就是由以这个故事为基础的。</p><p>同样的，灾难片《2012》其中最后地球是被海水淹没大部分地区的灾难设定也就是源自于此。</p><p>更有意思的是，上面提到鸽子，因为鸽子带着树枝回来，诺亚才知道洪水退去了。因此鸽子在西方背景中被视为和平的象征，那就是和平鸽最早的起源。到这里也就不难猜，这个树枝是什么？当然是橄榄树树枝。</p><p>这一期就到这里吧，下一期讲摩西。</p>]]></content>
      
      
      <categories>
          
          <category> culture </category>
          
          <category> culture20200520 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> culture </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyJournal 2</title>
      <link href="/2020/05/20/lovestory-1/"/>
      <url>/2020/05/20/lovestory-1/</url>
      
        <content type="html"><![CDATA[<p>记录感情生活的第二天，今天2020.05.20，和yinan一起出去享受生活啦。</p><p>虽然yinan在前一天，叮咛了几百遍，让我别迟到，然后自己今天迟到了。让我一个人傻乎乎的在地铁站等她。有点生气的噢！</p><p>中午，去了食不食货，这家店还是挺不错的。尤其是这个是冰镇小龙虾，似乎是放了青红酒吧，也许是啤酒，觉得味道还可以，虾的个头也比较大。满足～</p><p><img src="/images/shibushihuo.JPG" alt="alt"></p><p>可惜了龙骨感觉就一般了，我以为是烘箱烘的肉，结果却是腌制的，味道也一般吧。皮皮虾的个头倒是甚合我心。捞汁毛豆味道也比较有特色，具体形容起来就是，辣椒油混合了醋，再加点糖？感觉挺喜欢的这个口味的。</p><p>下午就去撸猫啦，yinan还忽悠我我，说是去鬼屋哈哈哈。以为我胆小吗？？</p><p><img src="/images/maoshe1.JPG" alt="alt"></p><p><img src="/images/maoshe2.JPG" alt="alt"></p><p>可惜，下午可能去的时候猫舍，猫猫们似乎都在晒太阳睡觉。不过还是挺可爱的。</p><p>最后是花鸟市场啦，展示一下下午的收获。</p><p>买给yinan的花儿</p><p><img src="/images/hua1.JPG" alt="alt"></p><p>我的最爱郁金香</p><p><img src="/images/hua2.jpg" alt="alt"></p><p>超大束的进口满天星</p><p><img src="/images/hua3.jpg" alt="alt"></p><p>写到最后突然意识到，今天大概是在一起三年了。</p><p>也算得上是一人两花三年了</p><p><img src="/images/end.JPG" alt="alt"></p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200520 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cyJournal 1</title>
      <link href="/2020/05/19/lovestory/"/>
      <url>/2020/05/19/lovestory/</url>
      
        <content type="html"><![CDATA[<p>尝试记录一下自己的感情生活，也算是记录自己的生活吧。这是第一篇关于自己的情感生活的blog。实际上知道我的人都知道，我不怎么喜欢将一些情感生活记录下来。但是还是想突破的尝试一下。现在是2020.5.19.19:00，大部分情侣还是和往常一样在准备着如何过5.20。我和yinan也不例外。</p><p>实际上，今天我委婉的向她表达了，我觉得一年中不需要过这么多的纪念日，她的对与纪念日的要求可以说是很细致了，从早到晚都安排的满满的，每一次都能给我很多的惊喜。也不知明天她给我的惊喜是什么？</p><p>但是，为什么我还是今天委婉的表达了，可以不需要过这么多纪念日呢，其实准确的说，我是觉得绝大多数的纪念日可以通过出去吃个饭，去买点喜欢的，来庆祝。而，只有少部分的生日、纪念日等需要相对隆重的仪式感。我只是觉得每个小日子都过的很有仪式感，会显得很累。但是我想说明的是，过的有仪式感和过的累，并不是划等号的。更加准确的说，我觉得仪式感可以换更加多样化的方式获得，而不是单一化的过节日来获得。（我知道yinan是一个非常看重仪式感的人）。</p><p>她今天可能不是很能理解我的言语，似乎有些生气了。希望她能理解吧。</p>]]></content>
      
      
      <categories>
          
          <category> storys </category>
          
          <category> 20200519 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cyJournal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>financial engineering 2</title>
      <link href="/2020/05/19/financial-engineering-1/"/>
      <url>/2020/05/19/financial-engineering-1/</url>
      
        <content type="html"><![CDATA[<p><strong>算法交易和T0交易的区别</strong></p><p>在其他地方看一个博主的回答个人觉得比较符合实际（2020.5.19日以前的情况），在引用完全文后，还有个人的一些见解。</p><p>T0和算法交易从模型层面上来讲，区别并不是很大。都是基于股票横截面和时序数据做短周期预测，只是由于T0需要承担手续费，而算法交易则需要每天把交易需求全部做完，需要更多的交易信号以保证这一点，所以从信号强度来讲T0的信号强度会比算法交易大很多，同时信号个数会比算法交易少很多。不过算法比T0复杂的地方在于挂撤单和交易进度的控制，很多时候如果持续没有合适的信号或者时间比较紧张，挂单又不能成交，只能去敲一些对手价，这个时候就会产生亏损，如何控制交易进度并减少敲对价产生的损失，这又是另外一个问题了。</p><p>回到这个问题，那个方向更有前途。从目前业内状况看来，在任何一家alpha靠谱且管理规模大于2个亿的私募，算法交易都是比T0有前途的多的方向，整个方向的利润空间，生存压力都不是程序化T0所能想象的。这一点可能跟外界了解的区别甚大，这其中缘由，恐怕是18年各个券商私募的一轮造神运动中把T0吹上了天，而外界往往又不了解算法交易的利润空间所致，毕竟各位大佬们出去吹牛，可以吹我们程序化T0年化30%，可是没法吹算法交易年化30%，因为这理论上就不可能。</p><p>从截止本文的现实来看，算法交易至少在以下几个方面是远胜于T0的</p><p><strong>一、利润空间</strong></p><p>以一家靠谱且规模较小的私募为例，假设其总的股票持仓为2亿，每天的换手率25%，一个靠谱的算法交易员，其单边收益应该在万三到万六之间，这里取万4，双边就是万八，那么每天的底仓收益率大概是万二左右，年化是5%，大概对应业绩是1000万。5%在T0行业是什么概念呢，17年人工T0比较厉害的团队7%左右，程序化能做到3-4%就不错了。18年比较厉害的人工交易员团队能做到3-5%，程序化3%都有困难，19年除开上半年比较疯狂的几个月，下半年人工都做不到每天万一，程序化收益能做到年化1.5%已经不算差，也就是说，除了大牛市小牛市，程序化T0对底仓收益的贡献都是远低于算法交易的；</p><p><strong>二、资金容量</strong></p><p>前面说到算法交易信号强度要求低，触发次数多，而且有很多单纯的挂单成交，而T0由于要计算手续费，必然会要求比较强的信号，因此触发次数少很多，这就会带来另外一个问题，资金容量。比如一个T0的信号，可能要求强到有千3左右的费后预期收益才会去做，因为考虑到手续费和冲击成本，抢单难度，低于这个预期收益的信号实盘中可能会亏钱，而算法交易则不同，由于不需要手续费，可以做比较弱的信号，而此时的抢单难度不高，信号比较多，一次冲击成本也不会太大，因此可能预期有一个千二左右费前收益的信号就会做，考虑到千1.4左右的手续费，实际上这两个信号的强度差距千2.4，这样带来的信号个数可能是5-10倍的差距，相应的资金容量也会有类似的差距，也就是，同样一套模型，在T0上可能是3-5亿资金容量，在算法交易上就会有15-50亿的资金容量，这两者的差距显然是没有任何办法可以弥补的；</p><p><strong>三、竞争压力</strong></p><p>第一、目前国内程序化T0从产生到现在，一直面对一个强大的竞争对手，人工T0。目前业内前几名的私募，比如九坤幻方，都是有成规模的人工T0团队的，也就意味着这些公司的程序化T0在这么几年的发展中，依然比不过人工交易员，也不见业内有其他团队跳出来声称自己比人工T0强，目前市场上几家接程序化T0券的公司靠的是比人工交易员低一大截的提成，以及部分公司无力组建人工交易员团队，同时给出的提成又无法满足独立运营人工交易员团队的需求；第二，从2018年以来，很多期货高频团队受外资竞争影响，原有业务盈利下降非常厉害，甚至到了生存不下去的地步，因此逐步转型股票T0。实际上，这个市场的资金容量和利润空间都是极其有限的，但是由于私募行业整体上的封闭性和18年以来各大券商私募的错误宣传，导致这些人认为程序化T0是一个人傻钱多的行业，实际上到目前为止依然有期货高频团队排队入场，后果是这些人并没有开辟出新的方法来赚钱，反而是在原有的策略上大家相互抢钱，这也解释了为何19下半年在行情并没有明显比17年差的情况下，T0收益下降这么多。  </p><p>作者：匿名用户<br>链接：<a href="https://www.zhihu.com/question/354264347/answer/883277309" target="_blank" rel="noopener">https://www.zhihu.com/question/354264347/answer/883277309</a><br>来源：知乎</p><p><strong>个人见解</strong></p><p>首先，程序化交易无论是从掩盖交易量，还是提升利润空间都是可行的。资金量大的基金，更加希望能够借助程序化交易掩盖自身下单行为造成的市场影响，小规模的基因，则更加提升利润空间。</p><p>但是程序化交易的市场空间更大，T0的交易空间相对较小。在随着外资的引入，市场体系不断趋向于成熟，市场能出现适合做T0的机会注定是越来越少的。从长远看，这应该是符合有效市场理论的（这就不做过多展开了）。</p><p>其次，那么来讨论一下市场越来越成熟，难道程序化交易不受到影响么，受到！但是，问题是日内的T0，基本上要千5的利润空间才会去做，但是，程序化即使千1的利润空间也能去做。</p><p>不妨考虑，一个股票，已知今天收盘前需要平仓，T0由于摩擦、交易成本等，需要千5的利润空间才会去做，因为我要卖出，买入，再卖出，但是程序交易，我只需要千1的空间，因为我只要找机会卖出即可。</p><p>那么随着市场的完善和成熟，高利润点，注定是先受到影响的。所以成熟市场，程序化交易受到的影响比T0要小。</p><p>最后，凡是能做T0的时间点，程序化交易也可以做。但是能做程序化的，T0不一定能做。具体参考上面的例子。</p><p>如果你有任何的见解，请与我联系：<strong><a href="mailto:qianniao0825@icloud.com">qianniao0825@icloud.com</a></strong></p>]]></content>
      
      
      <categories>
          
          <category> financial engineering </category>
          
          <category> T0 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> financial engineering </tag>
            
            <tag> T0 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>financial engineering</title>
      <link href="/2020/05/18/financial-engineering/"/>
      <url>/2020/05/18/financial-engineering/</url>
      
        <content type="html"><![CDATA[<p><strong>This is my first financial engineering-themed blog. Here I want to record a summary of my undergraduate thesis. The specific content can be obtained in the download link below.</strong></p><p>Financial risk is a concept that financial markets cannot ignore. After the 2008 financial crisis, research in this field reached its peak. In recent years, with the trend of trade protectionism and globalization, the market attaches great importance to financial risks. Therefore, it is necessary to carry out risk assessment of financial markets. The stock market is a barometer of the economy, so this paper chooses to make a risk assessment for the index of the stock market. First of all, the index (CSI 300) of the reciprocal income, as a label. Then, 523 sets of factors were extracted and designed, and after the factor effectiveness analysis, the distribution pattern was selected after the collinear processing. The 294 factors obtained were normalized and finally predicted by the LSTM model. At the same time, the prediction results are optimized, and the results after optimization are compared with the prediction results of undeleted, the prediction results of non-log labels, and the prediction results of multi-nonlinear regression, and the evaluation functions designed by themselves are used for analysis.  </p><p>The conclusion shows that in the financial market, logarithm label is more suitable for prediction than non-log label, the optimized LSTM prediction performance is better than multi-nonlinear regression, the evaluation function of design has a good evaluation of the forecast demand, and the necessity of collinear processing of factor data is demonstrated. The treatment of normalized, in this paper is more suitable for the prediction model.  </p><p>You can contact me via the following email: <a href="mailto:qianniao0825@icloud.com">qianniao0825@icloud.com</a></p><p><strong>Full text link</strong> <a href="/download/benke.pdf">download</a></p>]]></content>
      
      
      <categories>
          
          <category> financial engineering </category>
          
          <category> financial risk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> financial engineering </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>“Resources”</title>
      <link href="/2020/05/18/%E2%80%9CResources%E2%80%9D/"/>
      <url>/2020/05/18/%E2%80%9CResources%E2%80%9D/</url>
      
        <content type="html"><![CDATA[<p>Here, I will list some books on using and learning (some of them are written by myself). Hope it helps you.   </p><p><strong>Important:</strong> All books listed here are for learning use only. If you feel that some copyrights have been infringed, please contact me. You can contact me via the following email: <a href="mailto:qianniao0825@icloud.com">qianniao0825@icloud.com</a></p><p><strong>1.  SAS guide 9.4</strong> <a href="/download/SAS9.4.pdf">download</a></p><p><strong>2. Mathematics for Computer Science（MIT2015）</strong><a href="/download/Mcs.pdf">download</a></p>]]></content>
      
      
      <categories>
          
          <category> free download </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Resources </tag>
            
            <tag> download </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tagscloud</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>about me</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[<p>Hello, this is augest-chen.<br>I am a researcher engaged in quantitative finance and modern statistics.<br>You can contact me via the following email: <a href="mailto:qianniao0825@icloud.com">qianniao0825@icloud.com</a><br>You are welcome to exchange any content with me about financial markets and modern statistics.<br>I also use some software: Python, Matlab, R, Mathematica, SAS. I will also write some summaries of my personal experience, which will be put in the blog, I hope these summaries will play a role for you.</p>]]></content>
      
    </entry>
    
    
  
</search>
