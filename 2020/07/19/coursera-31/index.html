<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="xDxeiN8UNesdSzXA443HQ-Oo_3g__1XDd8szZhVPjgg" />



  <meta name="msvalidate.01" content="true" />



  <meta name="yandex-verification" content="true" />




  <meta name="baidu-site-verification" content="mt1uVtI4Qf" />







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="coursera,IBM,IBM AI Engineering Professional Certificate,Machine Learning with Python," />










<meta name="description" content="*回归模型 * 我将向您简要介绍机器学习。 因此，让我们开始吧。 这是从患者身上提取的人体细胞样本， 并且这个细胞具有特征 例如，其团块厚度为6，均匀度单元大小的“ 1”表示其边缘粘附为1，依此类推。 在这一点上，我们可以问的一个有趣的问题是：这是良性还是恶性的 细胞？ 与良性肿瘤相反，恶性肿瘤是可能侵犯周围肿瘤的肿瘤 组织或周围组织扩散，及早诊断可能是患者患病的关键 生存。 可以轻易地假设只有具">
<meta property="og:type" content="article">
<meta property="og:title" content="IBM Machine Learning with Python">
<meta property="og:url" content="https://augest-chen.github.io/2020/07/19/coursera-31/index.html">
<meta property="og:site_name" content="augest-chen">
<meta property="og:description" content="*回归模型 * 我将向您简要介绍机器学习。 因此，让我们开始吧。 这是从患者身上提取的人体细胞样本， 并且这个细胞具有特征 例如，其团块厚度为6，均匀度单元大小的“ 1”表示其边缘粘附为1，依此类推。 在这一点上，我们可以问的一个有趣的问题是：这是良性还是恶性的 细胞？ 与良性肿瘤相反，恶性肿瘤是可能侵犯周围肿瘤的肿瘤 组织或周围组织扩散，及早诊断可能是患者患病的关键 生存。 可以轻易地假设只有具">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-07-19T14:21:31.000Z">
<meta property="article:modified_time" content="2020-07-24T05:19:47.468Z">
<meta property="article:author" content="augest-chen">
<meta property="article:tag" content="coursera">
<meta property="article:tag" content="IBM">
<meta property="article:tag" content="IBM AI Engineering Professional Certificate">
<meta property="article:tag" content="Machine Learning with Python">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://augest-chen.github.io/2020/07/19/coursera-31/"/>





  <title>IBM Machine Learning with Python | augest-chen</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">augest-chen</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            Schedule
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            Sitemap
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://augest-chen.github.io/2020/07/19/coursera-31/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="augest-chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/Wechat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="augest-chen">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">IBM Machine Learning with Python</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-19T16:21:31+02:00">
                2020-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/coursera/" itemprop="url" rel="index">
                    <span itemprop="name">coursera</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/coursera/IBM-AI-Engineering-Professional-Certificate/" itemprop="url" rel="index">
                    <span itemprop="name">IBM AI Engineering Professional Certificate</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/coursera/IBM-AI-Engineering-Professional-Certificate/Machine-Learning-with-Python/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning with Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>*<em>回归模型 *</em></p>
<p>我将向您简要介绍机器学习。 因此，让我们开始吧。 这是从患者身上提取的人体细胞样本， 并且这个细胞具有特征 例如，其团块厚度为6，均匀度单元大小的“ 1”表示其边缘粘附为1，依此类推。 在这一点上，我们可以问的一个有趣的问题是：这是良性还是恶性的 细胞？ 与良性肿瘤相反，恶性肿瘤是可能侵犯周围肿瘤的肿瘤 组织或周围组织扩散，及早诊断可能是患者患病的关键 生存。 可以轻易地假设只有具有多年经验的医生才能诊断出 肿瘤并说出患者是否患上癌症。 对？ 好吧，想象一下，您已经获得了一个包含数千个特征的数据集。 从被认为有发展风险的患者中提取的人类细胞样本 癌症。 对原始数据的分析表明，许多特征存在显着差异 在良性和恶性样本之间。 您可以使用其他患者样本中的这些细胞特征值来得出 早期指示新样本可能是良性还是恶性的。 您应该清理数据，选择适当的算法来构建预测模型， 并训练您的模型以了解数据中良性或恶性细胞的模式。 通过反复遍历数据对模型进行训练后，就可以用来预测 您的新单元格或未知单元格的准确性很高。 这是机器学习！ 这是机器学习模型可以完成医生任务或至少可以帮助您的方法 那位医生可以使过程更快。 现在，让我给出机器学习的正式定义。 机器学习是计算机科学的子领域，它赋予“计算机”以能力 无需明确编程即可学习。” 让我解释一下我说“没有明确编程”时的意思。 假设您有一个动物图像的数据集，例如猫和狗，并且您想要 拥有可以识别和区分它们的软件或应用程序。 您在这里要做的第一件事是将图像解释为一组功能集。 例如，图像是否显示了动物的眼睛？ 如果是这样，它们的大小是多少？ 它有耳朵吗？ 那尾巴呢？ 几条腿？ 它有翅膀吗？ 在机器学习之前，每个图像都将转换为特征向量。 然后，传统上，我们必须写下一些规则或方法才能获得计算机 变得聪明并发现动物。 但是，这是一个失败。 为什么？ 嗯，您可以猜到，它需要很多规则，高度依赖于当前数据集， 并且没有足够的泛化能力来检测样本外的案例。 这是机器学习进入现场的时候。 利用机器学习，我们可以构建一个模型，以查看所有功能集， 及其相应的动物类型，并了解每种动物的模式。 它是由机器学习算法构建的模型。 它无需进行显式编程即可进行检测。 本质上，机器学习遵循的过程与4岁孩子用于学习的过程相同， 了解并区分动物。 因此，受人类学习过程启发的机器学习算法会迭代 从数据中学习，并允许计算机找到隐藏的见解。 这些模型可以帮助我们完成各种任务，例如对象识别，汇总， 推荐，等等。 机器学习以非常有影响力的方式影响社会。 这是一些真实的例子。 首先，您认为Netflix和Amazon如何向用户推荐视频，电影和电视节目？ 他们使用机器学习来提供您可能会喜欢的建议！ 这类似于您的朋友可能会根据以下内容向您推荐电视节目 了解他们喜欢观看的节目类型。 您认为银行在批准贷款申请时如何做出决定？ 他们使用机器学习来预测每个申请人的违约概率，然后批准 或根据该可能性拒绝贷款申请。 电信公司使用其客户的人口统计数据对它们进行细分或预测 他们是否将在下个月退订公司。 我们每天都会看到机器学习的其他许多应用 生活，例如聊天机器人，使用面部识别功能登录我们的手机甚至是电脑游戏。 这些工具均使用不同的机器学习技术和算法。 因此，让我们快速检查一些较流行的技术。 回归/估计技术用于预测连续值。例如，根据房屋的特征来预测房屋价格等事物，或进行估算 汽车发动机的二氧化碳排放量。 分类技术用于预测案件的类别或类别，例如， 单元格是良性还是恶性的，或者客户是否会流失。 例如，可以将相似病例的聚类组找到相似的患者，或者可以使用 用于银行领域的客户细分。 关联技术用于查找经常发生的项目或事件，例如， 通常由特定客户一起购买的杂货。 异常检测用于发现异常和异常情况，例如，它用于 用于信用卡欺诈检测。 序列挖掘用于预测下一个事件，例如点击流 在网站上。 降维用于减少数据大小。 最后，推荐系统将人们的偏好与他人联系起来 口味相似的人，并向他们推荐新商品，例如书籍或电影。 在接下来的视频中，我们将介绍其中一些技巧。 至此，我很确定这个问题已经引起您的注意，“有什么区别 这些天我们不断听到的流行语之间，例如人工智能 （或AI），机器学习和深度学习？” 好吧，让我解释一下两者之间的区别。 简而言之，人工智能试图使计算机智能化以模仿认知功能 人类。 因此，人工智能是一个广泛的通用领域，包括：计算机视觉， 语言处理，创造力和总结。 机器学习是AI的一个分支，涵盖了人工智能的统计部分 情报。 它通过查看数百或数千个示例来教会计算机解决问题， 向他们学习，然后利用这些经验在新情况下解决相同的问题。 深度学习是机器学习的一个非常特殊的领域，计算机实际上可以 自行学习并做出明智的决策。 与大多数机器学习算法相比，深度学习涉及更深层次的自动化。 现在我们已经完成了机器学习的介绍，后续的视频将 着重于检查两个主要组成部分：首先，您将学习目的 机器学习及其在现实世界中的应用范围；和其次，您将获得机器学习主题的总体概述，例如监督学习的主题。 对比无监督学习，模型评估和各种机器学习算法。 因此，既然您已经了解了此旅程中存储的内容，那么让我们继续 我们对机器学习的探索！</p>
<p>我们将讨论如何使用Python进行机器学习。所以让我们开始吧。 Python是一种流行且功能强大的通用编程语言 最近成为数据科学家的首选语言。 您可以使用Python编写机器学习算法，它可以很好地工作。 但是，Python中已经实现了很多模块和库， 这人才更轻松的使用它。 我们将在本堂课中介绍python包 并在本堂课中使用它，从而令您有更好的实践经验。 第一个包是NumPy 他是一个数学库，用于处理Python中的N维数组。 它使您能够高效且有效地进行计算。 它比普通的Python更好，因为它具有惊人的功能。 例如，对于使用数组（array），字典（dictionary）， 函式（功能），数据类型和使用你需要知道的图像NumPy。 SciPy是数值算法和领域特定工具箱的集合， 包括信号处理，优化， 和统计等等。 SciPy是一个有用的科学和综合计算的好库。 Matplotlib是一个非常受欢迎的绘图包，提供2D绘图， 以及3D绘图。 这三个基于python建造的包对于想要解决现实问题的数据科学家来说 是一笔很好的资产。 如果您不熟悉这些包裹， 我建议您先去学习《使用Python进行数据分析》这堂课。 本课程涵盖了这些包中的大多数有用的知识。 Pandas库是一个非常高级的Python库 它提供了高性能，易于使用的数据结构。 它具有许多有用的数据导入，操作和分析的功能。 特别是，它提供数据结构（data structure）和 操作数值表和时间序列的操作。 SciKit Learn是多种算法和工具 机器学习这是我们的重点 您将在这堂课中学习如何使用它。 因为我们在lab中会使用到Scikit学习 让我解释并告诉你为什么它在数据科学家中如此受欢迎。 SciKit Learn是一个免费的Python编程语言机器学习库。 它有大部分的分类， 回归和聚类算法， 他是专门为了python的数值和科学库：NumPy和Scipy 而设计出来的。 此外，它包括非常好的文档。 最重要的是， 使用SciKit Learn和用几行代码写出机器学习模型是一件 非常简单的事情 最初需要在机器学习管道（机器学习管道）中需要完成的 项目已经在Scikit学习中被完成，其中就包括预处理数据（数据的预处理） 特征选择（功能选择），特征提取（功能提取），训练集和测试集的分裂（测试分裂）， 定义算法（algorithm），拟合模型（models）， 调整参数，预测，评估和导出模型。 让我向您展示一个示例，了解SciKit学习在您使用此库时的外观。 您现在不必了解代码，只是看看 只需几行代码即可轻松构建模型。 基本上，机器学习算法受益于数据集的标准化。 如果数据集中存在一些异常值或不同的比例分段， 您必须解决这些。 SciKit学习的预包提供了几个常用的实用功能和反相类 可将原始特征向量 更改为适合的矢量形式。 您必须将数据集分解为训练集和测试集 从而训练您的模型，然后分别测试模型的准确性。 在一行代码中，SciKit学习可以将多重或矩阵分割为 随机训练和测试子集。 然后你可以设置你的算法。 例如，您可以使用支持矢量分类算法内置分类器。 我们将加速度器实例称为CLF并初始化其参数。 现在，您可以通过将训练集传递给 拟合方法来训练您的模型与训练集， CLF模型学会对未知病例进行分类。 然后我们可以使用我们的测试集来进行预测， 然后结果会告诉我们每个未知值的类是什么。 此外，您可以使用不同的指标来评估模型的准确性。 例如，使用重组矩阵来显示结果。 最后，您保存模型。 您可能会发现所有或部分机器学习术语令人困惑，但不要担心， 我们将在以下视频中讨论所有这些主题。 请记住最重要的一点就是， 使用SciKit Learn可以在几行代码中完成机器学习任务。 称为的，，如果您想使用NumPy或SciPy替换完成所有这些操作 虽然可能，但不那么容易。 当然，如果您只使用纯python去完成这些任务， 你会需要大量更多的代码。 </p>
<p>回归，让我们开始看看 该数据集与二氧化碳有关 来自不同汽车的排放量 包括发动机尺寸的汽缸数 油耗和二氧化碳排放量 各种汽车模型的问题 给定这个数据集我们可以预测 使用其他汽车的二氧化碳排放量 字段，例如发动机尺寸或气缸 假设我们有一些历史 来自不同汽车的数据，并假设 第9行之类的汽车尚未 尚未生产，但我们对 估算其近似的二氧化碳排放量 生产后有可能我们可以 使用回归方法来预测 连续值，例如二氧化碳排放量 使用其他一些变量 确实，回归是 预测中的连续值 回归有两种类型 变量一个因变量和一个 或更多个自变量 因变量可以看作是 说明我们研究的目标或最终目标，以及 尝试预测和独立 变量也称为解释性 变量可以看作是导致 那些陈述自变量 通常用X表示，而 因变量用Y a表示 回归模型与Y或 X的函数的因变量，即 自变量的关键 回归是我们的依赖 值应该是连续的，不能是 离散值，但独立 一个或多个变量可以在 绝对的或连续的 测量规模，所以我们要做什么 这是使用的历史数据 一些汽车使用其一个或多个 特征和数据 建立一个模型，我们使用回归来建立 这样的回归估计模型 该模型用于预测 新的或 未知车基本上有两个 回归模型的类型简单 回归和多元回归 简单回归就是当 自变量用于估计 因变量，可以是 线性或非线性 例如预测二氧化碳排放量 使用引擎大小的变量 回归线性基于 之间关系的性质 自变量和因变量 一个以上的自变量是 目前的过程称为多重 线性回归，例如预测 使用发动机尺寸和 给定汽车中的气缸数 再次取决于之间的关系 因变量和自变量 可以是线性或非线性的 回归让我们检查一些样本 本质上是回归的应用 当我们想要 例如估计一个连续值 回归的应用之一 分析可能是在销售领域 预测您可以尝试预测 销售人员的年度总销售额来自 自变量，例如年龄 教育和多年的经验可以 也可用于心理学领域 例如确定个人 基于人口统计学和 我们可以使用的心理因素 回归分析预测价格 根据房屋面积确定房屋面积 卧室的数量等等，我们甚至可以 用它来预测 自变量，例如小时数 工作教育职业性别年龄岁 经验等等，确实可以 找到许多有用的例子 这些和许多中的回归分析 其他领域或领域，例如金融 医疗保健零售以及更多我们有很多 他们每个人都有回归算法 它自己的重要性和具体 他们的申请条件 最合适的，虽然我们已经介绍了 本课程中的一些 您有足够的基础知识来 探索不同的回归技术。</p>
<p>欢迎光临本视频 涵盖您没有的线性回归 需要知道任何线性代数 了解线性回归中的主题 这个高层次的介绍将给 您有足够的背景资料 线性回归才能使用它 有效地解决您自己的问题，因此 让我们开始吧，让我们来看看 该数据集与二氧化碳有关 排放的不同汽车包括 发动机大小的气缸油耗 和各种车型的二氧化碳排放量 问题是给这个数据集可以 我们预测汽车的二氧化碳排放量 使用其他字段，例如引擎尺寸 很简单，是的，我们可以使用线性 回归以预测连续值 例如通过使用其他方法排放二氧化碳 变量线性回归是 线性模型的近似 描述两个或两个之间的关系 简单线性中的更多变量 回归有两个变量 因变量和独立变量 改变线性的关键点 回归是我们的依赖价值 应该是连续的，不能是 离散值但是独立 变量可以在 分类或连续测量 刻度线有两种类型 回归模型很简单 回归和多元回归 简单的线性回归是当 自变量用于估计 例如因变量 使用引擎预测二氧化碳排放量 多个时的大小可变 存在自变量 这个过程叫做多重线性 回归，例如预测二氧化碳 使用发动机尺寸和气缸排放 的汽车，我们在这个视频中的重点是 现在简单的线性回归 线性回归如何工作好吧，让我们 再看一下我们的数据集 要了解线性回归，我们可以 在这里绘制变量，我们展示引擎 大小作为自变量和 使命是我们的目标价值 想预测一个散点图 清楚地表明 一个变量发生变化的变量 解释或可能引起变化 另一个变量也表示 这些变量是线性的 与线性回归相关，您可以 例如，通过数据拟合一条线 随着发动机尺寸的增加， 线性回归可以排放 模拟这些关系 一个好的模型可以用来变量 预测什么 每辆车是如何使用这条线的 现在的预测让我们假设 这条线很适合的时刻 我们可以用来预测的数据 例如，排放未知的汽车 用于发动机尺寸为2.4的样车 你会发现现在的发射是214 让我们来谈谈拟合线 实际上是我们要预测 在本例中使用 独立可变的发动机尺寸 用X 1表示拟合线 传统上作为一个多项式 一个简单的回归问题单X 该模型的形式为theta 0加 在这个方程中的theta 1 X 1是 因变量或预测 值，X 1是独立的 变量theta 0和theta 1是 该行的参数，我们必须 调整θ1称为斜率或 拟合线和theta的梯度0 被称为intercept theta 0和 θ1也称为系数 可以解释的线性方程 这个方程式 是X 1或Y hat的函数 取决于X 1现在的问题是 您将如何通过 点，以及如何确定 线拟合最佳线性回归 估计线的系数 这意味着我们必须计算theta 0和 theta 1找到最适合的线 该行的数据将最好地估计 省略未知数据点 让我们看看如何找到这条线或 更准确地说，我们如何调整 使线条最适合的参数 暂时假设数据 我们已经找到最合适的线 现在获取我们的数据 点并检查它们对齐的程度 这条线最适合这里意味着 如果我们有一辆汽车 发动机尺寸x1等于5.4和实际co 2等于250，其co 2应为 预测非常接近实际值 y等于250，基于 历史数据，但如果我们使用拟合 行或更好地说使用我们的 参数已知的多项式 预测二氧化碳排放量将返回 如果您比较y帽子现在等于340 汽车排放的实际价值 与我们使用我们的预测 模型，您会发现我们有一个 90个单位的错误，这意味着我们的预测 行不准确，此错误也 称为残留误差，所以我们可以说 误差是与数据的距离 指向拟合的回归线 所有残留误差的平均值表明 该行与整个数据的拟合度很差 在数学上进行设置可以显示为 方程的均方误差为 MSE我们的目标是找到一条线 所有这些错误的平均值是 换句话说，最小化平均误差 拟合线的预测 应该最小化 让我们从技术上改写它 线性回归的目的是 最小化该MSE方程并 最小化它，我们应该找到最好的 参数theta0和theta1现在 问题是如何找到零零和 theta one以这样的方式 最小化此错误，我们如何找到 如此完美的路线或另辟way径 我们应该如何找到最佳参数 我们的线应该移到 随机抽签并计算MSE值 每次选择最少的一个 其实我们没有两个选择 在这里，我们可以使用一种数学方法 方法或选项二，我们可以使用 优化方法让我们看看我们如何 可以轻松地使用数学公式 找到theta零和theta一 在零和零之前提到过 简单线性回归中的一个是 拟合线的系数，我们可以 用一个简单的方程式估算这些 给出的系数是 只有两个的简单线性回归 参数并知道theta 0和 θ1是的截距和斜率 我们可以直接估算的线 根据我们的数据，它要求我们 计算独立的均值 以及来自 数据集注意所有数据 必须可用于遍历和 计算可以显示的参数 截距和斜率可以是 使用这些方程式可以计算出 首先估算一下 theta 1这是您如何找到 基于数据X条的线的斜率 是引擎尺寸的平均值 在我们的数据集中，请考虑我们 有九个 在这里上升到第零到八排 计算x1的平均值和平均值 的Y，然后将其插入坡度 方程以找到theta1 XI和yi 等式中的事实是 我们需要重复这些计算 在我们数据集中的所有值中，我 指x或y的右值 应用所有值我们找到theta一 等于39这是我们的第二个参数 用于计算第一个参数 现在是线的截距 我们可以将theta1插入线路 方程找到theta 0很容易 计算出theta 0等于125点 七个四个，所以这是两个 theta 0是的那行的参数 也称为偏差系数和 θ1是 二氧化碳排放量列，请注意 真的不需要记住 计算这些参数的公式 就像大多数用于 python r和scala中的机器学习 可以轻松为您找到这些参数 但是了解如何 现在可以了，我们可以写下来 该线的多项式，所以我们知道如何 找到最适合我们的数据及其 等式现在的问题是我们如何 用它来预测新物质的排放 我们根据它的发动机尺寸 找到了线性的参数 进行方程式预测非常简单 作为求解特定方程式的方法 一组输入想象我们正在预测 二氧化碳排放量或发动机尺寸的Y或X 对于创纪录的9的汽车 我们的线性回归模型 这个问题的表示将是 y帽子等于theta 0加theta 1 x1或者如果我们将其映射到我们的数据集 将是二氧化碳排放等于theta零 加上我们看到的theta 1发动机尺寸 可以使用找到theta 0 theta 1 我们刚才谈到的方程式 发现我们可以插入方程式 例如，线性模型让我们使用theta 0等于125，θ1等于39，所以我们 可以将线性模型重写为co2 排放等于125加39发动机尺寸 现在让我们插入第九行 数据集并计算二氧化碳排放量 对于引擎大小为2.4的汽车 二氧化碳排放等于125加39倍 2.4因此我们可以预测 该特定汽车的二氧化碳排放量将 218点六让我们谈谈 为什么线性回归如此有用 简直是最基本的回归 使用和理解实际上是一个原因 为什么线性回归如此有用是 很快 它也不需要调整 参数，例如调整 K参数和K最近邻居或 神经网络的学习率 不用担心线性 回归也很容易理解。</p>
<p>在这个视频里， 我们将介绍模型评估。 因此，让我们开始吧。 回归的目标是建立一个模型来准确预测未知病例。 为此，我们必须在构建模型后执行回归评估。 在本视频中，我们将介绍和讨论两种类型的 可用于实现此目标的评估方法。 这些方法是在同一数据集上进行训练和测试，以及对训练/测试进行拆分。 我们将讨论这些是什么， 以及使用每种模型的利弊。 另外，我们将介绍一些用于回归模型准确性的指标。 让我们看一下第一种方法。 在考虑评估模型时， 我们显然希望选择一种能够为我们提供最准确结果的产品。 所以，问题是 我们如何计算模型的准确性？ 换句话说，我们可以信任这个模型来预测 使用一个未知样本 给定的数据集并建立了线性回归等模型？ 解决方案之一就是选择一部分数据集进行测试。 例如，假设我们的数据集中有10条记录。 我们将整个数据集用于训练， 然后我们使用此训练集建立模型 现在，我们选择数据集的一小部分， 例如第六至九行 但没有标签。 这个集称为测试集， 有标签， 但标签不用于预测，仅用作基本事实。 这些标签称为测试集的实际值。 现在我们通过测试部分的功能集 建立模型并预测目标值。 最后，我们比较预测值 我们的模型与测试集中的实际值。 这表明我们的模型实际上有多精确。 有不同的指标来报告模型的准确性， 但大多数都基于 预测值和实际值的相似性。 让我们看一下最简单的指标之一 计算我们的回归模型的准确性。 如上所述，我们只是将实际值y与预测值进行比较， 对于测试集，这被称为。 模型的误差计算为平均差 所有行的预测值和实际值之间。 我们可以将此误差写为方程式。 因此，我们刚才讨论的第一种评估方法是最简单的方法， 在同一数据集上进行训练和测试。 本质上，这种方法的名称说明了一切。 您在整个数据集上训练模型， 然后使用同一数据集的一部分对其进行测试。 在一般意义上， 当您使用知道每个数据点目标值的数据集进行测试时， 您可以获取一定比例的模型准确预测。 这种评估方法很可能具有很高的培训准确性，并且 由于 模型从训练中知道所有测试数据点。 什么是训练精度和样本外精度？ 我们说过，对同一个数据集进行训练和测试可以提高训练精度， 但是训练准确度到底是什么？ 训练准确性是 使用测试数据集时模型可以做出正确的预测。 但是，高训练精度并不一定是一件好事。 例如，具有高训练精度可能会导致数据过拟合。 这意味着该模型过度训练了数据集， 可能会捕获噪声并生成非通用模型。 样本外准确性是指正确预测的百分比 该模型使用的数据尚未经过训练。 在同一数据集上进行训练和测试很可能会 由于过度拟合的可能性，样本外准确性较低。 我们的模型必须具有 样本外准确性高，因为我们模型的目的是 当然，要对未知数据做出正确的预测。 那么，如何提高样本外准确性呢？ 一种方法是使用另一种评估方法，称为训练/测试拆分。 通过这种方法，我们选择了一部分数据集进行训练，例如， 从零到五排 其余的用于测试， 例如，第六至九行。 该模型基于训练集。 然后，将测试特征集传递给模型进行预测。 最后，预测值 将测试集与测试集的实际值进行比较。 第二种评估方法称为训练/测试拆分。 训练/测试拆分涉及拆分数据集 分为训练集和测试集， 它们是互斥的。 之后，您将使用训练集进行训练并使用测试集进行测试。 这将提供对样本外准确性的更准确评估，因为 测试数据集不属于用于训练数据的数据集。 对于现实世界中的问题而言，这更为现实。 这意味着我们知道数据集中每个数据点的结果， 非常适合进行测试。 由于此数据尚未用于训练模型， 该模型不知道这些数据点的结果。 因此，从本质上讲，这是真正的样本外测试。 但是，请确保随后使用测试集训练模型， 因为您不想丢失可能有价值的数据。 火车/测试拆分的问题在于 取决于训练和测试数据的数据集。 这种变化导致训练/测试分裂 比在相同数据集上进行训练和测试更好的样本外预测， 但是由于这种依赖性，它仍然存在一些问题。 另一个评估模型称为K折交叉验证， 解决了大多数这些问题。 您如何解决因依赖性导致的高变异？ 好吧，你平均。 让我解释一下K折的基本概念 交叉验证，看看我们如何解决这个问题。 整个数据集由图像左上角的点表示。 如果我们有K等于四倍， 然后我们按如下所示拆分此数据集。 例如在第一折中 我们将数据集的前25％用于测试，其余用于训练。 使用训练集构建模型，并使用测试集评估模型。 然后，在下一轮或第二轮中 数据集的后25％是 用于测试，其余用于训练模型。 再次，计算模型的准确性。 我们继续努力。 最后，将所有四个评估的结果平均。 也就是说，然后将每一折的准确性平均， 请记住，每折都是不同的， 在一个折叠中没有使用训练数据的另一折叠中。 最简单形式的K折交叉验证可进行多次训练/测试拆分， 使用相同的数据集，但每个拆分均不同。 然后，对结果进行平均以产生更一致的样本外精度。 我们想向您展示一个评估模型， 解决了我们先前方法中描述的一些问题。 但是，深入了解K折交叉验证模型 超出了本课程的范围。</p>
<p>我们将介绍模型评估的准确性指标。因此，让我们开始吧。评估指标用于解释模型的性能。 让我们更多地讨论用于回归的模型评估指标。 如上所述，基本上，我们可以比较实际值和预测值， 计算我们的回归模型的准确性。 评估指标，在模型开发中发挥关键作用， 因为它提供了需要改进的领域的洞察力。 我们将审查许多模型评估指标，包括 平均绝对误差，均方误差和均方根误差。 但是在定义这些之前， 我们需要定义错误实际上是什么。 在回归的背景下， 模型的误差是 算法生成的数据点和趋势线。 由于有多个数据点， 错误可以通过多种方式确定。 平均绝对误差是误差绝对值的平均值。 这是最容易理解的指标， 因为这只是平均误差。 均方误差是均方误差的均值。 比平均绝对误差更受欢迎 因为重点更多是针对大错误。 这是由于平方项 与较小的错误相比，较大的错误呈指数增加。 均方根误差是均方误差的平方根。 这是最受欢迎的评估指标之一 因为均方根误差是可以解释的 以与响应向量相同的单位或y单位， 轻松关联其信息。 相对绝对误差，也称为残差平方和， 其中y bar是y的平均值， 取总绝对误差并将其归一化 除以简单预测变量的总绝对误差。 相对平方误差与相对绝对误差非常相似 但是被数据科学界广泛采用， 因为它用于计算R平方。 R平方本身不是错误 但它是模型准确性的常用指标。 它表示数据值有多接近 拟合拟合的回归线。 R平方越高 模型越适合您的数据。 这些指标均可用于量化您的预测。 指标的选择 完全取决于模型的类型 您的数据类型和知识领域。 不幸的是，进一步的审查超出了本课程的范围。 </p>
<p>在这个视频里， 我们将介绍多元线性回归。 如您所知，线性回归模型有两种， 简单回归和多元回归。 简单线性回归是什么时候 一个自变量用于估计因变量。 例如，使用发动机尺寸变量预测CO_2排放量。 实际上，有多个变量可预测CO_2的排放。 如果存在多个自变量， 该过程称为多元线性回归。 例如，使用 发动机尺寸和汽车发动机中的气缸数。 本视频中的重点是多元线性回归。 好是多元线性回归 是简单线性回归模型的扩展。 所以，我建议你经历 如果您尚未观看过简单的线性回归视频，请先观看。 在我们深入研究样本数据集并了解多元线性回归如何工作之前， 我想告诉你它可以解决什么样的问题， 何时应该使用它，特别是 我们可以用它回答什么样的问题。 基本上，多元线性回归有两个应用。 首先，当我们想确定 自变量对因变量的影响。 例如，修订时间，测试焦虑程度， 演讲人数和性别对学生的考试成绩有影响吗？ 其次，它可以用来预测变更的影响，即 了解因变量如何变化 当我们改变自变量时。 例如，如果我们正在查看一个人的健康数据， 多元线性回归可以告诉您多少 该人的血压上升或下降 每个单位的增加或减少 保持其他因素不变的患者体重指数。 与简单的线性回归一样， 多元线性回归是一种预测连续变量的方法。 它使用多个称为独立变量或预测变量的变量 最能预测目标的价值 变量，也称为因变量。 在多元线性回归中 目标值Y 是自变量X的线性组合。 例如，您可以预测汽车可能产生的CO_2 由于诸如汽车的发动机尺寸之类的独立变量而承认， 气缸数和油耗。 多元线性回归非常有用，因为您可以检查 哪些变量是结果变量的重要预测因子。 此外，您还可以了解每个功能如何影响结果变量。 同样，就像简单的线性回归一样， 如果您设法建立这样的回归模型， 你可以用它来预测排放量 未知案例，例如记录9。 通常，模型的形式为y等于theta零， 再加上theta一x_1， 再加上theta两个x_2，依此类推， 直到theta n x_n。 在数学上，我们也可以将其显示为矢量形式。 这意味着它可以显示为两个向量的点积； 参数向量和特征集向量。 通常，我们可以将多维空间显示为theta转置x的方程， 其中theta是多维空间中未知参数的n×一个矢量， x是特征集的向量， 因为theta是系数的向量，并且是 应该乘以x。按照惯例，它显示为转置theta。 Theta也称为回归方程的参数或权重向量。 这两个术语可以互换使用， x是代表汽车的特征集。 例如，x_1表示发动机尺寸，x_2表示气缸，依此类推。 功能集的第一个元素将设置为一个， 因为它将theta零变成截距或偏差 向量乘以参数向量时的参数。 请注意theta转置x in 一维空间是直线的方程式， 这就是我们在简单线性回归中使用的方法。 在更高维度上，当我们有多个输入时 或x线称为平面或超平面， 这就是我们用于多元线性回归的方法。 因此，整个想法是为我们的数据找到最合适的超平面。 为此，与线性回归一样， 我们应该估计theta向量的值 最好预测每一行中目标字段的值。 为了实现这个目标， 我们必须最小化预测误差。 现在的问题是 我们如何找到优化的参数？ 要找到我们模型的优化参数， 我们首先应该了解优化参数是什么， 然后我们将找到一种优化参数的方法。 简而言之，优化参数是导致模型误差最小的参数。 假设我们已经找到模型的参数向量， 这意味着我们已经知道θ矢量的值。 现在我们可以使用模型的第一行的模型和特征集 我们的数据集可以预测第一辆车的二氧化碳排放量，对吗？ 如果将要素集值插入模型方程式， 我们发现你的帽子。 举例来说， 它返回140作为该特定行的预测值， 实际值是多少？ Y等于196。 预测值与实际值196有什么不同？ 好吧，我们可以很简单地将其计算为196减去140， 当然等于56。 在我们的案例中，这仅是针对一排或一辆汽车的模型错误。 与线性回归一样 我们可以说这里的误差是与 数据指向拟合的回归模型。 所有残留误差的平均值表明模型代表数据集的程度， 这称为均方误差或MSE。 在数学上，MSE可以用方程式表示。 尽管这不是暴露多元线性回归模型误差的唯一方法， 这是最受欢迎的方法之一。 我们数据集的最佳模型是所有预测值的误差最小的模型。 因此，多元线性回归的目标是最小化MSE方程。 为了使其最小化，我们应该找到最佳的参数theta，但是如何？ 好的，我们如何找到多元线性回归的参数或系数？ 有许多方法可以估算这些系数的值。 但是，最常见的方法是 普通最小二乘法和优化方法。 普通最小二乘法试图估计 通过最小化均方误差来确定系数。 这种方法使用数据作为矩阵并使用 线性代数运算以估计theta的最佳值。 这种技术的问题是计算的时间复杂度 矩阵运算，因为它可能需要很长时间才能完成。 当数据集中的行数少于10,000时， 您可以将此技术视为一种选择。 但是，对于更大的价值， 您应该尝试其他更快的方法。 第二种选择是使用优化算法来找到最佳参数。 也就是说，您可以使用优化值的过程 通过迭代最小化模型对训练数据的误差来确定系数。 例如，您可以使用梯度下降 以每个系数的随机值开始优化， 然后计算错误并尝试将其最小化 通过y在多次迭代中更改系数。 如果您有大量数据集，则梯度下降法是一种适当的方法。 但是请理解，还有其他估算方法 您可以自己探索的多元线性回归的参数。 找到适合您模型的最佳参数后， 您可以进入预测阶段。 找到线性方程的参数后， 进行预测就像解决一组特定输入的方程式一样简单。 假设我们正在预测CO_2排放或Y 从其他汽车的变量中获得了第9个记录。 我们的线性回归模型表示为 这个问题是y等于theta转置x。 找到参数后， 我们可以将它们插入线性模型的方程式中。 例如，让我们使用theta零等于125， θ等于6.2， θ2等于14，依此类推。 如果我们将其映射到我们的数据集， 我们可以将线性模型重写为CO_2排放等于 125加6.2乘以发动机尺寸， 加14乘以圆柱，以此类推。 如您所见，多元线性回归 估计预测变量的相对重要性。 例如，它表明气缸具有更高的冲击力 与发动机尺寸相比的二氧化碳排放量。 现在，让我们插入数据集的第九行并计算 引擎尺寸为2.4的汽车的CO_2排放量。 因此，CO_2排放等于125加6.2乘以2.4， 再加上14乘以4，依此类推。 我们可以预测，这辆特定汽车的CO_2排放为214.1。 现在，让我解决一些您可能会担心的问题 关于多元线性回归已经有。 如您所见，您可以使用 多个自变量以预测多元线性回归中的目标值。 与使用相比，有时会产生更好的模型 一个简单的线性回归 只有一个自变量来预测因变量。 现在的问题是， 我们应该使用许多自变量进行预测吗？ 我们应该使用数据集中的所有字段吗？ 是否将自变量添加到 多元线性回归模型总能提高模型的准确性？ 基本上，添加太多的自变量而没有 任何理论上的证明都可能导致过拟合模型。 过拟合模型是一个实际问题，因为它也是 您的数据集比较复杂，不够通用，无法用于预测。 因此，建议避免使用许多变量进行预测。 有多种方法可以避免在回归中过度拟合模型， 但是，这超出了本视频的范围。 下一个问题是 自变量应该是连续的吗？ 基本上，可以合并类别自变量 通过将它们转换为数值变量来回归模型。 例如，给定二进制变量（例如汽车类型）， 手动代码为零，自动车代码为零。 最后一点 请记住，多元线性回归是线性回归的一种特殊类型。 因此，两者之间必须存在线性关系 因变量和您的每个自变量。 有很多方法可以检查线性关系。 例如，您可以使用散点图，然后目视检查线性。 如果散点图中显示的关系不是线性的， 那么您需要使用非线性回归。</p>
<p> 我们将介绍非线性回归基础知识。因此，让我们开始吧。这些数据点对应于1960-2014年间的中国国内生产总值或GDP。 第一列是年份，第二列是 中国当年的相应年度国内总收入（美元）。 这就是数据点的样子。 现在，我们有几个有趣的问题。 首先，可以根据时间预测GDP吗？ 其次，我们可以使用简单的线性回归对其进行建模吗？ 确实。如果数据显示出弯曲的趋势，那么线性回归就不会产生 与非线性回归相比，结果非常准确。 只是因为顾名思义， 线性回归假设数据是线性的。 散点图表明，GDP与时间之间似乎存在很强的关系， 但关系不是线性的。 如您所见，增长开始缓慢， 然后从2005年开始， 增长非常显着。 最后，它在2010年代略有减速。 它看起来像是逻辑函数或指数函数。 因此，它需要一种特殊的非线性回归程序估计方法。 例如，如果我们假设这些数据点的模型是指数函数， 例如Y帽子等于Theta零加Theta 一个Theta两个转置X或X的幂， 我们的工作是估算模型的参数，即Thetas， 并使用拟合模型来预测未知或未来情况下的GDP。 实际上，存在许多不同的回归 可以用来适应数据集的外观。 您可以在此处看到二次和三次回归线， 它可以无限地持续下去。 本质上，我们可以将所有这些多项式回归称为 自变量X与 因变量Y建模为X中的N次多项式。 有多种回归类型可供选择， 很有可能会很好地适合您的数据集。 请记住，选择最适合数据的回归很重要。 那么，什么是多项式回归？ 多项式回归使曲线适合您的数据。 所示的次数为3的多项式的简单示例为Y hat等于Theta 0 加Theta 1_X加Theta 2_X平方再加上Theta 3_X立方或乘以3的幂， 其中Thetas是要估计的参数 使模型完全适合基础数据。 虽然X和Y之间的关系是 这里是非线性的，多项式回归不适合它们， 多项式回归模型仍可以表示为线性回归。 我知道这有点令人困惑， 但让我们看一个例子。 给定三阶多项式方程， 通过定义X_1等于X，X_2等于X平方或X等于2的幂，依此类推， 当Y hat等于时，模型将转换为具有新变量的简单线性回归 Theta 0加Theta 1 X_1加Theta 2 X_2加Theta 3 X_3。 这个模型的参数是线性的，对吧？ 因此，该多项式回归被认为是 是传统多元线性回归的特例。 因此，您可以使用与线性回归相同的机制来解决此问题。 因此，多项式回归模型可以使用最小二乘法拟合。 最小二乘是一种估计方法 线性回归模型中的未知参数，方法是将 之间的差异的平方 观察到的因变量 给定的数据集以及通过线性函数预测的数据集。 那么，什么是非线性回归呢？ 首先，非线性回归是一种建模方法 两者之间的非线性关系 因变量和一组自变量。 其次，对于被认为是非线性的模型， Y hat必须是参数Theta的非线性函数， 不一定是特征X。 说到非线性方程， 它可以是指数的形状 对数和逻辑或其他许多类型。 如您在所有这些方程式中所见， Y hat的变化取决于参数Theta的变化， 不一定只在X上。 也就是说，在非线性回归中 通过参数非线性模型。 与线性回归相反， 我们不能使用普通的最小二乘法在非线性回归中拟合数据。 通常，参数的估计并不容易。 让我在这里回答两个重要的问题。 首先，如何以简单的方式知道问题是线性的还是非线性的？ 为了回答这个问题， 我们必须做两件事。 首先是从视觉上找出该关系是线性的还是非线性的。 最好用每个输入变量绘制输出变量的二元图。 此外，您可以计算相关系数 在自变量和因变量之间，如果 对于所有变量，该值为0.7或更高， 存在线性趋势，因此， 拟合非线性回归是不合适的。 我们要做的第二件事是使用非线性回归而不是 当我们不能线性回归时 使用线性参数准确地建立关系模型。 第二个重要问题是 如果数据在散点图上显示为非线性，应该如何建模？ 好吧，为了解决这个问题， 您必须使用多项式回归 使用非线性回归模型， 或转换您的数据， 这不在本课程范围内。</p>
<p><strong>分类模型</strong></p>
<p>我们将为您介绍分类。 因此，让我们开始吧。 在机器学习中分类是 有监督的学习方法，可以认为是 一种将一些未知项目分类或分类为一组离散类的方法。 分类尝试学习一组之间的关系 特征变量和感兴趣的目标变量。 分类中的目标属性是具有离散值的分类变量。 那么，分类和分类器如何工作？ 给定一组训练数据点以及目标标签， 分类确定未标记测试用例的类标签。 让我们用一个例子来解释一下。 贷款违约预测是一个很好的分类样本。 假设银行担心无法偿还贷款的可能性？ 如果以前的贷款违约数据可以用来预测 哪些客户可能在偿还贷款方面遇到问题， 这些不良风险客户可能会 他们的贷款申请被拒绝或提供了替代产品。 贷款违约预测变量的目标是使用 现有的贷款违约数据，其中包含有关客户的信息，例如年龄，收入， 教育等等，建立一个分类器， 向模型传递新客户或潜在的未来默认值， 然后将其标记，即数据点为默认值或不默认值。 或例如零或一。 这就是分类器如何预测未标记的测试用例。 请注意，此特定示例是关于带有两个值的二进制分类器的。 我们也可以为 二进制分类和多分类。 例如，假设您已经收集了有关一组患者的数据， 他们都患有同样的疾病。 在治疗过程中， 每位患者对三种药物之一有反应。 您可以将此标签数据集与 分类算法以建立分类模型。 然后，您可以使用它来找出可能是哪种药物 适合将来有相同疾病的患者。 如您所见，它是多类分类的示例。 分类也有不同的业务用例。 例如，要预测客户所属的类别， 对于流失检测，我们可以预测是否 客户切换到另一个提供商或品牌， 或预测客户是否响应特定的广告活动。 数据分类在广泛的行业中有多种应用。 本质上，许多问题可以表示为 特征和目标变量之间的关联， 尤其是在有标签数据的情况下。 这为分类提供了广泛的适用性。 例如，分类可用于电子邮件过滤，语音识别， 手写识别，生物识别， 文档分类等等。 这里我们有分类算法和机器学习的类型。 它们包括决策树， 朴素贝叶斯，线性判别分析， k近邻，逻辑回归， 神经网络和支持向量机。 分类算法有很多类型。 在本课程中，我们将只介绍一些。</p>
<p>我们将介绍K最近邻算法。 因此，让我们开始吧。 想象一下，电信提供商 按服务使用模式细分客户群， 将客户分为四类。 如果人口统计数据可用于预测组成员身份，则 公司可以为个人客户定制报价。 这是分类问题。 也就是说，假设数据集带有预定义标签， 我们需要建立一个模型来预测新案件或未知案件的类别。 该示例着重于使用人口统计数据，例如 地区，年龄和婚姻状况，以预测使用方式。 目标字段custcat具有 对应于四个客户组的四个可能值如下： 基本服务，电子服务， 加上服务和全面服务。 我们的目标是建立一个分类器。 例如，使用零到七行来预测第八行的类别。 我们将使用一种特定的分类类型，称为K最近邻。 只是为了示范， 我们只使用两个字段作为预测变量， 年龄和收入，然后 根据他们的组成员关系来绘制客户。 现在，我们有一个新客户。 例如，记录八， 具有已知的年龄和收入。 我们如何找到该客户的类别？ 我们能否找到最接近的案例之一并为我们的新客户分配相同的类别标签？ 我们还可以说 我们的新客户很可能是第四类，即全面服务， 因为最近的邻居也属于第四类？ 我们可以。事实上，它是第一个最近的邻居。 现在的问题是 我们在多大程度上可以信任基于第一个最近邻居的判断？ 特别是这可能是一个糟糕的判断 如果最近的邻居是一个非常特殊的情况或异常值，对吗？ 现在，让我们再次查看散点图。 与其选择第一个最近的邻居， 如果我们选择了五个最近的邻居并且做了 其中有大多数人投票决定了我们新客户的类别？ 在这种情况下，我们会看到 每五个最近的邻居中就有三个告诉我们去上第三堂课， 这是Plus服务。 这不是更有意义吗？ 是。实际上，确实如此。在这种情况下，K最近邻居算法中的K值为5。 此示例强调了K最近邻居算法背后的直觉。 现在，让我们定义K个最近的邻居。 K最近邻居算法是一种分类算法， 采取一堆标记点，并使用它们来学习如何标记其他点。 该算法基于案例与其他案例的相似性对其进行分类。 在“ K最近邻居”中，彼此靠近的数据点被称为邻居。 K最近邻居基于此范例。 具有相同类别标签的相似案例彼此靠近。 因此，两个案例之间的距离是它们不相似的度量。 有多种计算相似度的方法，或者相反， 两个数据点的距离或相异性。 例如，可以使用欧几里得距离来完成。 现在，让我们看看K最近邻居算法是如何工作的。 在分类问题中 K最近邻居算法的工作原理如下。 一，选择K的值。二， 计算数据集中每个案例与新案例之间的距离。 三，搜索中的K观测值 最接近未知数据点测量值的训练数据。 四，预测未知数据点的响应 使用“ K最近邻居”中最受欢迎的响应值。 该算法有两个部分，可能会有些混乱。 首先，如何选择正确的K，其次， 如何计算案例之间的相似度， 例如，在客户中。 让我们首先从第二个问题开始。 也就是说，我们如何计算两个数据点之间的相似度？ 假设我们有两个客户， 客户一和客户二， 暂时假设这两个客户只有一个功能， H.我们可以轻松使用特定类型的 用Minkowski距离来计算这两个客户的距离， 确实是欧几里得距离。 X_1与X_2的距离是34的根减去30到2的幂（即4）。 如果我们有多个功能怎么办？ 例如年龄和收入。 如果我们有每个客户的收入和年龄， 我们仍然可以使用相同的公式，但是这次， 我们在二维空间中使用它。 我们还可以对多维矢量使用相同的距离矩阵。 当然，我们必须规范我们的功能 设置以获得准确的相异度度量。 还有其他差异性措施 可以用于此目的，但如上所述， 它高度依赖于数据类型和 也是为其进行分类的领域。 如前所述，K和K最近邻居是要检查的最近邻居的数量。 应该由用户指定。 那么，我们如何选择合适的K？ 假设我们要查找的类 客户在图表上标记为问号。 如果我们选择非常低的K值会怎样？ 假设K等于1。 最接近的第一点是蓝色， 这是第一课。 这将是一个糟糕的预测， 因为围绕它的更多点是洋红色或四级。 实际上，由于其最近的邻居是蓝色的，我们可以说我们捕获了 数据中的噪声，或者我们选择了数据中异常的点之一。 K的值低也会导致模型非常复杂， 这可能会导致模型过度拟合。 这意味着预测过程不是 概括到足以用于样本外的情况。 样本外数据是用于训练模型的数据集之外的数据。 换句话说，不能将其用于未知样本的预测。 重要的是要记住，过度拟合是不好的， 因为我们想要一个适用于任何数据的通用模型， 不只是用于训练的数据。 现在，在光谱的另一面， 如果我们选择非常高的K值，例如K等于20， 然后模型变得过于笼统。 那么，如何找到K的最佳值呢？ 一般的解决方案是保留一部分 您的数据以测试模型的准确性。 完成后， 选择K等于1，然后使用训练部分进行建模 并使用测试集中的所有样本计算预测的准确性。 重复此过程，增加K，然后查看哪个K最适合您的模型。 例如，在我们的例子中， K等于4将为我们提供最佳精度。 最近邻分析还可以用于计算连续目标的值。 在这种情况下， 最近的邻居用于获得新案例的预测值。 例如，假设您要根据房屋的功能集来预测房屋价格， 例如房间数， 平方英尺，建造年份等。 您可以轻松找到三个最近的邻居房屋 当然，不仅基于距离，而且 也基于所有属性，然后 预测房屋价格，作为邻居的中介。</p>
<p>PS KNN的K是，近邻个数。</p>
<p>我们将介绍一个检查决策树。 因此，让我们开始吧。 决策树到底是什么？ 我们如何使用它们来帮助我们分类？ 我该如何发展自己的决策树？ 这些可能是您遇到的一些问题 从听到术语决策树的想法。 希望您很快就能回答 这些问题以及观看此视频的更多问题。 假设您是一名医学研究人员，正在为一项研究收集数据。 您已经收集了有关一组 所有患者都患有相同的疾病。 在治疗过程中， 每个患者对两种药物之一有反应。 我们称它们为药物A和药物B。 您的工作之一是建立一个模型来找出哪种药物 可能适合将来患有相同疾病的患者。 该数据集的特征集是年龄，性别， 血压和胆固醇水平 病人和目标是每个病人反应的药物。 它是二进制分类器的示例，您可以 使用数据集的训练部分来构建决策树 然后使用它来预测未知患者的类别。 从本质上讲，是要为新患者开哪种药的决定。 让我们看看如何为该数据集构建决策树。 通过将训练集划分为不同的节点来构建决策树， 其中一个节点包含一种数据的全部或大部分。 如果我们看这里的图， 我们可以看到它是患者的分类器。 因此，如上所述，我们想为新患者开药， 但是选择药物A或B的决定将受到患者情况的影响。 我们从年龄开始 可以是年轻，中年或高级。 如果病人是中年 那么我们一定会去买毒品B。 另一方面，如果他有年轻或年长的病人， 将需要更多详细信息来帮助我们确定要开哪种药。 其他决策变量可以是胆固醇水平， 性别或血压。 例如，如果患者是女性， 那么我们将推荐药物A， 但是如果病人是男性 然后去买毒品B。 如你看到的， 决策树是关于测试属性和 根据测试结果分支案例。 每个内部节点对应一个测试， 每个分支对应一个测试结果， 每个叶节点将一个病人分配给一个类别。 现在的问题是 我们如何建立这样的决策树？ 这是构建决策树的方式。 可以通过一一考虑属性来构造决策树。 首先，从我们的数据集中选择一个属性。 计算属性在数据分割中的重要性。 在下一个视频中 我们将解释如何计算 属性以查看其是否为有效属性。 接下来，根据最佳属性的值分割数据， 然后转到每个分支并对其余属性重复此操作。 建好这棵树之后 您可以使用它来预测未知病例的类别；或就我们而言根据新患者的特征为其选择合适的药物。</p>
<p>我们将介绍构建决策树的过程。 因此，让我们开始吧。 再次考虑药物数据集。 问题是，我们如何基于该数据集构建决策树？ 使用递归分区来构建决策树以对数据进行分类。 假设我们的数据集中有14位患者， 该算法选择最具预测性的功能来分割数据。 在制定决策树时重要的是 是确定哪个属性最好或更多 预测根据功能拆分数据。 假设我们选择胆固醇作为分割数据的第一个属性， 它将我们的数据分为两个分支。 如你看到的， 如果病人胆固醇高，我们不能说 非常有信心药B可能适合他。 另外，如果患者的胆固醇正常， 我们仍然没有足够的证据或信息来 确定药物A或药物B实际上是否合适。 它是用于拆分数据的不良属性选择的示例。 因此，让我们尝试另一个属性。 同样，我们有14个案例， 这次我们选择了患者的性别属性。 它将我们的数据分为男性和女性两个分支。 如您所见，如果患者是女性， 我们可以说毒品B可能非常适合她。 但是如果病人是男性 我们没有足够的证据或 确定药物A或药物B是否合适的信息。 但是，与 胆固醇属性，因为结点中的结果更纯净。 这意味着节点大多是药物A或药物B。 因此，我们可以说性别属性比胆固醇更重要， 换句话说，它比其他属性更具预测性。 实际上，可预测性是基于节点杂质的减少。 我们正在寻找最好的功能以减少患者叶片中的杂质， 根据该功能将它们拆分后。 因此，性别特征是 以下情况是因为它几乎找到了纯属患者。 让我们更进一步。 对于男性患者科， 我们再次测试其他属性以拆分子树。 我们在这里再次测试胆固醇 如您所见，它产生的叶子更加纯净。 这样我们就可以在这里轻松地做出决定。 例如，如果患者是男性且胆固醇很高， 我们当然可以开药A， 但是如果正常的话 我们可以高信度地开出药物B。 您可能会注意到， 分割数据的属性选择非常 重要的是分割后叶片的纯度。 如果在100％的情况下，树中的节点被视为纯节点， 节点属于目标字段的特定类别。 实际上，该方法使用递归分区来拆分 通过将每个步骤中的杂质减到最少，训练记录会分成多个部分。 通过节点中数据的熵来计算节点的杂质。 那么，熵是什么？ 熵是信息混乱的数量或数据中的随机性的数量。 节点中的熵取决于 该节点中有多少随机数据，并针对每个节点进行计算。 在决策树中，我们正在寻找在其节点中具有最小熵的树。 熵用于计算该节点中样本的均匀性。 如果样品完全均匀， 熵为零，如果样本均分，则熵为1。 这意味着，如果节点中的所有数据都是药物A或药物B， 那么熵为零 但是如果数据的一半是药物A，另一半是药物B，那么熵就是1。 您可以使用的频率表轻松计算节点的熵 通过熵公式的属性，其中 P是类别的比例或比率， 例如药物A或B。 请记住，尽管您不必将这些计算为 它可以通过您使用的库或软件包轻松计算。 例如，让我们在分割数据集之前先计算它的熵。 我们有9种药物B和5种药物A。 您可以将这些数字嵌入到熵公式中 计算目标属性的杂质，然后再拆分。 在这种情况下，它是0.94。 那么，分裂后的熵是多少？ 现在，我们可以测试不同的属性，以找到最具预测性的属性， 这导致了另外两个纯分支。 首先选择患者的胆固醇， 查看如何根据数据值拆分数据。 例如，在正常情况下，药物B有6种药物， 另两种是药物A。 我们可以根据以下公式计算该节点的熵 在这种情况下，药物A和药物B的分布为0.8。 但是，胆固醇高的时候 药物B的数据分为三个，药物A的数据分为三个。 计算它的熵，我们可以看到它是1.0。 我们应该遍历所有属性并计算熵 分割后，然后选择最佳属性。 好的。让我们尝试另一个领域。让我们为下一个检查选择性别属性。 如您所见，当我们使用sex属性分割数据时， 当它的价值是女性时， 我们有三位患者对 药物B和四位对药物A有反应的患者。 该节点的熵为0.98，这不太有希望。 但是，在分支的另一边， 当sex属性的值为男性时， 药物B的性别结果更为纯净，药物A的性别结果更为纯正。 该组的熵为0.59。 现在的问题是 胆固醇和性别属性哪个是更好的选择？ 将数据集划分为两个分支的第一个属性哪个更好？ 换句话说 哪个属性可以使我们的药物更加纯净？ 还是在分裂之后而不是分裂之前，哪棵树的熵较小？ 性别的熵分别为0.98和0.59或 胆固醇属性在其分支中的熵分别为0.81和1.0。 答案是分裂后具有更高信息增益的树。 那么，什么是信息增益？ 信息获取是可以获取的信息 分裂后增加确定性水平。 它是分裂前的一棵树的熵 减去按属性划分后的加权熵。 我们可以认为信息获取和熵是相反的。 随着熵或随机性的减少， 信息获取或确定性增加，反之亦然。 因此，构建决策树就是关于 查找返回最高信息增益的属性。 让我们看看如何计算性别属性的信息增益。 如前所述，获得的信息是树的熵 分割前减去分割后的加权熵。 分裂前的树的熵为0.94， 女性患者的比例为14分之7，其熵为0.985。 同样，男性的比例是14分之7，男性节点的熵是0.592。 方括号的结果是分割后的加权熵。 所以，如果我们使用树的信息增益 用于拆分数据集的sex属性为0.151。 如您所见，我们将考虑熵 属于以下情况的样本分布 每个叶节点，我们将取加权平均值 该熵由属于该假的样本比例加权。 如果我们也使用胆固醇，我们可以计算出树的信息增益。 是0.48。 现在的问题是 哪个属性更合适？ 好吧，正如所提到的，在分裂后获得的信息量更高的树， 这意味着性别属性。 因此，我们选择sex属性作为第一个拆分器。 现在，按性别属性分支后的下一个属性是什么？ 好吧，你可以猜到 我们应该为每个分支重复该过程并测试每个 其他属性继续达到最纯净的叶子。 这是构建决策树的方式。</p>
<p>我们将学习一种称为 用于分类的逻辑回归。 在检查此方法时， 我们将专门回答这三个问题。 什么是逻辑回归？ Logistic回归可以解决哪些问题？ 在哪些情况下我们使用逻辑回归？因此，让我们开始吧。Logistic回归是一种统计和机器学习技术，用于 根据输入字段的值对数据集的记录进行分类。 假设我们有一个电信数据集 进行分析，以了解下个月哪些客户可能会离开我们。 这是历史客户数据，其中每一行代表一个客户。 假设您是这家公司的分析师 您必须找出谁要离开，为什么要离开？ 您将使用数据集基于以下内容构建模型 历史记录，并使用它来预测客户群中的未来客户流失。 数据集包含有关以下服务的信息： 每个客户都已注册，客户帐户信息， 有关客户的人口统计信息，例如性别和 年龄范围以及上个月离开公司的客户。 该列称为搅动。 我们可以使用逻辑回归来建立模型 使用给定功能预测客户流失。 在逻辑回归中，我们使用一个或多个自变量，例如任期， 年龄和收入来预测结果，例如流失， 我们称之为因变量 代表客户是否将停止使用该服务。 Logistic回归类似于线性回归 但尝试预测分类或离散目标字段，而不是数字字段。 在线性回归中，我们可能会尝试预测 变量的连续值，例如房屋价格， 病人的血压 或汽车的油耗。 但是在逻辑回归中 我们预测一个二进制变量，例如yes / no，true / false， 成功或不成功，怀孕/未怀孕， 依此类推，所有这些都可以编码为零或一。 在逻辑回归中，因变量应该是连续的。 如果是分类的，则应为虚拟或指示符编码。 这意味着我们必须将它们转换为某个连续值。 请注意，逻辑回归可以用于 二进制分类和多分类。 但是为了简单起见，在这个视频中 我们将重点介绍二进制分类。 在解释逻辑回归的工作原理之前，让我们研究一下逻辑回归的一些应用。 如前所述，逻辑回归是一种分类算法， 因此可以在不同情况下使用。 例如，预测一个人的概率 在指定时间段内心脏病发作， 根据我们对某人年龄的了解， 性别和体重指数。 或预测死亡的机会 受伤的病人或预测病人是否患有 特定疾病，例如糖尿病 观察到的该患者的特征，例如体重， 身高，血压以及各种血液检查的结果等。 在营销方面， 我们可以用它来预测客户购买的可能性 产品或暂停订阅，就像我们在流失示例中所做的那样。 我们还可以使用逻辑回归来预测 给定过程，系统或产品失败的概率。 我们甚至可以用它来预测房主拖欠抵押贷款的可能性。 这些都是可以使用逻辑回归解决的问题的很好的例子。 请注意，在所有这些示例中，我们不仅可以预测每种情况的类别， 我们还测量了案件属于特定类别的可能性。 有不同的机器算法可以对变量进行分类或估计。 问题是，什么时候应该使用逻辑回归？ 在以下四种情况下，逻辑回归是一个很好的选择。 首先，当数据中的目标字段是分类字段或特定而言是二进制字段时。 例如零/一，是/否， 流失或没有流失，正/负等。 其次，您需要预测的可能性。 例如，如果您想知道客户购买产品的概率是多少。 Logistic回归返回概率分数 对于给定的数据样本，介于0和1之间。 实际上，逻辑回归可以预测 该样本，然后根据该概率将案例映射到离散类。 第三，如果您的数据是线性可分离的。 逻辑回归的决策边界是直线或平面或超平面。 分类器将对所有点进行分类 决策边界的一侧属于一类 以及另一端所有属于另一类的人。 例如，如果我们只有两个功能，并且 不应用我们可以获得的多项式处理 像Theta零加Theta 1x1加上theta 2x2这样的不等式大于零， 这是一个容易绘制的半平面。 请注意，在使用逻辑回归时， 我们还可以使用多项式处理来获得复杂的决策边界， 在这里超出范围。您将从中获得更多见解了解逻辑回归如何工作时的决策边界。 第四，您需要了解功能的影响。 您可以根据以下条件选择最佳功能 Logistic回归模型系数或参数的统计意义。 也就是说，找到最佳参数后， 权重Theta接近零的特征X具有 比具有Theta one绝对值大的特征对预测的影响小。 确实，它使我们能够了解影响的独立变量 在控制其他自变量的同时具有因变量。 让我们再次看一下我们的数据集。 我们将自变量定义为X，将因变量定义为Y。 注意，为简单起见，我们可以编写代码 目标或相关值设为零或一。 Logistic回归的目标是建立一个模型来预测 在这种情况下是客户的每个样本的类别， 以及每个样本属于一个类别的概率。 鉴于此，让我们开始对问题进行形式化。 X是m乘n实数空间中的数据集。那是，共有m个维度或要素以及n个记录，并且 Y是我们要预测的班级 可以是零或一。 理想情况下，采用逻辑回归模型，即所谓的Y hat 可以预测到客户的等级是一， 鉴于其特征X。 也可以很容易地表明 客户处于零类的概率可以 计算为1减去客户类别为1的概率。 </p>
<p>我们看一下线性回归，看看为什么 不能正确地用于某些二进制分类问题。 我们还要看一下S型函数 这是逻辑回归的主要部分。开始吧。让我们再次看一下电信数据集。 Logistic回归的目标是建立一个模型来预测 每个客户，以及每个样本属于某个类别的概率。 理想情况下，我们要建立一个模型， 可以估计，由于其特征是 X。我想强调y是标签的向量，也称为实际值 我们想要预测的 是模型预测值的向量。 将类标签映射到整数， 我们可以使用线性回归来解决这个问题吗？ 首先，让我们回想一下线性回归如何工作以更好地理解逻辑回归。 暂时忘记流失预测，然后假设 我们的目标是预测数据集中的客户收入。 这意味着，与其预测流失， 这是绝对价值， 让我们预测收入，它是一个连续的值。 那么，我们该怎么做呢？ 让我们选择一个自变量，例如 客户年龄并预测因变量，例如收入。 当然，我们可以拥有更多功能，但是为了简单起见， 让我们在这里仅介绍一项功能。 我们可以绘制它并显示年龄为 我们希望预测的自变量和收入为目标值。 使用线性回归，您可以通过数据拟合直线或多项式。 我们可以通过训练模型来找到这条线 根据样本集进行数学计算。 我们将说，这是贯穿样本集的一条直线。 这条线的方程式显示为加号bx1。 现在，使用这条线来预测连续值y。 也就是说，使用这条线来预测 根据他或她的年龄，一个未知的客户，并且做到了。 如果我们要预测用户流失怎么办？ 我们可以使用相同的技术来预测吗 诸如流失之类的分类字段？好吧，让我们看看。说，我们得到了有关客户流失和目标的数据 这次是根据客户的年龄预测客户流失率。 我们有一个功能， 以x1表示的年龄， 并具有分类特征 有两个类别，客户流失是，而客户流失是。 如前所述，我们可以将yes和no映射到整数值0和1。 我们现在如何建模？ 嗯，以图形方式，我们可以用散点图表示数据， 但是这一次，我们的y轴只有两个值。 在该图中，零级用红色表示，而一级用蓝色表示。 我们的目标是建立一个基于 现有数据，以预测新客户是红色还是蓝色。 让我们做与线性回归相同的技术 看看我们是否可以解决分类属性（例如客户流失）的问题。 使用线性回归，您可以再次通过数据拟合多项式， 传统上将其显示为加号bx。 该多项式在传统上也可以显示为Theta0加Theta1 x1。 这行有两个参数，用 向量Theta，向量的值为Theta0和Theta1。 我们还可以在Theta转置x时正式显示这条线的方程式。 通常，我们可以将Theta转置x来表示多维空间的方程， 其中Theta是其中的线的参数 二维空间或三维空间中平面的参数，依此类推。 由于Theta是参数的向量，并且应该乘以x， 它通常显示为转置Theta。 Theta也称为权重因子或等式的置信度， 同时使用这两个术语 X是可互换的，代表客户的功能集。 无论如何，给定一个数据集， 所有功能集x Theta参数都可以 通过优化算法或数学计算得出 得出拟合线的方程。 例如，该行的参数为负1和0.1， 直线的方程式为负一加0.1 x1。 现在，我们可以使用该回归线来预测新客户的流失率。 例如，对于我们的客户，或者说， 年龄x值等于13的数据点 我们可以将值插入行公式中， 并计算y值并返回一个数字。 例如，对于p1点， 我们有Theta转置x等于负1加0.1乘以x1， 等于负1加0.1乘以13，等于0.3。 我们可以在图表上显示它。 现在，我们可以在此处定义一个阈值。 例如，以0.5定义类。 因此，我们在此处为模型编写规则， y帽子，这使我们可以将零类与一类分开。 如果Theta转置x的值小于0.5， 那么该类为零。 否则，如果Theta转置x的值大于0.5， 那一班是一班 因为我们的客户y值小于阈值， 根据我们的模型，我们可以说它属于零类。 但是这里有一个问题。 该客户属于零类的概率是多少？ 如您所见，它不是解决此问题的最佳模型。 此外，还有其他一些问题可以验证 线性回归不是解决分类问题的正确方法。 因此，如上所述，如果我们使用回归线来计算点的类别， 它总是返回一个数字，例如3或负2，依此类推。 然后，我们应该使用一个阈值，例如， 0.5，将该点分配给零或一类。 此阈值用作阶跃函数 不论大小，输出零或一， 输入为正或负。 因此，使用阈值， 我们可以找到记录的类别。 请注意，在步进功能中， 不管价值多大 只要大于0.5， 它仅等于一，反之亦然。 不管y值有多小， 如果小于0.5，则输出为零。 换句话说，两者之间没有区别 价值为一或一千的客户。 结果将是一个。 除了具有此步骤功能之外， 如果我们有一条更平滑的线，那会不会很好， 一个将这些值投影在零和一之间的数字？ 确实，现有方法并没有真正 给我们一个顾客属于某类的可能性， 这是非常可取的。 我们需要一种可以给我们降级可能性的方法。 那么，这里的科学解决方案是什么？ 好吧，如果不是使用Theta转置x， 我们使用一个称为Sigmoid的特定函数 然后Theta转置x的S形给我们概率 属于类的点，而不是直接y的值。 我将在稍后解释此S形函数， 但就目前而言，除了它可以解决问题之外，请。 与其直接计算Theta的值，不如直接转置x， 它返回Theta转置x很大或很小的概率。 它总是返回0到1之间的值 取决于Theta转置x的实际大小。 现在，我们的模型是Theta转置x的S形， 表示给定x时输出为1的概率。 现在的问题是 乙状结肠功能是什么？ 让我详细解释什么是乙状结肠。 S形函数，也称为逻辑函数， 类似于步进功能，由 逻辑回归中的以下表达式。 乙形函数起初看起来有点复杂， 但是不用担心记住这个方程式， 使用它对您有意义。 请注意，在S型方程式中 当Theta转置x变得非常大时， e幂减Theta将x转置为分数的分母 几乎变为0，并且S型函数的值接近于1。 如果Theta转置x非常小， sigmoid函数接近于0。 描绘在S形图中 当Theta转置x变大时， sigmoid函数的值接近1，并且 同样，如果Theta转置x非常小， sigmoid函数接近于0。 因此，sigmoid函数的输出始终在0到1之间 这使得将结果解释为概率是适当的。 显然，当S形函数的结果接近1时， 如果x上升，则y等于1的概率。 相反，当S形值接近于0时， 给定x时y等于1的概率非常小。 那么，当我们使用S型函数时，模型的输出是什么？ 在逻辑回归中，我们对输入x， 属于默认类y等于1， 并且我们可以正式地写为y等于1的概率x。 我们还可以写出y属于的概率 给定x的类0为1减去y的概率等于给定x的1。 例如，客户留在公司的概率可能是 显示为给定客户的收入和年龄的客户流失几率等于1， 可以是0.8，和 给定客户的收入，同一个客户的客户流失概率为0， 年龄可以计算为1减去0.8等于0.2。 因此，现在我们的工作是训练模型以在 在给定x的情况下，我们的模型可以很好地估计y的概率等于1。 实际上，这就是一个好的分类器模型 通过logistic回归构建的数据应该对我们有用。 而且，应该很好地估计y属于的概率 给定x的0类，可以显示为1减去Theta转置x的S形。 现在的问题是 我们怎样才能做到这一点？ 我们可以通过培训过程找到Theta。 那么，让我们看看培训过程是什么。 第一步，初始化Theta向量 与大多数机器学习算法一样具有随机值。 例如，负1或2。 第二步，计算模型输出， 这是Theta的S型转置x。 例如，您的培训集中的客户。 X和Theta转置x是特征向量值。 例如，客户的年龄和收入， 2和5，Theta是您在上一步中设置的置信度或权重。 该方程的输出是预测值， 换句话说，客户属于类别1的概率。 第三步，比较我们模型的输出， 你的帽子，可能是 假设是0.7，带有客户的实际标签， 例如，1表示客户流失。 然后，将该差异记录为该客户对该模型的错误， 那是1减去0.7， 当然，等于0.3。 这是培训集中所有客户中只有一个客户的错误。 第四步，计算误差 所有客户，就像我们在前面的步骤中所做的一样，并将这些错误加总。 总误差是模型的成本，并由模型成本函数计算得出。 顺便说一下，成本函数 基本上代表了如何计算模型的误差 实际值与模型预测值之间的差异。 因此，成本显示了模型在评估客户标签方面的能力。 因此，成本越低， 模型越能正确估计客户标签。 因此，我们想要做的就是尽量减少这种成本。 第五步，但由于Theta的初始值是随机选择的， 成本函数很可能很高， 因此我们以某种方式更改Theta以希望降低总成本。 第六步，更改Theta的值后， 我们回到第二步， 然后我们开始另一个迭代并再次计算模型的成本。 我们不断重复这些步骤， 每次更改Theta的值，直到成本足够低为止。 因此，这带来了两个问题。 首先，我们如何更改 Theta，以便在迭代中降低成本？ 第二，我们什么时候应该停止迭代？ 有多种方法可以更改Theta的值， 但是最受欢迎的方法之一是梯度下降。 另外，有多种方法可以停止迭代， 但实际上，您通过计算来停止训练 模型的准确性，并在满意时将其停止。</p>
<p>我们将学习有关训练逻辑回归模型的更多信息。 另外，我们将讨论如何改变 模型的参数以更好地估计结果。 最后，我们讨论成本函数和梯度下降 逻辑回归作为优化模型的一种方式。所以，让我们开始吧。培训和培训的主要目标 Logistic回归是要更改模型的参数， 从而最好地估计数据集中样本的标签。 例如，客户流失。我们该怎么做？简而言之，首先我们要看看成本函数 并查看成本函数和参数theta之间的关系。 因此，我们应该制定成本函数。 然后，使用成本函数的导数，我们可以找到 更改参数以降低成本，甚至减少错误。 让我们深入了解它是如何工作的。 但是在我解释之前，我应该为您强调 了解一些基本的数学背景。 但是，您不必担心，因为大多数数据科学语言（例如Python， R和Scala具有一些程序包或库来为您计算这些参数。 因此，让我们来看一下。 首先让我们找到一个样本案例的成本函数方程。 为此，我们可以在流失问题中使用一位客户。 通常有一个用于计算成本的一般公式。 成本函数是 y的实际值和模型输出y hat。 这是机器学习中大多数成本函数的一般规则。 我们可以将其显示为模型与实际标签进行比较的成本， 这是预测值之间的差 我们的模型和目标领域的实际价值， 其中我们模型的预测值是θ转置x的S形。 通常使用该方程的平方是因为 产生负面结果的可能性，并且为了简单起见， 该值的一半被视为通过微分过程的成本函数。 现在，我们可以为训练集中的所有样本编写成本函数。 例如，对于所有客户，我们可以写 它是所有案例的成本函数的平均和。 也称为均方误差 参数向量theta的函数，表示为theta的J。 好的，我们有成本函数。 现在，我们如何找到或设置 最小化此成本函数的最佳权重或参数？ 答案是，我们应该计算出 这个成本函数，它将为我们显示模型的最佳参数。 尽管我们可以使用函数的导数找到函数的最小点， 没有找到这样一个方程式的全局最小点的简便方法。 鉴于这种复杂性，描述如何达到 此等式的全局最小值超出了此视频的范围。 那么，解决方案是什么？ 好吧，我们应该找到另一个成本函数， 一种具有相同的行为，但更容易找到其最低点。 让我们为模型绘制理想的成本函数。 回想一下，我们的模型是帽子。 我们的实际值为y等于零或一， 然后我们的模型尝试根据需要进行估算 为我们的模型找到一个简单的成本函数。 暂时假设我们对y的期望值为1。 这意味着如果我们的模型估计y等于1，则它是最好的。 在这种情况下，我们需要一个成本函数 如果模型的结果为1，则返回零， 与实际标签相同。 而且随着我们模型的结果越来越远，成本也应继续增加。 如果我们模型的结果接近零，那么成本应该非常大。 我们可以看到负对数函数为我们提供了这种成本函数。 这意味着如果实际值为1，并且模型也预测为1， 负对数函数返回零成本。 但是如果预测值小于1， 负对数函数将返回较大的成本值。 因此，我们可以使用减号日志功能 计算我们的逻辑回归模型的成本。 所以，如果您还记得， 我们之前注意到，通常 难以计算成本函数的导数。 好了，我们现在可以使用模型的负对数来更改它。 我们可以轻松证明在期望y为1的情况下， 成本可以计算为负对数， 在期望y为零的情况下，成本 可以计算为负对数一负。 现在，我们可以将其插入总成本函数并将其重写为该函数。 因此，这就是逻辑回归成本函数。 如您所见，它惩罚了以下情况 类为零，模型输出为一，反之亦然。 但是请记住，您的帽子不会像 输出，但是它是零或一的值，应假定为概率。 现在，我们可以轻松地使用此函数来查找参数 我们的模型以最小化成本的方式。 好的，让我们回顾一下我们所做的事情。 我们的目标是找到一个最佳估计实际标签的模型。 找到最佳模型意味着找到该模型的最佳参数theta。 所以，第一个问题是 我们如何找到模型的最佳参数？ 好吧，通过查找和最小化我们模型的成本函数。 换句话说，为了最小化theta的J，我们刚刚定义了。 下一个问题是 我们如何最小化成本函数？ 答案是使用优化方法。 有不同的优化方法， 但是我们在这里使用了最著名和最有效的方法之一，即梯度下降。 下一个问题是 什么是梯度下降？ 通常，梯度下降是 寻找函数最小值的迭代方法。 特别是在我们的案例中，梯度下降是一种使用 成本函数，用于更改参数值以最小化成本或误差。 让我们看看它是如何工作的。 梯度下降的主要目标是改变 参数值以最小化成本。 梯度下降该怎么做？ 考虑我们模型中的参数或权重在二维空间中。 例如，theta一， θ两个代表两个特征集，即年龄和收入。 回想一下成本函数， J，我们在前面的幻灯片中讨论过。 我们需要最小化成本函数J 这是变量θ1和θ2的函数。 因此，让我们为观察到的成本添加一个维度， 或错误，J函数。 假设如果我们根据theta one的所有可能值绘制成本函数， 西塔二，我们可以看到这样的事情。 它代表不同参数值的误差值， 那是误差，它是参数的函数。 这称为成本函数的误差曲线或误差碗。 回想一下我们要使用此错误提示框来查找 最佳参数值，可将成本值最小化。 现在的问题是 哪个点是成本函数的最佳点？ 是的，您应该尽量减少在误差曲线上的位置。 那你该怎么办？ 您必须通过更改参数来找到成本的最小值。 但是，哪条路呢？ 您会增加一些价值还是减去一些价值？ 那价值多少呢？ 您可以选择在碗上定位点的随机参数值。 您可以认为我们的起点是黄点。 您可以通过delta theta 1和delta theta 2来更改参数， 并在表面上迈出一步。 假设我们往碗里走了一步。 只要我们向下走，我们就可以再走一步。 坡度越陡，我们可以越走越远， 而且我们可以继续采取步骤。 当我们接近最低点时，斜率逐渐减小， 因此我们可以采取更小的步骤，直到达到平坦的表面。 这是我们曲线的最小点，是最佳θ1，θ2。 这些步骤到底是什么？ 我的意思是我们应该朝着哪个方向采取措施以确保我们下降， 步骤应该多大？ 要找到这些步骤的方向和大小， 换句话说，找到如何更新参数， 您应该在此时计算成本函数的梯度。 梯度是表面在每个点的斜率 坡度的方向就是最大上坡的方向 现在的问题是 我们如何计算一个点上成本函数的梯度？ 如果您在此表面上选择一个随机点， 例如黄点， 并取J的偏导数 关于该点每个参数的theta， 它为您提供了该点上每个参数的移动斜率。 现在，如果我们沿该斜率的相反方向移动， 它保证了我们走在误差曲线上。 例如，如果我们计算J关于θ1的导数， 我们发现这是一个正数。 这表明功能随着θ1的增加而增加。 因此，要降低J，我们应该向相反方向移动 方向。这意味着向内移动 θ1的负导数的方向，即 坡。我们还必须在每个步骤中为其他参数计算它。梯度值还指示要采取的步幅。 如果斜率很大，则应该采取较大的步骤，因为我们离最小值很远。 如果斜率较小，我们应该采取较小的步骤。 梯度下降的步伐越来越小 每次迭代都向最小方向发展。 使用该表达式计算成本函数J的偏导数。 如果您想知道如何计算J函数的导数， 您需要了解衍生概念，这不在我们的讨论范围之内。 但是说实话，您并不需要真正记住所有有关 因为您可以轻松地使用此方程式来计算梯度。 简而言之，该方程返回的斜率是 该点，我们应该在相反的方向上更新参数。 所有这些斜率的向量就是梯度向量， 我们可以使用此向量来更改或更新所有参数。 我们采用参数的先前值并减去误差导数。 这导致新的theta参数，我们知道这将降低成本。 同样，我们将梯度值乘以常数mu， 这称为学习率。 学习速度可让我们进一步控制表面运动的速度。 总之，我们可以简单地说， 梯度下降就像在斜坡的当前方向上迈出一步， 学习速度就像您迈出的一步之长。 因此，这些将是我们的新参数。 请注意，这是一个迭代操作，在每次迭代中我们都会更新 参数并最小化成本，直到 算法收敛在可接受的最小值上。 好吧，让我们回顾一下到目前为止所做的事情 逐步重新训练算法。 第一步，我们使用随机值初始化参数。 第二步，我们向成本函数提供训练集并计算成本。 由于参数是随机设置的，因此我们期望较高的错误率。 第三步，我们计算 考虑到成本函数，我们必须使用偏导数。 因此，要计算梯度向量，我们需要 所有训练数据以为每个参数提供方程式。 当然，这是算法的昂贵部分， 但是有一些解决方案。 第四步，我们使用新的参数值更新权重。 第五步，我们回到第二步，再次输入成本函数， 具有新参数。 如前所述， 当我们走到错误表面时，我们期望更少的错误。 我们继续这个循环，直到达到一个短值 成本或某些有限的迭代次数。 第六步，在一些迭代之后应该大致找到该参数。 这意味着模型已经准备就绪，我们可以使用它来 预测客户留下或离开的可能性。</p>
<p>我们将学习一种机器学习方法， 支持向量机或SVM，用于分类。 因此，让我们开始吧。<br>想象一下，您已经获得了包含特征的数据集 数以千计的人类细胞样本 提取自被认为有患癌症风险的患者。<br>对原始数据的分析表明，许多特征有所不同 在良性和恶性样本之间差异显着。 您可以使用这些单元格特征的值 在其他病人的样本中 尽早指出新样本是良性还是恶性的。 您可以使用支持向量机，或者 SVM，作为训练模型的分类器 了解数据中可能显示，良性或恶性细胞的模式。<br>训练模型后，就可以用来预测您的新模型或 未知单元格的准确性很高。 现在，让我给您一个SVM的正式定义。<br>支持向量机是一种监督算法 通过查找分隔符可以对案例进行分类。 SVM的工作原理是首先将数据映射到高维特征空间，以便数据 即使数据无法线性分离，也可以对点进行分类。 然后，为数据估计一个分隔符。 数据应该以这种方式转换 可以将分隔符绘制为超平面。 例如，考虑下图，该图显示了 一小部分细胞仅根据其单位大小和团块厚度而定。 如您所见，数据点分为两个不同的类别。 它表示线性不可分离的数据集。 这两个类别可以用曲线分开，但不能用直线分开。 也就是说，它表示线性不可分离的数据集， 大多数现实世界的数据集就是这种情况。 我们可以将这些数据传输到更高维度的空间 例如，将其映射到三维空间。 改造后 这两个类别之间的边界可以由超平面定义。 正如我们现在在三维空间中一样，分隔符显示为一个平面。 该平面可以用于对新的或未知的案例进行分类。 因此，SVM算法 输出对新示例进行分类的最优超平面。 现在，有两个具有挑战性的问题需要考虑。 首先，我们如何以这种方式传输数据 分隔符可以绘制为超平面吗？ 第二，我们如何找到最好的 转换后优化的超平面分离器？<br>让我们首先看一下转换数据以了解其工作原理。 为了简单起见，假设我们的数据集是一维数据。 这意味着我们只有一个特征x。 如您所见，它不是线性可分离的。 那么我们在这里可以做什么？ 好吧，我们可以将其转移到二维空间中。 例如，您可以通过将x映射到 一个使用输出x和x平方的函数的新空间。 现在数据是线性可分离的，对吧？<br>请注意，因为我们在二维空间中，所以超平面是一条线 将飞机分为两部分，每节课在每一侧放置。 现在，我们可以使用此行对新案例进行分类。 基本上，将数据映射到更高维度的空间称为 仁。 用于转换的数学函数称为核 函数，可以是不同的类型，例如线性， 多项式，径向基函数或RBF和S形。 这些功能中的每一个都有自己的特点，优点和缺点，以及 它的方程式。 但好消息是，您不需要像大多数人一样了解它们 已经在数据科学编程语言库中实现。<br>另外，因为没有一种简单的方法可以知道哪个函数在任何情况下都表现最佳 给定数据集，我们通常依次选择不同的函数并比较结果。<br>现在我们来谈另一个问题。 具体来说，我们如何在转换后找到合适的或优化的分隔符？<br>基本上，SVM基于发现超平面的想法 最好将数据集分为两类，如下所示。<br>当我们处于二维空间中时，您可以想到超平面 作为将蓝点和红点线性分离的线。<br>最佳超平面的一种合理选择是代表 两类之间最大的间隔或边距。 因此，目标是选择具有尽可能大裕度的超平面。 最接近超平面的例子是支持向量。 直观地讲，只有支持向量对实现我们的目标至关重要。 因此，其他趋势示例可以忽略。 我们试图以这种方式找到超平面 它具有支持向量的最大距离。 请注意，超平面和边界决策线 有自己的方程式<br>因此，找到优化的超平面可以使用以下公式来形式化： 涉及很多数学，因此在这里我将不详细介绍。<br>也就是说，超平面是从训练数据中学到的 使用最大化利润的优化程序。 像许多其他问题一样，此优化问题可以 也可以通过梯度下降来解决，这超出了本视频的范围。 因此，算法的输出是该行的值w和b。 您可以使用此估算线进行分类。 将输入值插入线性方程式就足够了。 然后，您可以计算未知点是在线的上方还是下方。 如果公式返回的值大于0， 那么该点属于该线上方的第一类，反之亦然。 支持向量机的两个主要优点是 在高维空间中精确。 他们在决策函数中使用了训练点的子集， 支持向量，因此它的存储效率也很高。<br>支持向量机的缺点 包括该算法易于实现的事实 如果特征数量远大于样本数量，则为过度拟合。 而且，SVM不会直接提供概率估计， 在大多数分类问题中都是需要的。 最后，SVM在计算上不是很有效 如果您的数据集非常大（例如，当您有超过1,000行时）。<br>现在我们的最后一个问题是，在哪种情况下应该使用SVM？<br>好吧，SVM非常适合图像分析任务， 例如图像分类和手写数字识别。 此外，SVM在文本挖掘任务中非常有效， 特别是由于其在处理高维数据方面的有效性。 例如，它用于 检测垃圾邮件，文本类别分配和情感分析。<br>SVM的另一个应用是在基因表达数据分类中， 再次，由于其在高维数据分类中的强大功能。 SVM还可以用于其他类型的机器学习问题， 例如回归，离群值检测和聚类。 我将留给您探索有关这些特定问题的更多信息。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/coursera/" rel="tag"># coursera</a>
          
            <a href="/tags/IBM/" rel="tag"># IBM</a>
          
            <a href="/tags/IBM-AI-Engineering-Professional-Certificate/" rel="tag"># IBM AI Engineering Professional Certificate</a>
          
            <a href="/tags/Machine-Learning-with-Python/" rel="tag"># Machine Learning with Python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/07/19/coursera-39/" rel="next" title="University of Washington Machine Learning Foundations A Case Study Approach">
                <i class="fa fa-chevron-left"></i> University of Washington Machine Learning Foundations A Case Study Approach
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/07/19/coursera-36/" rel="prev" title="deep learning ai AI for Medical Diagnosis">
                deep learning ai AI for Medical Diagnosis <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/Wechat.jpg"
                alt="augest-chen" />
            
              <p class="site-author-name" itemprop="name">augest-chen</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">152</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">195</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">130</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">augest-chen</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
